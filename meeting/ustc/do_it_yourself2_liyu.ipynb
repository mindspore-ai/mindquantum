{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "train sample and feature shape:  (20, 4)\nfirst train sample:  [ 0.33333302 -0.24999988  0.804878    0.5294118 ]  with label:  1\n"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '2'\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def generate_train_and_test(split=0.8, shuffle=True):\n",
    "    iris = datasets.load_iris()\n",
    "    data = iris.data[:100, :].astype(np.float32)\n",
    "    data = preprocessing.minmax_scale(data) * 2 - 1\n",
    "    label = np.zeros(100).astype(int)\n",
    "    label[50:] = 1\n",
    "    return train_test_split(data, label, train_size=split, shuffle=shuffle)\n",
    "\n",
    "\n",
    "train_x, test_x, train_y, test_y = generate_train_and_test(split=0.2)\n",
    "print('train sample and feature shape: ', train_x.shape)\n",
    "print('first train sample: ', train_x[0, :], ' with label: ', train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "encoder circuit:\nq0: ──RX(x0)──\n              \nq1: ──RX(x1)──\n              \nq2: ──RX(x2)──\n              \nq3: ──RX(x3)──\n\n\nansatz circuit:\nq0: ──RX(gamma0)──\n                  \nq1: ──RX(gamma1)──\n                  \nq2: ──RX(gamma2)──\n                  \nq3: ──RX(gamma3)──\n\ntotal circuit:\nq0: ──RX(x0)────RX(gamma0)──\n                            \nq1: ──RX(x1)────RX(gamma1)──\n                            \nq2: ──RX(x2)────RX(gamma2)──\n                            \nq3: ──RX(x3)────RX(gamma3)──\n"
    }
   ],
   "source": [
    "from mindquantum import H, RZ, RX, X, Circuit, RY, UN\n",
    "\n",
    "\n",
    "def encoder(n):\n",
    "    c = Circuit()\n",
    "    #create your new encoder here\n",
    "    for i in range(n):\n",
    "        c += RX(f'x{i}').on(i)\n",
    "    return c\n",
    "\n",
    "\n",
    "enc = encoder(4).no_grad()\n",
    "print(\"encoder circuit:\")\n",
    "print(enc)\n",
    "print(\"\\n\")\n",
    "\n",
    "def ansatz(n_qubits):\n",
    "    c = Circuit()\n",
    "    # create your new ansatz here:\n",
    "    for i in range(n_qubits):\n",
    "        c += RX(f\"gamma{i}\").on(i)\n",
    "    return c\n",
    "\n",
    "\n",
    "ans = ansatz(4)\n",
    "print(\"ansatz circuit:\")\n",
    "print(ans)\n",
    "if len(ans) > 15:\n",
    "    raise ValueError(\n",
    "        \"Too many gates in the ansatz circuit, we limited it to 15 gate.\")\n",
    "tot = enc + ans\n",
    "print(\"\\ntotal circuit:\")\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1.0 [Z2] , 1.0 [Z3] ]\n"
    }
   ],
   "source": [
    "from mindquantum.ops import QubitOperator\n",
    "from mindquantum import Hamiltonian\n",
    "\n",
    "hams = [Hamiltonian(QubitOperator(f'Z{i}')) for i in [2, 3]]\n",
    "print(hams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindquantum import Simulator\n",
    "sim = Simulator('projectq', tot.n_qubits)\n",
    "f_g_ops = sim.get_expectation_with_grad(hams, tot,encoder_params_name=enc.params_name,ansatz_params_name=ans.params_name, parallel_worker=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([[-0.02425483+0.j,  0.42179538+0.j]]),\n array([[[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]]]),\n array([[[ 1.54498810e-17+0.j, -1.30104261e-17+0.j, -9.99705808e-01+0.j,\n           0.00000000e+00+0.j],\n         [-9.44611143e-18+0.j, -3.67002435e-17+0.j,  6.74915852e-17+0.j,\n          -9.06691047e-01+0.j]]]))"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "p0 = np.random.uniform(size=len(ans.params_name))\n",
    "f_g_ops(train_x[:1], p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "from mindquantum.nn import MQLayer\n",
    "ms.context.set_context(mode=ms.context.PYNATIVE_MODE, device_target=\"CPU\")\n",
    "ms.set_seed(42)\n",
    "net = MQLayer(f_g_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "QNN output: \n [[0.68977344 0.87000996]\n [0.7570179  0.80612576]\n [0.69660926 0.5286067 ]\n [0.7631809  0.6245892 ]]\n\nweight: \n [ 0.00495268 -0.00754737  0.00474223 -0.01383794]\n"
    }
   ],
   "source": [
    "from mindspore import Tensor\n",
    "print('QNN output: \\n', net(Tensor(train_x[:4])))\n",
    "print('\\nweight: \\n', net.weight.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.dataset as ds\n",
    "ms.set_seed(42)\n",
    "\n",
    "batch = 5\n",
    "train_loader = ds.NumpySlicesDataset({\n",
    "    'feats': train_x,\n",
    "    'labs': train_y\n",
    "},\n",
    "                                     shuffle=False).batch(batch)\n",
    "test_loader = ds.NumpySlicesDataset({\n",
    "    'feats': test_x,\n",
    "    'labs': test_y\n",
    "}).batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ms.nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "opti = ms.nn.Adam(net.trainable_params(), learning_rate=1e-1)\n",
    "monitor = ms.train.callback.LossMonitor(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch: 4 step: 4, loss is 0.31389818\nepoch: 8 step: 4, loss is 0.26366514\nepoch: 12 step: 4, loss is 0.2762904\nepoch: 16 step: 4, loss is 0.27422777\nepoch: 20 step: 4, loss is 0.27375117\nepoch: 24 step: 4, loss is 0.27409387\nepoch: 28 step: 4, loss is 0.2736756\nepoch: 32 step: 4, loss is 0.2739952\nepoch: 36 step: 4, loss is 0.27390555\nepoch: 40 step: 4, loss is 0.27395308\nepoch: 44 step: 4, loss is 0.273955\nepoch: 48 step: 4, loss is 0.2739719\n"
    }
   ],
   "source": [
    "model = ms.Model(net, loss, opti, metrics={'Acc': ms.nn.Accuracy()})\n",
    "model.train(50, train_loader, callbacks=[monitor], dataset_sink_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'Acc': 1.0}\n"
    }
   ],
   "source": [
    "predict = np.argmax(ms.ops.Softmax()(model.predict(ms.Tensor(test_x))), axis=1)\n",
    "corr = model.eval(test_loader, dataset_sink_mode=False)\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6cd6e2203b621035efd3b4ac9716079b52ce7fc5622f6651a3ae71459e0d54ce"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bit6d85dc99a0154758b5e9cafe0290ba76"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}