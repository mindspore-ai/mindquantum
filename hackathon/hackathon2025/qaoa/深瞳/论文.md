---
abstract: |
  Clifford线路能够在经典计算机上高效模拟，同时这类线路也可以产生和处理量子纠缠态，这为高效量子算法的设计提供了新思路。文献[@Mu_oz_Arias_2024]基于对自适应量子近似优化算法（ADAPT-QAOA）在最大割问题上的执行分析发现，在算法训练得到的参数下，线路近似为Clifford线路，这启发作者提出了自适应Clifford算法，该方法具有多项式时间复杂度，且数值实验表明其比传统方法具有更高的近似比。此次比赛要求针对带一阶项的伊辛模型探索基于Clifford门的量子组合优化算法设计与实现。我们通过扩展自旋变量消除了一阶项，从而使得原论文的方法可以推广到带一阶项的情形，同时我们指出，此操作造成了原论文伊辛模型的$Z_2$对称性破缺。我们对原论文方法的详细分析表明，ADAPT-QAOA学习到的其实是一个经典结构，原论文提出的自适应Clifford算法本质上是一个新的经典的贪心算法，我们通过近似比分析说明了该算法不比传统的贪心算法差。本文工作提供了两个有意义的启示：1.ADAPT-QAOA对混合哈密顿量的选择策略的贪心性质导致其实际上学到的是经典的贪心算法，但此算法比传统的贪心算法更优，说明变分量子算法有助于发掘新的经典算法。2.Clifford线路由于能被经典计算机高效模拟，其本身可能并不能提供量子优势。
author:
- 深瞳    中国科学院数学与系统科学研究院
bibliography:
- ref.bib
nocite: "[@*]"
title: 2025量子计算黑客松决赛论文------量子组合优化赛道
---

::: center
:::

# 问题背景

大部分组合优化问题都可以转化为二值变量优化问题，在有约束的情形可以把约束作为惩罚项加到优化的目标函数中，而二值变量可以表示为自旋，从而把待优化的目标函数转化为一个哈密顿量，这样我们可以把一个组合优化问题映射为一个伊辛模型的基态求解问题（若原问题要求最大值则加一个负号）。包含N个自旋变量$\{\sigma_z^{i}|\ i\in\{1,2,\dots,N-1,N\}\}$的伊辛模型的哈密顿量可以表示为：
$$H_{C}=\sum_{i}h_{i}\sigma^{i}_z+\sum_{i<j,\ \overline{ij}\in E}J_{ij}\sigma^{i}_z\sigma^{j}_z\label{equ1}$$

基于量子绝热演化理论，可以从一个简单哈密顿量$H_{B}$的基态出发，通过绝热演化逐渐获得目标哈密顿量$H_{C}$的基态，由此可以得到量子绝热算法（QAA），但量子线路只能以离散的步骤改变量子态，于是人们将演化时间离散化为一组小参数，结合变分量子算法（VQA）的通用框架提出了量子近似优化算法（QAOA）.
一个伊辛模型对应的标准p层QAOA量子线路如下图所示：

<figure id="fig1">
<p><span><img src="figures/QAOA线路.png" alt="image" /></span></p>
<figcaption>QAOA量子线路</figcaption>
</figure>

其中含有$\gamma=(\gamma_{1},\gamma_{2},\dots,\gamma_{p}),\ \beta=(\beta_{1},\beta_{2},\dots,\beta_{p})$共$2p$个参数，对线路末态$\ket{\Psi}$测量伊辛模型对应哈密顿量的均值$C(\gamma,\beta)=\bra{\Psi}H_{C}\ket{\Psi}$作为目标函数。简单哈密顿量$H_B$通常被称为混合哈密顿量，在QAOA中被设置为$H_B=\sum_i \sigma^i_x$，这未必是最好的选择，因此便有了ADAPT-QAOA的想法。ADAPT-QAOA每一层的混合哈密顿量是从一个预先给定的算子池里选择的，设第$l$层的混合哈密顿量为$A_l$，则$p$层ADAPT-QAOA制备出的态为：
$$\label{equ2}
|\psi(\gamma, \beta)\rangle_p^{\rm ADAPT} = \left[\prod_{l=1}^p e^{-i\beta_l A_l } e^{-i \gamma_l H_{\rm C}} \right] \mathrm{H}^{\otimes N} |0\rangle^{\otimes N}$$

$A_l$的选择按照最大化当前能量梯度的策略进行，即： $$\label{equ3}
A_l = \underset{A_s \in \mathrm{P}_{\rm op}}{\rm argmax}\left[-i\langle\psi_{l-1}|e^{i\gamma_l H_{\rm C}}[H_{\rm C}, \hat{A}_s]e^{-i\gamma_l H_{\rm C}}|\psi_{l-1}\rangle \right]$$

$$\label{equ4}
\begin{split}
\mathrm{P}_{\rm op} =& \{ \sum_i X_i, \sum_i Y_i \} \cup \{X_j, Y_j\}_{j=1,...,N}\cup \{X_j X_k, Y_j Y_k, Y_j Z_k, Z_j Y_k\}_{j,k=1,...,N;\ j\ne k}
\end{split}$$

注意这种策略已经蕴含了贪心性质，因为后续加入的线路层完全有可能影响前面线路层的混合哈密顿量对应的能量梯度，而此策略无法考虑该影响，因此是仅考虑局部最优的贪心策略，这为它学习出一个经典的贪心算法埋下了伏笔。文献[@Mu_oz_Arias_2024]中考虑了什么情况下，ADAPT-QAOA的Ansatz会成为一个Clifford线路。设$\tilde{P}_i,\tilde{P}_j$为两个不同的泡利串，ADAPT-QAOA的Ansatz具有$W(\theta)=e^{-i\theta \tilde{P}_j}$的形式。当$[\tilde{P}_i,\tilde{P}_j]=0$时，$W^\dagger \tilde{P}_i W = \tilde{P}_i$；当$\{\tilde{P}_i,\tilde{P}_j\} = 0$且$\theta = \pm m\frac{\pi}{4},\ m\in\mathbb{N}$时，$W^\dagger \tilde{P}_i W = i\tilde{P}_i\tilde{P}_j$.
这两种情况下ADAPT-QAOA的Ansatz是Clifford的。文献在使用ADAPT-QAOA求解最大割问题时发现，问题哈密顿量对应的演化参数$\gamma_l$近似收敛到0，而最大梯度对应的混合哈密顿量形式大都为$A_l=Y_iZ_j$，对应的演化参数$\beta_l$近似收敛到$0$或$-\frac{\pi}{4}$，这说明经过变分优化后的线路近似为一个Clifford线路。文献[@Mu_oz_Arias_2024]利用稳定子的有关理论从这类Clifford线路中抽象出了一个求解最大割问题的算法：
将编码图顶点的量子比特分为激活比特和非激活比特。初始时，所有比特都是非激活的，算法每迭代一步，就会通过纠缠操作激活一个比特。设第$r$步的激活比特位置（指在比特串的第几位或者对应的图顶点编号）为$a^{(r)}\in\mathbf{a}^{(r)}$，非激活比特位置为$b^{(r)}\in\mathbf{b}^{(r)}$，激活比特处于量子纠缠态，而非激活比特处于平凡的乘积态。原先的梯度公式（[\[equ3\]](#equ3){reference-type="ref"
reference="equ3"}）可化简为： $$\label{equ5}
g_{a^{(r-1)},b^{(r-1)}}^{(r)} = -i\langle[H_{\rm C},Z_{a^{(r-1)}} Y_{b^{(r-1)}}]\rangle_{r-1} \\
 = -\sum_l \omega_{l,b^{(r-1)}}\langle Z_l X_{b^{(r-1)}} Z_{a^{(r-1)}} \rangle_{r-1}$$

其中，$\langle.\rangle_{r-1} = \langle\psi_{r-1}|.|\psi_{r-1}\rangle$是在算法的第$r-1$步得到的态上取期望。并且梯度计算只考虑激活比特和非激活比特之间的梯度，这样当我们得到最大梯度时就可以把它对应的非激活比特激活。当所有比特均被激活后算法结束，测量输出态，$\ket{0}$和$\ket{1}$对应的顶点划分成两个集合，它们之间的边就是割集。算法的具体步骤如下，文献中称其为ADAPT-Clifford算法：

 

1.  $r=0\ $ 随机选择一个比特位置$k$，制备一个乘积态： $$\label{equ6}
            |\psi_0\rangle = Z_k \mathrm{H}^{\otimes N}|0\rangle^{\otimes N}.$$

    此时激活比特和非激活比特位置集分别为$\mathbf{a}^{(0)}=\{k\}$和$\mathbf{b}^{(0)}=\{1,..,N\}\backslash \{k\}$.

2.  $r=1\ $
    计算$a^{(0)}=k$涉及的梯度，$\underset{b^{(0)}}{\rm max}[g^{(1)}_{k,b^{(0)}}] = \underset{b^{(0)}}{\rm max}[\omega_{k,b^{(0)}}]$，选出需要激活的比特位：
    $$j = \underset{b^{(0)}}{{\rm argmax}}[\omega_{k,b^{(0)}}].$$

    作用量子门$e^{i{\frac{\pi}{4}}Y_k Z_j}$得到态：
    $$|\psi_{1}\rangle = e^{i\frac{\pi}{4}Z_j Y_k} Z_k \mathrm{H}^{\otimes N}|0\rangle^{\otimes N}.$$

    更新激活比特和非激活比特位置集为$\mathbf{a}^{(1)}=\{k,j\}$ 和
    $\mathbf{b}^{(1)}=\{1,..,N\}\backslash \{k,j\}$.

3.  $r=2,...,N-1\ $找出一对比特$(\tilde{l},b^{(r-1)}),\ \tilde{l}\in\{k,j\}$，使其最大化梯度$g^{(r)}_{\tilde{l},b^{(r-1)}}$.

    作用量子门$e^{i{\frac{\pi}{4}} Z_{\tilde{l}} Y_{b^{(r-1)}}}$，更新激活和非激活比特位置集。

    若有多个比特对$(\tilde{l},b^{(r-1)})$使得梯度$g^{(r)}_{a^{(r-1)},b^{(r-1)}}$具有相同的最大值，随意选择一对。

4.  在$N$步迭代后，算法结束，得到量子态： $$\label{equ9}
                  |\Psi\rangle = \left[ \prod_{r=2}^{N-1} e^{i\frac{\pi}{4} Z_{\tilde{l}} Y_{b^{(r)}}} \right] e^{i\frac{\pi}{4} Z_{j} Y_{k}} Z_k \mathrm{H}^{\otimes N}|0\rangle^{\otimes N}$$

    对量子态进行测量，读出最大割集。

 

上述算法中的量子门$e^{i{\frac{\pi}{4}}Z_{\tilde{l}} Y_m} = \mathrm{S}_m \mathrm{H}_{\tilde{l}} {\rm CNOT}_{m,\tilde{l}} R_x^{(m)}(-\pi/2) {\rm CNOT}_{m,\tilde{l}}\mathrm{S}^\dagger_m \mathrm{H}_{\tilde{l}}$可分解为Clifford门的组合。整个算法可以用稳定子的视角来理解：在算法的开始，乘积态$\ket{\psi_0}$有$N-1$个稳定子$X_l,\ l=1,...,N,\ l\ne k$和一个单独的稳定子$-X_k$，随着算法的执行，稳定子将不断更新：算法第一步$r=1$，$-X_k\to -e^{i{\frac{\pi}{4}}Y_k Z_j}X_ke^{-i{\frac{\pi}{4}}Y_k Z_j}=-Z_kZ_j$；算法后续步骤$r>1$，$X_m\to e^{i{\frac{\pi}{4}}Z_{\tilde{l}} Y_m}X_me^{-i{\frac{\pi}{4}}Z_{\tilde{l}} Y_m}=Z_{\tilde{l}}Z_m$.

论文作者对最大割问题验证了上述ADAPT-Clifford算法的有效性，其近似比甚至可与经典的Goemans-Williamson算法相媲美，时间复杂度至多$O(N^3)$.
而赛题受其启发，希望选手能够探索针对一般伊辛模型的ADAPT-Clifford算法，由于Clifford线路可被经典计算机高效模拟，这实际上是对量子启发算法的一种探索。

# ADAPT-Clifford算法的本质

在文献[@Mu_oz_Arias_2024]中，作者无法提供ADAPT-Clifford算法的有效性证明，而我们通过分析将指出，ADAPT-Clifford算法本质上是一个新的贪心算法，进一步地，我们分析了该算法和传统贪心算法的异同并给出其近似比下界以及优势。

## 新的贪心算法

注意到，ADAPT-Clifford算法执行后所得量子态（[\[equ9\]](#equ9){reference-type="ref"
reference="equ9"}）的稳定子中有$N-1$个很重要：$\{-Z_kZ_j,\ Z_{\tilde{l}}Z_m\ |\ \tilde{l}\in \{k,j\},\ m\in\{1,...,N\}\backslash\{k,j\},\ $稳定子的下标$m$取不同的值$\}$.
从这里可以看出，当我们对量子态（[\[equ9\]](#equ9){reference-type="ref"
reference="equ9"}）进行$Z$基测量时，$k$和$j$位量子比特的结果一定不同，即一个测得1则另一个必为-1，而其他位量子比特$m$的测量结果一定与它在稳定子中匹配的$\tilde{l}$位的结果相同。这样，算法的执行过程其实对应了一个经典的过程：就最大割问题而言，首先选择图的一个顶点$k$，然后在第一步以某种方式选择顶点$j$，这两个顶点初始化了两个集合，接下来的每一步都按照某种方式选择一个顶点并将其加入某个集合中，当所有顶点都被加入到某个集合里时算法结束，得到的两个集合之间的边即为问题的一个近似解。跟随文献[@Mu_oz_Arias_2024]的计算，梯度公式（[\[equ5\]](#equ5){reference-type="ref"
reference="equ5"}）可以进一步化简为（梯度计算时，在激活比特位置集里取值的梯度下标只需考虑$k$和$j$，这是因为其他情况的梯度总可以等值地转化为这两种情形，具体详见[@Mu_oz_Arias_2024]）：
$$\label{equ10}
g_{k,b^{(r-1)}}^{(r)} = -\sum_{\substack{l\in\mathbf{V}_k^{(r-1)}\\
(l,b^{(r-1)})\in\mathcal{E}}} \omega_{l,b^{(r-1)}} + \sum_{\substack{l\in\mathbf{V}_j^{(r-1)}\\
(l,b^{(r-1)})\in\mathcal{E}}} \omega_{l,b^{(r-1)}}$$
以及$g_{j,b^{(r-1)}}^{(r)} = - g_{k,b^{(r-1)}}^{(r)}$.
其中，$\mathcal{E}$是图的边集，$\mathbf{V}_k^{(r-1)}$是激活比特位置集$\mathbf{a}^{(r)}$中因为与比特$k$纠缠而激活的比特位构成的集合，而$\mathbf{V}_j^{(r-1)}$则是与比特$j$纠缠激活的比特位构成的集合，我们有$\mathbf{a}^{(r)}=V_{k}^{(r)} \cup V_j^{(r)},\ V_{k}^{(r)} \cap V_j^{(r)} = \emptyset$.（[\[equ10\]](#equ10){reference-type="ref"
reference="equ10"}）式已经不包含任何算符，事实上，可以看出，这其实就是把顶点$b^{(r-1)}$划分到和$k$一类时增加的割与划分到和$j$一类时增加的割之差。而$g_{j,b^{(r-1)}}^{(r)}$的值则是把顶点$b^{(r-1)}$划分到和$j$一类时增加的割与划分到和$k$一类时增加的割之差。由于要取最大梯度对应的顶点，所以取的是正值，也就是说和哪个点划为一类增加的割更多就把顶点$b^{(r-1)}$划分到那个点所在的集合里。这样，我们便看到了ADAPT-Clifford算法本质上其实是如下贪心算法（我们称为算法A）：

 

1.  随机选择一个顶点$k$，将与$k$相邻且边权最大的顶点选出并记为$j$，初始化两个集合$V_k=\{k\},\ V_j=\{j\}$.

2.  对于未被选出加入到两个集合中的顶点$m$，按如下规则决定将其分配到哪个集合：

    1.  计算将$m$分配到$V_k$会增加的割边权重（即$m$与当前$V_j$中所有顶点的边权之和），以及分配到$V_j$会增加的割边权重（即$m$与当前$V_k$中所有顶点的边权之和）。

    2.  如果分配到$V_k$的增加量大于分配到$V_j$的增加量，则点$m$若被选出则应加入到$V_k$中，否则应加入到$V_j$中。

    3.  只有选择顶点$m$能产生最大的增加量时，才选出顶点$m$并按照上述规则分配到$V_k$或$V_j$中。

3.  重复步骤2，直到所有顶点都被分配到$V_k$或$V_j$中。此时，两个集合之间的边即为割边。

## 和传统贪心算法的比较以及近似比分析

求解最大割问题传统的贪心算法（我们称为算法B）如下：

1.  初始时将顶点随机分为两个集合。

2.  不断遍历顶点：对于每个顶点，如果将其分配到另一个集合能增加割边权重，就将其移动到另一个集合，否则不移动。

3.  重复步骤2，直到移动任何单个顶点都不再能增加割边权重。

 

容易看出，两种贪心算法的关键区别在于：算法A在决定一个顶点的分配时，只考虑它与已经分配的顶点之间的边权；一旦初始顶点确定，算法A就有一个明确的顶点分配顺序，且算法在所有顶点按序分配完后终止。算法B在决定一个顶点的分配时，会考虑它与所有其他顶点之间的边权；初始随机分配后，算法可能多次遍历所有顶点，直到移动任何顶点都无法增加割边权重时终止。

不难证明，算法B的近似比下界为$\frac{1}{2}$，这是已知的。下面我们证明，算法A的近似比下界也是$\frac{1}{2}$：

设$G=(V,E)$为无向图，边权$\omega(e)\geq 0$，最优割权重（最优割所有边权之和）为$opt$，算法A输出的割权重为$C_A$.

1.  令算法A添加顶点的顺序为$u_1,u_2,...,u_n$，其中$u_1=k,\ u_2=j$.

2.  设$S_t$为添加$u_t$前已选顶点的集合，$g(u_t)=max(\Delta_k(u_t),\Delta_j(u_t))$为添加$u_t$时的割边权重增量，则$C_A=\sum_{t=1}^ng(u_t)$.
    $\Delta_k(u_t),\Delta_j(u_t)$分别为将顶点$u_t$分配到与$k$或$j$一类时增加的割边权重。

3.  对任意顶点$u_t$有： $$\begin{aligned}
            g(u_t)&=max(\sum_{v\in V_j\cap S_t}\omega(u_t,v),\sum_{v\in V_k\cap S_t}\omega(u_t,v))\notag\\
            &\geq\frac{1}{2}(\sum_{v\in V_j\cap S_t}\omega(u_t,v)+\sum_{v\in V_k\cap S_t}\omega(u_t,v))=\frac{1}{2}deg_t(u_t)\notag
        
    \end{aligned}$$

    其中，$deg_t(u_t)=\sum_{v\in S_t}\omega(u_t,v)$是$u_t$与$S_t$中顶点的边权和。

4.  因此： $$C_A\geq \frac{1}{2}\sum_{t=1}^n deg_t(u_t) \notag$$

5.  考虑$\sum_{t=1}^n deg_t(u_t)$，每条边$(u,v)$在添加第二个端点时被计入（即若$v$在$u$之后添加，则当添加$v$时$u\in S_t$，边权$\omega(u,v)$计入$deg_t(v)$，保证了所有边均被计算在内）。因此：
    $$\sum_{t=1}^n deg_t(u_t)=\sum_{e\in E}\omega(e)\notag$$

6.  综上可得：

    $$C_A\geq \frac{1}{2}\sum_{e\in E}\omega(e)\geq \frac{1}{2}opt \notag$$

    故算法A有$\frac{1}{2}$近似比。

 

以上说明算法A不差于算法B，但是根据文献[@Mu_oz_Arias_2024]中的数值实验，ADAPT-Clifford算法明显更优，所以算法A应该优于算法B.
我们认为，这是由于算法A在很多情况下近似比都会更好，因为算法在初始化阶段确保高权重边被固定，后续顶点的选择基于最大增量，优先处理与已选顶点集合高连接的顶点，使得高权重边更可能被包含在割集中，并引导后续决策朝向更优的全局解。

# 推广到带一阶项的伊辛模型以及$Z_2$对称性破缺

为将ADAPT-Clifford算法推广到带一阶项的伊辛模型（[\[equ1\]](#equ1){reference-type="ref"
reference="equ1"}），我们采用了扩展自旋变量的方法。即引入一个新的自旋变量$\sigma^0_z$同时令$J_{0i}=J_{i0}=h_i,\ J_{ij}=0$若$\overline{ij}\notin E$，这样（[\[equ1\]](#equ1){reference-type="ref"
reference="equ1"}）就转化为了：
$$H_{C}=\frac{1}{2}\sum_{i,j=0}^NJ_{ij}\sigma^{i}_z\sigma^{j}_z\label{equ11}$$

从而可以用ADAPT-Clifford算法求解。注意到，二阶伊辛模型有一个$Z_2$对称性，即翻转所有自旋$\sigma^i_z$的符号并不改变哈密顿量。ADAPT-Clifford算法保持了这一对称性，其输出量子态（[\[equ9\]](#equ9){reference-type="ref"
reference="equ9"}）实际上是两个互补的$Z$基的和（例如$\frac{1}{\sqrt{2}}(\ket{01101}+\ket{10010})$），测量后会随机得到其中一个解。而对于扩展变量的模型，这个对称性被破缺了，因为必须保证扩展变量$\sigma^0_z=1$扩展前后的模型才是等价的。所以输出态的两个基矢中只有第0位比特为0的才是解。除此以外，为了进一步提高近似比，跳出局部解，我们可以针对不同的初始顶点执行算法，然后挑取最优的输出，但限于比赛的时间要求，只能随机选择几个初始顶点，而不能遍历所有顶点。关于此，我们做了补充实验：在题给的200个点的伊辛模型数据集上做重复测试。针对赛题模板给的贪心算法，也即算法B，设置重复次数1-200，步长为4，例如重复次数为197，就是执行算法B197次，每次都是从一个随机划分开始，全部执行完毕后取最好的结果。针对本文给出的算法A，也设置重复次数1-200，步长为4，但是每次执行选择不同的初始顶点，例如重复次数为9，就是执行算法A9次，每次从不同的初始顶点开始，全部执行完毕后取最好的结果。实验结果如图[2](#fig2){reference-type="ref"
reference="fig2"}和图[3](#fig3){reference-type="ref"
reference="fig3"}所示。从图中可以看出，算法B具有很大的随机性，重复执行并不能有效提高分数（总分是指5个种子的伊辛模型的分数和），分数变化范围为3006.44-3370.11；而算法A的效果会随重复次数增加而有效提高，且在重复次数超过25次后基本趋于稳定，分数变化范围为3158.38-3516.10，最低和最高分均优于算法B.
值得注意的是，虽然算法B只重复一次时就能取得3300的分数，但这实际上具有很大随机性，例如重复5次的分数还不到3050，同样的，算法A只重复一次的分数也具有随机性，实验显示算法A单次执行更容易取得较高分数。这些结果从数值角度说明了，虽然具有同样的近似比下界，但算法A明显优于算法B.

<figure id="fig2">
<p><span><img src="figures/replot_with_keypoints_B.png"
alt="image" /></span></p>
<figcaption>算法B执行结果</figcaption>
</figure>

<figure id="fig3">
<p><span><img src="figures/replot_with_keypoints_A.png"
alt="image" /></span></p>
<figcaption>算法A执行结果</figcaption>
</figure>

至此，我们的结果已经全部介绍完毕，至于比赛得分可参见云平台分数。需要说明的是，由上图可知，算法A的重复次数并非越多越好，以200比特伊辛模型为例，25次是最佳的重复值，继续增加执行次数分数不再有较多提高，而运行时间将不断增加。
本文工作提供了两个有意义的启示：1.ADAPT-QAOA对混合哈密顿量的选择策略的贪心性质导致其实际上学到的是经典的贪心算法，但此算法比传统的贪心算法更优，说明变分量子算法有助于发掘新的经典算法。2.Clifford线路由于能被经典计算机高效模拟，其本身可能并不能提供量子优势。[@Mu_oz_Arias_2024]设计的ADAPT-Clifford算法就是一个例子，它实际上就是一个纯经典的贪心算法，并没有使用量子线路执行的必要。

 

 

 

 

 

 

::: appendices
# 主要代码

answer.py

``` {.python language="python"}
```
:::
