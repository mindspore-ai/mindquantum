{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2542fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code functionality: Adaptive mixer allocation strategy\n",
    "# Step 1: 1-layer ansatz, mixers applied to some vertices\n",
    "# Step 2: Select some operators from the operator pool and add them to the current circuit. The selection criterion: a score composed of the average gradient and average expectation function value. Only mixers are added.\n",
    "# Step 3: Optimize the current circuit\n",
    "# Step 4: Repeat Step 2 and Step 3 until the iteration convergence condition is met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0b3691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindquantum.core.circuit import Circuit, UN\n",
    "from mindquantum.core.gates import H, ZZ, RX,RZ,X,I,Measure\n",
    "from mindquantum.core.operators import Hamiltonian, QubitOperator\n",
    "from mindquantum.framework import MQAnsatzOnlyLayer,MQLayer,MQAnsatzOnlyOps\n",
    "from mindquantum.simulator import Simulator\n",
    "from mindspore.common.initializer import Normal,initializer\n",
    "from mindspore import Tensor,ops\n",
    "from mindspore import dtype as mstype\n",
    "from mindspore.common.parameter import Parameter\n",
    "from mindspore.nn import Adam, TrainOneStepCell                   \n",
    "\n",
    "import networkx as nx\n",
    "import mindspore.nn as nn\n",
    "import mindspore as ms\n",
    "import mindquantum as mq\n",
    "import copy\n",
    "from math import pi\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import pi\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "\n",
    "# 加载额外需要用到的包\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import datetime\n",
    " \n",
    "def init_logger(filename, logger_name):\n",
    "    '''\n",
    "    @brief:\n",
    "        initialize logger that redirect info to a file just in case we lost connection to the notebook\n",
    "    @params:\n",
    "        filename: to which file should we log all the info\n",
    "        logger_name: an alias to the logger\n",
    "    '''\n",
    " \n",
    "    # get current timestamp\n",
    "    timestamp = datetime.datetime.utcnow().strftime('%Y%m%d_%H-%M-%S')\n",
    "    \n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO, \n",
    "        format='%(message)s',\n",
    "#         format='%(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(filename=filename,encoding='utf-8'),\n",
    "            logging.StreamHandler(sys.stdout)\n",
    "        ]\n",
    "    )\n",
    " \n",
    "    # Test\n",
    "    logger = logging.getLogger(logger_name)\n",
    "   #logger.info('### Init. Logger {} ###'.format(logger_name))\n",
    "    return logger\n",
    "\n",
    "\n",
    "# Initialize\n",
    "my_logger = init_logger(\"test.log\", \"ml_logger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cace375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the circuit depth using this interface\n",
    "\n",
    "# right 2021 Huawei Technologies Co., Ltd\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ============================================================================\n",
    "\"\"\"DAG Circuit.\"\"\"\n",
    "import typing\n",
    "\n",
    "from mindquantum.core import Circuit, gates\n",
    "from mindquantum.utils.type_value_check import _check_input_type\n",
    "\n",
    "# pylint: disable=invalid-name\n",
    "\n",
    "\n",
    "class DAGNode:\n",
    "    \"\"\"\n",
    "    Basic node in Directed Acyclic Graph.\n",
    "\n",
    "    A DAG node has local index, which label the index of leg of node, and child nodes and father nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize a DAGNode object.\"\"\"\n",
    "        self.child: typing.Dict[int, \"DAGNode\"] = {}  # key: local index, value: child DAGNode\n",
    "        self.father: typing.Dict[int, \"DAGNode\"] = {}  # key: local index, value: father DAGNode\n",
    "        self.local: typing.List[int] = []\n",
    "\n",
    "    def clean(self):\n",
    "        \"\"\"Clean node and set it to empty.\"\"\"\n",
    "        self.child = {}\n",
    "        self.father = {}\n",
    "        self.local = []\n",
    "\n",
    "    def insert_after(self, other_node: \"DAGNode\"):\n",
    "        \"\"\"\n",
    "        Insert other node after this dag node.\n",
    "\n",
    "        Args:\n",
    "            other_node (:class:`~.algorithm.compiler.DAGNode`): other DAG node.\n",
    "        \"\"\"\n",
    "        _check_input_type(\"other_node\", DAGNode, other_node)\n",
    "        for local in self.local:\n",
    "            if local in other_node.local:\n",
    "                other_node.father[local] = self\n",
    "                if local in self.child:\n",
    "                    other_node.child[local] = self.child.get(local)\n",
    "                    self.child.get(local).fathre[local] = other_node\n",
    "                self.child[local] = other_node\n",
    "\n",
    "    def insert_before(self, other_node: \"DAGNode\"):\n",
    "        \"\"\"\n",
    "        Insert other node before this dag node.\n",
    "\n",
    "        Args:\n",
    "            other_node (:class:`~.algorithm.compiler.DAGNode`): other DAG node.\n",
    "        \"\"\"\n",
    "        _check_input_type(\"other_node\", DAGNode, other_node)\n",
    "        for local in self.local:\n",
    "            if local in other_node.local:\n",
    "                other_node.child[local] = self\n",
    "                if local in self.father:\n",
    "                    other_node.father[local] = self.father.get(local)\n",
    "                    self.father.get(local).child[local] = other_node\n",
    "                self.father[local] = other_node\n",
    "\n",
    "\n",
    "def connect_two_node(father_node: DAGNode, child_node: DAGNode, local_index: int):\n",
    "    \"\"\"\n",
    "    Connect two DAG node through given local_index.\n",
    "\n",
    "    Args:\n",
    "        father_node (DAGNode): The father DAG node.\n",
    "        child_node (DAGNode): The child DAG node.\n",
    "        local_index (int): which leg you want to connect.\n",
    "    \"\"\"\n",
    "    if local_index not in father_node.local or local_index not in child_node.local:\n",
    "        raise ValueError(\n",
    "            f\"local_index {local_index} not in father_node\" f\" {father_node} or not in child_node {child_node}.\"\n",
    "        )\n",
    "    father_node.child[local_index] = child_node\n",
    "    child_node.father[local_index] = father_node\n",
    "\n",
    "\n",
    "class DAGQubitNode(DAGNode):\n",
    "    \"\"\"\n",
    "    DAG node that work as quantum qubit.\n",
    "\n",
    "    Args:\n",
    "        qubit (int): id of qubit.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, qubit: int):\n",
    "        \"\"\"Initialize a DAGQubitNode object.\"\"\"\n",
    "        super().__init__()\n",
    "        _check_input_type(\"qubit\", int, qubit)\n",
    "        self.qubit = qubit\n",
    "        self.local = [qubit]\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Return a string representation of qubit node.\"\"\"\n",
    "        return f\"q{self.qubit}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Return a string representation of qubit node.\"\"\"\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class GateNode(DAGNode):\n",
    "    \"\"\"\n",
    "    DAG node that work as quantum gate.\n",
    "\n",
    "    Args:\n",
    "        gate (:class:`~.core.gates.BasicGate`): Quantum gate.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gate: gates.BasicGate):\n",
    "        \"\"\"Initialize a GateNode object.\"\"\"\n",
    "        super().__init__()\n",
    "        _check_input_type(\"gate\", gates.BasicGate, gate)\n",
    "        self.gate = gate\n",
    "        self.local = gate.obj_qubits + gate.ctrl_qubits\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Return a string representation of gate node.\"\"\"\n",
    "        return str(self.gate)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Return a string representation of gate node.\"\"\"\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class BarrierNode(GateNode):\n",
    "    \"\"\"DAG node that work as barrier.\"\"\"\n",
    "\n",
    "    def __init__(self, gate: gates.BasicGate, all_qubits: typing.List[int]):\n",
    "        \"\"\"Initialize a BarrierNode object.\"\"\"\n",
    "        super().__init__(gate)\n",
    "        self.local = all_qubits\n",
    "\n",
    "\n",
    "class DAGCircuit:\n",
    "    \"\"\"\n",
    "    A Directed Acyclic Graph of a quantum circuit.\n",
    "\n",
    "    Args:\n",
    "        circuit (:class:`~.core.circuit.Circuit`): the input quantum circuit.\n",
    "\n",
    "    Examples:\n",
    "    from mindquantum.algorithm.compiler import DAGCircuit\n",
    "    from mindquantum.core.circuit import Circuit\n",
    "    circ = Circuit().h(0).x(1, 0)\n",
    "    dag_circ = DAGCircuit(circ)\n",
    "    dag_circ.head_node[0]\n",
    "        q0\n",
    "    dag_circ.head_node[0].child\n",
    "        {0: H(0)}\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, circuit: Circuit):\n",
    "        \"\"\"Initialize a DAGCircuit object.\"\"\"\n",
    "        _check_input_type(\"circuit\", Circuit, circuit)\n",
    "        self.head_node = {i: DAGQubitNode(i) for i in sorted(circuit.all_qubits.keys())}\n",
    "        self.final_node = {i: DAGQubitNode(i) for i in sorted(circuit.all_qubits.keys())}\n",
    "        for i in self.head_node:\n",
    "            self.head_node[i].insert_after(self.final_node[i])\n",
    "        for gate in circuit:\n",
    "            if isinstance(gate, gates.BarrierGate):\n",
    "                if gate.obj_qubits:\n",
    "                    self.append_node(BarrierNode(gate, sorted(gate.obj_qubits)))\n",
    "                else:\n",
    "                    self.append_node(BarrierNode(gate, sorted(circuit.all_qubits.keys())))\n",
    "            else:\n",
    "                self.append_node(GateNode(gate))\n",
    "        self.global_phase = gates.GlobalPhase(0)\n",
    "\n",
    "    @staticmethod\n",
    "    def replace_node_with_dag_circuit(node: DAGNode, coming: \"DAGCircuit\"):\n",
    "        \"\"\"\n",
    "        Replace a node with a DAGCircuit.\n",
    "\n",
    "        Args:\n",
    "            node (:class:`~.algorithm.compiler.DAGNode`): the original DAG node.\n",
    "            coming (:class:`~.algorithm.compiler.DAGCircuit`): the coming DAG circuit.\n",
    "\n",
    "        Examples:\n",
    "        from mindquantum.algorithm.compiler import DAGCircuit\n",
    "        from mindquantum.core.circuit import Circuit\n",
    "        circ = Circuit().x(1, 0)\n",
    "        circ\n",
    "            q0: ────■─────\n",
    "                    ┃\n",
    "                  ┏━┻━┓\n",
    "            q1: ──┨╺╋╸┠───\n",
    "                  ┗━━━┛\n",
    "        dag_circ = DAGCircuit(circ)\n",
    "        node = dag_circ.head_node[0].child[0]\n",
    "        node\n",
    "            X(1 <-: 0)\n",
    "        sub_dag = DAGCircuit(Circuit().h(1).z(1, 0).h(1))\n",
    "        DAGCircuit.replace_node_with_dag_circuit(node, sub_dag)\n",
    "        dag_circ.to_circuit()\n",
    "            q0: ──────────■───────────\n",
    "                          ┃\n",
    "                  ┏━━━┓ ┏━┻━┓ ┏━━━┓\n",
    "            q1: ──┨ H ┠─┨ Z ┠─┨ H ┠───\n",
    "                  ┗━━━┛ ┗━━━┛ ┗━━━┛\n",
    "        \"\"\"\n",
    "        if set(node.local) != {head.qubit for head in coming.head_node.values()}:\n",
    "            raise ValueError(f\"Circuit in coming DAG is not aligned with gate in node: {node}\")\n",
    "        for local in node.local:\n",
    "            connect_two_node(node.father[local], coming.head_node[local].child[local], local)\n",
    "            connect_two_node(coming.final_node[local].father[local], node.child[local], local)\n",
    "\n",
    "    def append_node(self, node: DAGNode):\n",
    "        \"\"\"\n",
    "        Append a quantum gate node.\n",
    "\n",
    "        Args:\n",
    "            node (:class:`~.algorithm.compiler.DAGNode`): the DAG node you want to append.\n",
    "\n",
    "        Examples:\n",
    "        from mindquantum.algorithm.compiler import DAGCircuit, GateNode\n",
    "        from mindquantum.core.circuit import Circuit\n",
    "        import mindquantum.core.gates as G\n",
    "        circ = Circuit().h(0).x(1, 0)\n",
    "        circ\n",
    "                  ┏━━━┓\n",
    "            q0: ──┨ H ┠───■─────\n",
    "                  ┗━━━┛   ┃\n",
    "                        ┏━┻━┓\n",
    "            q1: ────────┨╺╋╸┠───\n",
    "                        ┗━━━┛\n",
    "        dag_circ = DAGCircuit(circ)\n",
    "        node = GateNode(G.RX('a').on(0, 2))\n",
    "        dag_circ.append_node(node)\n",
    "        dag_circ.to_circuit()\n",
    "                  ┏━━━┓       ┏━━━━━━━┓\n",
    "            q0: ──┨ H ┠───■───┨ RX(a) ┠───\n",
    "                  ┗━━━┛   ┃   ┗━━━┳━━━┛\n",
    "                        ┏━┻━┓     ┃\n",
    "            q1: ────────┨╺╋╸┠─────╂───────\n",
    "                        ┗━━━┛     ┃\n",
    "                                  ┃\n",
    "            q2: ──────────────────■───────\n",
    "        \"\"\"\n",
    "        _check_input_type('node', DAGNode, node)\n",
    "        for local in node.local:\n",
    "            if local not in self.head_node:\n",
    "                self.head_node[local] = DAGQubitNode(local)\n",
    "                self.final_node[local] = DAGQubitNode(local)\n",
    "                self.head_node[local].insert_after(self.final_node[local])\n",
    "            self.final_node[local].insert_before(node)\n",
    "\n",
    "    def depth(self) -> int:\n",
    "        \"\"\"\n",
    "        Return the depth of quantum circuit.\n",
    "\n",
    "        Examples:\n",
    "        from mindquantum.core.circuit import Circuit\n",
    "        from mindquantum.algorithm.compiler import DAGCircuit\n",
    "        circ = Circuit().h(0).h(1).x(1, 0)\n",
    "        circ\n",
    "                  ┏━━━┓\n",
    "            q0: ──┨ H ┠───■─────\n",
    "                  ┗━━━┛   ┃\n",
    "                  ┏━━━┓ ┏━┻━┓\n",
    "            q1: ──┨ H ┠─┨╺╋╸┠───\n",
    "                  ┗━━━┛ ┗━━━┛\n",
    "        DAGCircuit(circ).depth()\n",
    "            2\n",
    "        \"\"\"\n",
    "        return len(self.layering())\n",
    "\n",
    "    def find_all_gate_node(self) -> typing.List[GateNode]:\n",
    "        \"\"\"\n",
    "        Find all gate node in this :class:`~.algorithm.compiler.DAGCircuit`.\n",
    "\n",
    "        Returns:\n",
    "            List[:class:`~.algorithm.compiler.GateNode`], a list of all :class:`~.algorithm.compiler.GateNode`\n",
    "            of this :class:`~.algorithm.compiler.DAGCircuit`.\n",
    "\n",
    "        Examples:\n",
    "        from mindquantum.algorithm.compiler import DAGCircuit\n",
    "        from mindquantum.core.circuit import Circuit\n",
    "        circ = Circuit().h(0).x(1, 0)\n",
    "        dag_circ = DAGCircuit(circ)\n",
    "        dag_circ.find_all_gate_node()\n",
    "            [H(0), X(1 <-: 0)]\n",
    "        \"\"\"\n",
    "        found = set(self.head_node.values())\n",
    "\n",
    "        def _find(current_node: DAGNode, found):\n",
    "            if current_node not in found:\n",
    "                found.add(current_node)\n",
    "                for node in current_node.father.values():\n",
    "                    _find(node, found)\n",
    "                for node in current_node.child.values():\n",
    "                    _find(node, found)\n",
    "\n",
    "        for head_node in self.head_node.values():\n",
    "            for current_node in head_node.child.values():\n",
    "                _find(current_node, found)\n",
    "        return [i for i in found if not isinstance(i, DAGQubitNode)]\n",
    "\n",
    "    def layering(self) -> typing.List[Circuit]:\n",
    "        r\"\"\"\n",
    "        Layering the quantum circuit.\n",
    "\n",
    "        Returns:\n",
    "            List[:class:`~.core.circuit.Circuit`], a list of layered quantum circuit.\n",
    "\n",
    "        Examples:\n",
    "        from mindquantum.algorithm.compiler import DAGCircuit\n",
    "        from mindquantum.utils import random_circuit\n",
    "        circ = random_circuit(3, 5, seed=42)\n",
    "        circ\n",
    "                  ┏━━━━━━━━━━━━━┓   ┏━━━━━━━━━━━━━┓\n",
    "            q0: ──┨             ┠─╳─┨ RY(-6.1944) ┠───────────────────\n",
    "                  ┃             ┃ ┃ ┗━━━━━━┳━━━━━━┛\n",
    "                  ┃ Rxx(1.2171) ┃ ┃        ┃        ┏━━━━━━━━━━━━━┓\n",
    "            q1: ──┨             ┠─┃────────╂────────┨             ┠───\n",
    "                  ┗━━━━━━━━━━━━━┛ ┃        ┃        ┃             ┃\n",
    "                  ┏━━━━━━━━━━━━┓  ┃        ┃        ┃ Rzz(-0.552) ┃\n",
    "            q2: ──┨ PS(2.6147) ┠──╳────────■────────┨             ┠───\n",
    "                  ┗━━━━━━━━━━━━┛                    ┗━━━━━━━━━━━━━┛\n",
    "        dag_circ = DAGCircuit(circ)\n",
    "        for idx, c in enumerate(dag_circ.layering()):\n",
    "            ...     print(f\"layer {idx}:\")\n",
    "            ...     print(c)\n",
    "            layer 0:\n",
    "                  ┏━━━━━━━━━━━━━┓\n",
    "            q0: ──┨             ┠───\n",
    "                  ┃             ┃\n",
    "                  ┃ Rxx(1.2171) ┃\n",
    "            q1: ──┨             ┠───\n",
    "                  ┗━━━━━━━━━━━━━┛\n",
    "                  ┏━━━━━━━━━━━━┓\n",
    "            q2: ──┨ PS(2.6147) ┠────\n",
    "                  ┗━━━━━━━━━━━━┛\n",
    "            layer 1:\n",
    "            q0: ──╳───\n",
    "                  ┃\n",
    "                  ┃\n",
    "            q2: ──╳───\n",
    "            layer 2:\n",
    "                  ┏━━━━━━━━━━━━━┓\n",
    "            q0: ──┨ RY(-6.1944) ┠───\n",
    "                  ┗━━━━━━┳━━━━━━┛\n",
    "                         ┃\n",
    "            q2: ─────────■──────────\n",
    "            layer 3:\n",
    "                  ┏━━━━━━━━━━━━━┓\n",
    "            q1: ──┨             ┠───\n",
    "                  ┃             ┃\n",
    "                  ┃ Rzz(-0.552) ┃\n",
    "            q2: ──┨             ┠───\n",
    "                  ┗━━━━━━━━━━━━━┛\n",
    "        \"\"\"\n",
    "\n",
    "        def _layering(current_node: GateNode, depth_map):\n",
    "            \"\"\"Layering the quantum circuit.\"\"\"\n",
    "            if current_node.father:\n",
    "                prev_depth = []\n",
    "                for father_node in current_node.father.values():\n",
    "                    if father_node not in depth_map:\n",
    "                        _layering(father_node, depth_map)\n",
    "                    prev_depth.append(depth_map[father_node])\n",
    "                depth_map[current_node] = max(prev_depth) + 1\n",
    "            for child in current_node.child.values():\n",
    "                if not isinstance(child, DAGQubitNode):\n",
    "                    if child not in depth_map:\n",
    "                        _layering(child, depth_map)\n",
    "\n",
    "        depth_map = {i: 0 for i in self.head_node.values()}\n",
    "        for current_node in self.head_node.values():\n",
    "            _layering(current_node, depth_map)\n",
    "        layer = [Circuit() for _ in range(len(set(depth_map.values())) - 1)]\n",
    "        for k, v in depth_map.items():\n",
    "            if v != 0:\n",
    "                if not isinstance(k, BarrierNode):\n",
    "                    layer[v - 1] += k.gate\n",
    "        return [c for c in layer if len(c) != 0]\n",
    "\n",
    "    def to_circuit(self) -> Circuit:\n",
    "        \"\"\"\n",
    "        Convert :class:`~.algorithm.compiler.DAGCircuit` to quantum circuit.\n",
    "\n",
    "        Returns:\n",
    "            :class:`~.core.circuit.Circuit`, the quantum circuit of this DAG.\n",
    "\n",
    "        Examples:\n",
    "        from mindquantum.core.circuit import Circuit\n",
    "        from mindquantum.algorithm.compiler import DAGCircuit\n",
    "        circ = Circuit().h(0).h(1).x(1, 0)\n",
    "        circ\n",
    "                  ┏━━━┓\n",
    "            q0: ──┨ H ┠───■─────\n",
    "                  ┗━━━┛   ┃\n",
    "                  ┏━━━┓ ┏━┻━┓\n",
    "            q1: ──┨ H ┠─┨╺╋╸┠───\n",
    "                  ┗━━━┛ ┗━━━┛\n",
    "        dag_circ = DAGCircuit(circ)\n",
    "        dag_circ.to_circuit()\n",
    "                  ┏━━━┓\n",
    "            q0: ──┨ H ┠───■─────\n",
    "                  ┗━━━┛   ┃\n",
    "                  ┏━━━┓ ┏━┻━┓\n",
    "            q1: ──┨ H ┠─┨╺╋╸┠───\n",
    "                  ┗━━━┛ ┗━━━┛\n",
    "        \"\"\"\n",
    "        circuit = Circuit()\n",
    "        considered_node = set(self.head_node.values())\n",
    "\n",
    "        def adding_current_node(current_node, circuit, considered):\n",
    "            if all(i in considered for i in current_node.father.values()) and not isinstance(\n",
    "                current_node, DAGQubitNode\n",
    "            ):\n",
    "                circuit += current_node.gate\n",
    "                considered.add(current_node)\n",
    "            else:\n",
    "                for node in current_node.father.values():\n",
    "                    if node not in considered:\n",
    "                        adding_current_node(node, circuit, considered)\n",
    "                for node in current_node.child.values():\n",
    "                    if node not in considered:\n",
    "                        adding_current_node(node, circuit, considered)\n",
    "\n",
    "        for current_node in self.final_node.values():\n",
    "            adding_current_node(current_node, circuit, considered_node)\n",
    "        return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae099768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the neighboring vertices' information\n",
    "def get_info_neighbors(g):\n",
    "    info = {}\n",
    "    \n",
    "    n = len(g.nodes())  # The number of vertices in the current subgraph\n",
    "    # Iterate over neighboring vertices and store their information\n",
    "    for k in g.nodes():\n",
    "        # Store the neighbors of vertex k\n",
    "        neighbors = []\n",
    "        # Iterate through the edges\n",
    "        for u, v in g.edges:\n",
    "            if v == k:\n",
    "                neighbors.append(u)\n",
    "            if u == k:\n",
    "                neighbors.append(v)\n",
    "        # Store vertex k and its neighbors in the dictionary 'info'\n",
    "        info[k] = neighbors\n",
    "#     my_logger.info('Vertices and their neighboring vertices: {}'.format(info))\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad7737b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the initial state, here we choose the all-zero state\n",
    "def create_encoder():\n",
    "    encoder = Circuit()  # Initialize the quantum circuit\n",
    "    return encoder\n",
    "\n",
    "\n",
    "\n",
    "# Build the circuit U_H_D based on the target Hamiltonian, parameterized by gamma\n",
    "def build_U_HD(layer, target_graph):\n",
    "    # Initialize the quantum circuit\n",
    "    cir_HD = Circuit()\n",
    "    for v in target_graph.nodes:\n",
    "        cir_HD += RZ('gamma{}'.format(layer)).on(v)  # Apply the RZ gate with 'gamma' parameter to each vertex\n",
    "    return cir_HD\n",
    "\n",
    "\n",
    "# Build the circuit U_H_M based on the initial Hamiltonian, parameterized by beta\n",
    "def build_U_HM(layer, info):\n",
    "    \n",
    "    # Initialize a quantum circuit with n qubits\n",
    "    cir_HM = Circuit()\n",
    "    \n",
    "    for key, value in info.items():\n",
    "        \n",
    "        if len(value) != 0:\n",
    "            # Flip the state of the adjacent qubits\n",
    "            for i in range(0, len(value)):\n",
    "                cir_HM += X.on(value[i])  # Apply X gate to each neighboring qubit\n",
    "                \n",
    "\n",
    "            # Directly implement the multi-qubit controlled gate: the first qubit is the target, the second qubit is the control\n",
    "            cir_HM += RX('beta{}'.format(layer)).on(key, value)\n",
    "\n",
    "            # Flip the state of the adjacent qubits back to their original state\n",
    "            for i in range(0, len(value)):\n",
    "                cir_HM += X.on(value[i])\n",
    "            cir_HM.barrier()  # Add a barrier to separate operations\n",
    "        else:\n",
    "            # Directly flip, because this is an isolated node, it can be added directly to the vertex subset\n",
    "            cir_HM += RX('beta{}'.format(layer)).on(key)  # Apply RX gate to the isolated qubit\n",
    "            cir_HM.barrier()  # Add a barrier     \n",
    "        \n",
    "    return cir_HM\n",
    "\n",
    "\n",
    "\n",
    "# Build the p-layer QAOA circuit\n",
    "def build_ansatz(p, target_graph):\n",
    "    \n",
    "    # Prepare the initial state, any feasible solution will work\n",
    "    encoder = create_encoder()\n",
    "    \n",
    "    # Get the neighbors' information for building the circuit\n",
    "    info = get_info_neighbors(target_graph)\n",
    "    \n",
    "    # QAOA, p-layer ansatz: first build the circuit for the target Hamiltonian, then for the initial Hamiltonian\n",
    "    ansatz = Circuit()\n",
    "    for layer in range(1, p + 1):\n",
    "        ansatz += build_U_HD(layer, target_graph)  # Add the U_H_D part of the circuit\n",
    "        ansatz += build_U_HM(layer, info)  # Add the U_H_M part of the circuit\n",
    "        ansatz.barrier()  # Add a barrier to separate layers\n",
    "\n",
    "    return encoder, ansatz  # Return the encoder and ansatz circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d92b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a complete 1-layer QAOA+ ansatz\n",
    "def build_initial_PQC(target_graph):\n",
    "    \n",
    "    # Method 1: Apply the mixer to each vertex\n",
    "#     encoder, ansatz = build_ansatz(1, target_graph)\n",
    "#     circ = encoder + ansatz\n",
    "    \n",
    "#     allowed_applied_nodes = []\n",
    "#     for node in V:\n",
    "#         allowed_applied_nodes.append(node)\n",
    "\n",
    "#     # Method 2: Allocate mixers based on vertex degree. If the vertex degree is less than or equal to the average degree, a mixer is applied. Otherwise, no mixer is applied.\n",
    "#     m = len(E)\n",
    "#     avg_d = (2 * m) / len(V)\n",
    "#     layer = 1\n",
    "#     allowed_applied_nodes = []\n",
    "#     for node, values in info.items():\n",
    "#         d = len(info[node])  # Degree of the node\n",
    "#         if d < avg_d:\n",
    "#             allowed_applied_nodes.append(node)\n",
    "            \n",
    "#     # First, create the unitary operator corresponding to the target Hamiltonian\n",
    "#     circ = build_U_HD(1, target_graph)\n",
    "    \n",
    "#     # Then, create the unitary operator corresponding to the mixer Hamiltonian\n",
    "#     for node in allowed_applied_nodes:\n",
    "#         value = info[node]  # Get the neighboring nodes\n",
    "        \n",
    "#         # Apply the corresponding mixer to node\n",
    "#         if len(value) != 0:\n",
    "#             # Flip the state of the neighboring qubits\n",
    "#             for i in range(0, len(value)):\n",
    "#                 circ += X.on(value[i])\n",
    "                \n",
    "\n",
    "#             # Directly implement the multi-qubit controlled gate, with the first qubit as the target and the second qubit as the control\n",
    "#             circ += RX('beta{}'.format(layer)).on(node, value)\n",
    "\n",
    "#             # Flip the state of the neighboring qubits back\n",
    "#             for i in range(0, len(value)):\n",
    "#                 circ += X.on(value[i])\n",
    "                \n",
    "#             circ.barrier()\n",
    "#         else:\n",
    "#             # Directly flip because this is an isolated point and can be added directly to the vertex subset\n",
    "#             circ += RX('beta{}'.format(layer)).on(node)\n",
    "#             circ.barrier()  \n",
    "\n",
    "    # Method 3: Randomly allocate vertices\n",
    "    layer = 1\n",
    "    allowed_applied_nodes = []\n",
    "    # For a regular graph, randomly select t vertices, where t <= min{t1, t2}\n",
    "    t1 = n - k\n",
    "    t2 = int(n / 2)\n",
    "    if t1 > t2:\n",
    "        t = t2\n",
    "    else:\n",
    "        t = t1\n",
    "        \n",
    "   # Randomly select t vertices to apply the mixer\n",
    "    while len(allowed_applied_nodes) <= t:\n",
    "        node = random.randint(0, n - 1)\n",
    "        if node not in allowed_applied_nodes:\n",
    "            allowed_applied_nodes.append(node)\n",
    "    my_logger.info('The vertices where the mixer can be applied in the first layer: {}'.format(allowed_applied_nodes))\n",
    "            \n",
    "\n",
    "    # First, create the unitary operator corresponding to the target Hamiltonian\n",
    "    circ = build_U_HD(1, target_graph)\n",
    "\n",
    "    # Then, create the unitary operator corresponding to the mixer Hamiltonian\n",
    "    for node in allowed_applied_nodes:\n",
    "        value = info[node]  # Get the neighboring nodes\n",
    "\n",
    "        # Apply the corresponding mixer to node\n",
    "        if len(value) != 0:\n",
    "            # Flip the state of the neighboring qubits\n",
    "            for i in range(0, len(value)):\n",
    "                circ += X.on(value[i])\n",
    "\n",
    "\n",
    "            # Directly implement the multi-qubit controlled gate, with the first qubit as the target and the second qubit as the control\n",
    "            circ += RX('beta{}'.format(layer)).on(node, value)\n",
    "\n",
    "            # Flip the state of the neighboring qubits back\n",
    "            for i in range(0, len(value)):\n",
    "                circ += X.on(value[i])\n",
    "\n",
    "            circ.barrier()\n",
    "        else:\n",
    "            # Directly flip because this is an isolated point and can be added directly to the vertex subset\n",
    "            circ += RX('beta{}'.format(layer)).on(node)\n",
    "#             circ.barrier() \n",
    "\n",
    "    \n",
    "    return circ, allowed_applied_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7da64b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the latest circuit, where the latest circuit = the already optimized circuit + the latest operator\n",
    "# The list 'applied_nodes' stores the vertices where the mixer can be applied. Based on these vertices and the 'info' data, the latest circuit is constructed\n",
    "def build_latest_PQC(updated_pqc, layer, applied_nodes, info):\n",
    "    \n",
    "    # Build the latest circuit\n",
    "    \n",
    "    # Implement adaptive e^{-i \\beta H_{M}}\n",
    "    \n",
    "    for node in applied_nodes:\n",
    "        value = info[node]  # Get the neighboring nodes\n",
    "        \n",
    "        # Apply the corresponding mixer to node\n",
    "        if len(value) != 0:\n",
    "            # Flip the state of the neighboring qubits\n",
    "            for i in range(0, len(value)):\n",
    "                updated_pqc += X.on(value[i])  # Apply X gate to each neighboring qubit\n",
    "                \n",
    "\n",
    "            # Directly implement the multi-qubit controlled gate: the first qubit is the target, the second qubit is the control\n",
    "            updated_pqc += RX('beta{}'.format(layer)).on(node, value)\n",
    "\n",
    "            # Flip the state of the neighboring qubits back to their original state\n",
    "            for i in range(0, len(value)):\n",
    "                updated_pqc += X.on(value[i])\n",
    "\n",
    "            updated_pqc.barrier()  # Add a barrier to separate operations\n",
    "        else:\n",
    "            # Directly flip because this is an isolated point and can be added directly to the vertex subset\n",
    "            updated_pqc += RX('beta{}'.format(layer)).on(node)\n",
    "            updated_pqc.barrier()  # Add a barrier\n",
    "            \n",
    "    return updated_pqc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bee48c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_pm is the number of mixers in the current layer. The lists 'beta' and 'gamma' store the current circuit parameters (including newly added layers)\n",
    "def calculate_initial_expectation_value(circ, beta, gamma):\n",
    "    # Store the parameters, first store gamma, then store beta\n",
    "    params = []\n",
    "    for i in range(0, len(gamma)):\n",
    "        params.append(gamma[i])\n",
    "       \n",
    "    # The part corresponding to the mixer unitary operation: reuse the already optimized parameters for the first p-1 layers, and randomly initialize the p-th layer\n",
    "    for i in range(0, len(beta)):\n",
    "        params.append(beta[i]) \n",
    "    \n",
    "    # Convert the list to an array\n",
    "    sim = Simulator('projectq', circ.n_qubits)  # Create a simulator using the 'projectq' backend, capable of simulating up to 5 qubits (the number of qubits in 'circ')\n",
    "    \n",
    "    # Create a parameter resolver\n",
    "    pr = dict(zip(circ.params_name, params))\n",
    "\n",
    "    # Apply the circuit to the simulator\n",
    "    sim.apply_circuit(circ, pr=pr)\n",
    "#     print(sim.get_qs(True))\n",
    "\n",
    "    # Compute the expectation value of the Hamiltonian\n",
    "    expectation = sim.get_expectation(ham)\n",
    "    return -1 * (expectation.real)  # Return the negative of the real part of the expectation value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "661f785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MQAnsatzOnlyLayer(nn.Cell):\n",
    "    def __init__(self, expectation_with_grad,params, weight='normal'):\n",
    "        \"\"\"Initialize a MQAnsatzOnlyLayer object.\"\"\"\n",
    "        super().__init__()\n",
    "        self.evolution = MQAnsatzOnlyOps(expectation_with_grad)\n",
    "        weight_size = len(self.evolution.expectation_with_grad.ansatz_params_name)\n",
    "#         print('weight_size = {} '.format(weight_size))\n",
    "\n",
    "        if isinstance(weight, ms.Tensor):\n",
    "            if weight.ndim != 1 or weight.shape[0] != weight_size:\n",
    "                raise ValueError(f\"Weight init shape error, required ({weight_size}, ), but get f{weight.shape}.\")\n",
    "        \n",
    "        \n",
    "        self.weight =  Parameter(params.astype(np.float32), name='ansatz_weight')\n",
    "        my_logger.info('weight = {}'.format(self.weight.asnumpy()))\n",
    "        \n",
    "\n",
    "    def construct(self):\n",
    "        \"\"\"Construct a MQAnsatzOnlyLayer node.\"\"\"\n",
    "        return self.evolution(self.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3e40b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration stopping condition: convergence error\n",
    "def execute_function(target_graph, circuit, beta, gamma):\n",
    "#     my_logger.info('layer = {}, initial_beta = {}, initial_gamma = {}'.format(layer, beta, gamma))\n",
    "    lr = 0.05  # Learning rate\n",
    "    ITR = 600  # Maximum number of iterations\n",
    "    \n",
    "    # Store parameters, first store gamma, then store beta, params = [gamma1, beta1, gamma2, beta2, ...]\n",
    "    # Since only the first layer of the ansatz contains the unitary operator corresponding to H_C, params = [gamma1, beta1, beta2, ...]\n",
    "    params = []\n",
    "    for i in range(0, len(gamma)):\n",
    "        params.append(gamma[i])\n",
    "        \n",
    "    for i in range(0, len(beta)):\n",
    "        params.append(beta[i])\n",
    "    \n",
    "    my_logger.info('This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = {}' .format(params))\n",
    "    ms.set_context(mode=ms.PYNATIVE_MODE, device_target=\"CPU\")\n",
    "\n",
    "    # Convert the list to an array\n",
    "    params = np.array(params)\n",
    "    sim = Simulator('projectq', circuit.n_qubits)  # Create a simulator using the 'projectq' backend, capable of simulating 5 qubits (the number of qubits in 'circ')\n",
    "#     ham = build_ham(target_graph)\n",
    "    \n",
    "    grad_ops = sim.get_expectation_with_grad(ham, circuit)  # Get the operator to calculate the expectation value and gradient of the variational quantum circuit\n",
    "    QuantumNet = MQAnsatzOnlyLayer((grad_ops), params)\n",
    "    \n",
    "    opti = Adam(QuantumNet.trainable_params(), learning_rate=lr)  # The parameters to optimize are those in QuantumNet, with a learning rate of 0.05\n",
    "    train_net = nn.TrainOneStepCell(QuantumNet, opti)  # Perform one step of training on the neural network\n",
    "\n",
    "    my_logger.info('lr = {}, ITR = {}'.format(lr, ITR))\n",
    "    loss0 = []  # Store the changes in the expectation function value during training\n",
    "    for i in range(0, ITR + 1):\n",
    "        # train_net().asnumpy() returns an array, returning the optimized expectation value\n",
    "        loss = train_net().asnumpy()[0]  \n",
    "        loss0.append(loss)\n",
    "        \n",
    "        if i >= 2:\n",
    "            l = len(loss0)\n",
    "            delta1 = abs(loss0[l - 1] - loss0[l - 2])\n",
    "            delta2 = abs(loss0[l - 2] - loss0[l - 3])\n",
    "            if delta1 <= 0.001 and delta2 <= 0.001:\n",
    "                my_logger.info('Convergence condition met, iterations = {}, loss changes = {}'.format(len(loss0), loss0))\n",
    "                break\n",
    "            else:\n",
    "                # For Hamiltonian expectation values, train_net.asnumpy(), train_net() is a Tensor\n",
    "                if i % 50 == 0:\n",
    "                    my_logger.info(\"train_step = {}, loss = {}\".format(i, round(loss, 5)))  # Print the current training step and the expectation value every 50 steps  \n",
    "\n",
    "    consumed_iter = len(loss0)  # The number of iterations consumed for this optimization\n",
    "    my_logger.info('Number of iterations consumed in this optimization: {}'.format(consumed_iter))\n",
    "    \n",
    "    # Retrieve the optimized parameters\n",
    "    beta_opt = []\n",
    "    gamma_opt = []\n",
    "    params = []\n",
    "    \n",
    "    # Get the circuit parameters\n",
    "    pr = dict(zip(circuit.params_name, QuantumNet.weight.asnumpy()))  # Get the circuit parameters\n",
    "    for key, value in pr.items():\n",
    "        params.append(value)\n",
    "    my_logger.info('Optimized circuit parameters: {}'.format(params))\n",
    "    my_logger.info('\\n\\n')\n",
    "    \n",
    "    if len(beta) == 1:\n",
    "        for i in range(0, len(params)):\n",
    "            if i % 2 == 0:\n",
    "                gamma_opt.append(params[i])\n",
    "            else:\n",
    "                beta_opt.append(params[i])          \n",
    "    else:\n",
    "        for i in range(0, len(params)):\n",
    "            if i == 0:\n",
    "                gamma_opt.append(params[i])\n",
    "            else:\n",
    "                beta_opt.append(params[i])   \n",
    "                \n",
    "    # Measure the quantum bits\n",
    "    for i in target_graph.nodes():\n",
    "        circuit += Measure('q_{}'.format(i)).on(i)  # Apply a measurement on vertex i and name the measurement 'q_{i}'\n",
    "    \n",
    "    result = sim.sampling(circuit, pr=pr, shots=1000)  # Perform sampling with 1000 shots\n",
    "    \n",
    "    # Maximize the loss\n",
    "    return result, gamma_opt, beta_opt, -round(loss, 5), loss0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfd2496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_training(ham, g, circ, SEED, initial_beta, initial_gamma):\n",
    "    # Randomly initialize 2p circuit parameters\n",
    "    # Generate a random tensor with values uniformly distributed in the range [min, max), shape is 'shape', data type is 'dtype'\n",
    "    # minval and maxval are Tensor types\n",
    "    minval = Tensor(0, ms.float32)  # Set the minimum value for uniform distribution\n",
    "    maxval = Tensor(np.pi, ms.float32)  # Set the maximum value for uniform distribution\n",
    "    shape = tuple([1])  # Define the shape of the tensor\n",
    "    \n",
    "    # Randomly initialize the initial parameters for the latest layer of the ansatz\n",
    "    if len(initial_beta) == 0:\n",
    "        param = ops.uniform(shape, minval, maxval, seed=SEED, dtype=ms.float32)  # Generate uniform random values for beta\n",
    "        initial_beta.append(param.asnumpy()[0])\n",
    "\n",
    "        param = ops.uniform(shape, minval, maxval, seed=SEED, dtype=ms.float32)  # Generate uniform random values for gamma\n",
    "        initial_gamma.append(param.asnumpy()[0])\n",
    "        \n",
    "    else:\n",
    "        # Only add the unitary operator corresponding to H_C in the first layer of the ansatz,\n",
    "        # in subsequent layers, only add the unitary operators corresponding to the mixers\n",
    "        param = ops.uniform(shape, minval, maxval, seed=SEED, dtype=ms.float32)  # Generate uniform random values for beta\n",
    "        initial_beta.append(param.asnumpy()[0])\n",
    "        \n",
    "    my_logger.info('SEED = {}, initial_beta = {}, initial_gamma = {}'.format(SEED, initial_beta, initial_gamma))\n",
    "\n",
    "    # Parameter optimization\n",
    "    # Get the optimized beta_opt, gamma_opt\n",
    "    result, gamma_opt, beta_opt, loss, loss0 = execute_function(g, circ, initial_beta, initial_gamma)\n",
    "\n",
    "    return result, gamma_opt, beta_opt, loss, loss0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b878678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the max_loss and corresponding optimized parameters under a 1-layer QAOA+ ansatz using multiple global random initializations\n",
    "def search_optimized_parameters(circ, g):\n",
    "    \n",
    "    ham = build_ham(g)  # Generate the Hamiltonian   \n",
    "\n",
    "    value = []  # Store the expectation values corresponding to each initial parameter after optimization\n",
    "    params = []  # Store the optimized parameters\n",
    "    measure_result = []  # Store the measurement results\n",
    "    ITR = []  # Store the number of iterations consumed for each run\n",
    "    \n",
    "    my_logger.info('\\n\\n')\n",
    "\n",
    "    SEED = []\n",
    "    for k in range(0, counts):\n",
    "        seed = random.randint(1, 2500)  # Generate random seeds\n",
    "        SEED.append(seed)  \n",
    "    \n",
    "    for i in range(1, counts + 1):\n",
    "        initial_beta = []  # Initialize beta list\n",
    "        initial_gamma = []  # Initialize gamma list\n",
    "        temp_circuit = copy.deepcopy(circ)  # Create a copy of the circuit\n",
    "        my_logger.info('The {}-th global random initialization'.format(i))\n",
    "        result, gamma_opt, beta_opt, loss, loss0 = global_training(ham, g, temp_circuit, SEED[i - 1], initial_beta, initial_gamma)\n",
    "\n",
    "        value.append(loss)\n",
    "        params.append([beta_opt, gamma_opt])\n",
    "        measure_result.append(result.data)\n",
    "        ITR.append(len(loss0))\n",
    "    \n",
    "    my_logger.info('Global random initialization completed, outputting related information... ...')\n",
    "    my_logger.info('value = {}'.format(value))\n",
    "    my_logger.info('\\n\\n')\n",
    "\n",
    "    my_logger.info('params = [[beta_optimized, gamma_optimized], ...] = {}'.format(params))\n",
    "    my_logger.info('\\n\\n')\n",
    "\n",
    "    my_logger.info('measure_result = {}'.format(measure_result))\n",
    "    my_logger.info('\\n\\n')\n",
    "    \n",
    "    my_logger.info('consumed_iterations = {}'.format(ITR))\n",
    "    my_logger.info('\\n\\n')\n",
    "    \n",
    "    # Calculate the average expectation value\n",
    "    avg = 0\n",
    "    for index in range(0, len(value)):\n",
    "        avg += value[index]\n",
    "    avg = avg / len(value)\n",
    "    avg = round(avg, 5)\n",
    "    my_logger.info('avg_loss = {}'.format(avg))\n",
    "    \n",
    "    # Calculate the average number of iterations consumed\n",
    "    avg_iterations = 0\n",
    "    for j in range(0, len(ITR)):\n",
    "        avg_iterations += ITR[j]\n",
    "    avg_iterations = avg_iterations / len(ITR)\n",
    "    avg_iterations = round(avg_iterations, 5)\n",
    "    my_logger.info('Average iterations consumed by multiple random initializations: avg_iterations = {}'.format(avg_iterations))\n",
    "    \n",
    "    # Find the maximum expectation value obtained from multiple random initializations\n",
    "    max_loss = max(value)\n",
    "    my_logger.info('max_loss = {}'.format(max_loss))\n",
    "    params_opt = []  # Store the optimized parameters corresponding to max_loss\n",
    "    SEED_opt = []  # Store the seeds corresponding to max_loss\n",
    "\n",
    "    for j in range(0, len(value)):\n",
    "        if value[j] == max_loss:\n",
    "            params_opt.append(params[j])\n",
    "            SEED_opt.append(SEED[j])\n",
    "    my_logger.info('params_opt = {}'.format(params_opt))\n",
    "    my_logger.info('\\n')\n",
    "    my_logger.info('SEED_opt = {}'.format(SEED_opt))\n",
    "    return params_opt, max_loss, avg, value, avg_iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01b64d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the target Hamiltonian H_D, target function min C = -sum(x_i), where i = 0, 1...N-1, x_i takes values 0 or 1,\n",
    "# and x_i = 1 means the vertex is in the subset V'\n",
    "def build_ham(g):\n",
    "    ham = QubitOperator()  # Initialize the Hamiltonian\n",
    "    for i in g.nodes:\n",
    "        ham += QubitOperator(f'Z{i}', 0.5)  # Apply Z gate to each node with coefficient 0.5\n",
    "        ham += QubitOperator(f'Z{i} Z{i}', -0.5)  # Apply Z^2, corresponding to the identity operator (I)\n",
    "    ham = Hamiltonian(ham)  # Create Hamiltonian object\n",
    "    return ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e757f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient(circuit, beta, gamma, target_param_index):\n",
    "    \"\"\"\n",
    "    Calculate the gradient of the target function with respect to the specified parameter. \n",
    "    Since the added part each time is e^{-i \\beta H_{B}}, we only need to vary the beta parameter when calculating the gradient.\n",
    "    \n",
    "    Parameters:\n",
    "    - circuit: The current quantum circuit\n",
    "    - beta, gamma: The current circuit parameters\n",
    "    - target_param_index: The index of the target parameter, corresponding to the parameter number in beta or gamma\n",
    "    \n",
    "    Returns:\n",
    "    - grad: The gradient with respect to the specified parameter\n",
    "    \"\"\"\n",
    "    shift = np.pi / 2  # The shift value for the parameter, used to calculate the gradient\n",
    "    \n",
    "    # Create shifted parameters\n",
    "    shifted_beta_plus = beta.copy()\n",
    "    shifted_beta_minus = beta.copy()\n",
    "    \n",
    "    # Add and subtract shift at the target parameter position\n",
    "    shifted_beta_plus[target_param_index] += shift\n",
    "    shifted_beta_minus[target_param_index] -= shift\n",
    "#     print('beta = {}, shift_plus_beta = {}, shift_beta_minus = {}'.format(beta, shifted_beta_plus, shifted_beta_minus))\n",
    "    \n",
    "    # Compute the expectation values for the shifted parameters\n",
    "    expectation_plus = calculate_initial_expectation_value(circuit, shifted_beta_plus, gamma)\n",
    "    expectation_minus = calculate_initial_expectation_value(circuit, shifted_beta_minus, gamma)\n",
    "#     print('expectation_plus = {}, expectation_minus = {}'.format(expectation_plus, expectation_minus))\n",
    "    \n",
    "    # Calculate the gradient\n",
    "    grad = abs((expectation_plus - expectation_minus) / (2 * np.sin(shift)))\n",
    "    \n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "057c1449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the vertex to apply the mixer based on the average gradient and average initial expectation value\n",
    "def select_mixer_vertices_combined(updated_pqc, layer, updated_beta, updated_gamma, applied_nodes, num_initial_params=10):\n",
    "    \"\"\"\n",
    "    Select the vertex to apply the mixer based on the combined average gradient and average initial expectation value, \n",
    "    while ensuring the same initial parameters are used for each vertex during the computation.\n",
    "    \n",
    "    Parameters:\n",
    "    - updated_pqc: The current quantum circuit\n",
    "    - layer: The current layer number\n",
    "    - updated_beta, updated_gamma: The parameters of the current circuit\n",
    "    - applied_nodes: The vertices where the mixer has already been applied\n",
    "    - num_initial_params: The number of initial parameter sets used for averaging the calculations\n",
    "    \n",
    "    Returns:\n",
    "    - selected_node: The selected vertex\n",
    "    - max_score: The corresponding maximum score\n",
    "    \"\"\"\n",
    "    # Define the candidate pool of vertices\n",
    "    pool = [i for i in range(len(V)) if i not in applied_nodes]\n",
    "    avg_gradients = []\n",
    "    avg_initial_values = []\n",
    "    \n",
    "#     my_logger.info('The function named select_mixer_vertices_combined, updated_beta = {}, updated_gamma = {}'.format(updated_beta, updated_gamma))\n",
    "    \n",
    "    for node in pool:\n",
    "        temp_applied_nodes = applied_nodes + [node]  # Hypothetically apply the mixer at vertex\n",
    "        \n",
    "        function_values = []\n",
    "        gradients = []\n",
    "        \n",
    "        # For the current circuit, calculate the average gradient and average expectation value by applying the mixer at vertex 'node'\n",
    "        # Use the same initial parameter set for calculating average gradient and average expectation value\n",
    "        for k in range(0, num_initial_params):\n",
    "            \n",
    "            # Store the already optimized parameters; only add the unitary operator corresponding to the mixer for the new layer,\n",
    "            # and random parameters are added for initial_beta later on\n",
    "            initial_beta = []\n",
    "            initial_gamma = []\n",
    "            for k0 in range(0, len(updated_beta)):\n",
    "                initial_beta.append(updated_beta[k0])\n",
    "\n",
    "            for k0 in range(0, len(updated_gamma)):\n",
    "                initial_gamma.append(updated_gamma[k0])\n",
    "            \n",
    "            minval = Tensor(0, ms.float32)\n",
    "            maxval = Tensor(np.pi, ms.float32)\n",
    "            shape = tuple([1])\n",
    "\n",
    "            # Randomly initialize the initial parameters for the latest layer e^{-i \\beta H_{B}}\n",
    "            SEED = random.randint(1, 2500)\n",
    "            param = ops.uniform(shape, minval, maxval, seed=SEED, dtype=ms.float32)\n",
    "            initial_beta.append(param.asnumpy()[0])\n",
    "            \n",
    "            # Build the parameterized quantum circuit\n",
    "            circ = copy.deepcopy(updated_pqc)\n",
    "            \n",
    "            temp_circuit = build_latest_PQC(circ, layer, temp_applied_nodes, info)\n",
    "\n",
    "            # Calculate the initial expectation value and gradient\n",
    "            expectation_value = calculate_initial_expectation_value(temp_circuit, initial_beta, initial_gamma)\n",
    "            gradient = calculate_gradient(temp_circuit, initial_beta, initial_gamma, len(initial_beta)-1)\n",
    "\n",
    "            function_values.append(expectation_value)\n",
    "            gradients.append(gradient)\n",
    "\n",
    "        # Calculate the average initial expectation value and average gradient\n",
    "        avg_initial_value = np.mean(function_values)\n",
    "        avg_gradient = np.mean(gradients)\n",
    "#         print('node = {}, avg_gradient = {}'.format(node, avg_gradient))\n",
    "        \n",
    "        avg_initial_values.append(avg_initial_value)\n",
    "        avg_gradients.append(avg_gradient)\n",
    "\n",
    "    # Combine the average gradient and initial expectation value to select the vertex\n",
    "    # score = (1-weight)*avg_initial_value + weight * avg_gradient\n",
    "    weight = 1/3  # Adjustable weight coefficient\n",
    "    scores = [(1-weight)*iv + weight * grad for iv, grad in zip(avg_initial_values, avg_gradients)]\n",
    "    max_score = max(scores)\n",
    "    selected_node = pool[scores.index(max_score)]\n",
    "    \n",
    "    # Get the average gradient for the selected node\n",
    "    for t0 in range(0, len(scores)):\n",
    "        if scores[t0] == max_score:\n",
    "            avg_grad_allowed_node = avg_gradients[t0]\n",
    "    \n",
    "    return selected_node, max_score, avg_grad_allowed_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1095d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the adaptive ansatz circuit\n",
    "def adaptive_ansatz(SEED):\n",
    "    \n",
    "    # Track the number of oscillations during the optimization process\n",
    "    shock = 0  # Initialize shock count to 0  \n",
    "    \n",
    "    function_value = []  # Store the expectation function values obtained after parameter optimization for each layer\n",
    "    circuit_depth_layer = []  # Record the circuit depth corresponding to the ansatz circuit of each layer\n",
    "    mixer_nodes = []  # Store the vertices where the mixer is allowed to act for each layer (layer >= 1)\n",
    "    ITR = []  # Store the number of iterations consumed in each optimization round\n",
    "    layer = 1  # Initialize the layer for the circuit\n",
    "    circ, allowed_applied_nodes = build_initial_PQC(target_graph)  # Build the initial quantum circuit\n",
    "    mixer_nodes.append(allowed_applied_nodes)  # Store the vertices where the mixer is allowed to act in layer 1\n",
    "    temp_circuit = copy.deepcopy(circ)\n",
    "    \n",
    "    circuit_depth_layer.append(DAGCircuit(temp_circuit).depth())  # Record the circuit depth for layer 1\n",
    "\n",
    "    \n",
    "    # For layer = 1\n",
    "    # Store the initial parameters\n",
    "    initial_beta = []\n",
    "    initial_gamma = []\n",
    "    \n",
    "    # Perform parameter optimization; loss is the obtained expectation value, and the list loss0 stores the change in expectation values during optimization\n",
    "#     result, optimized_gamma, optimized_beta, loss, loss0 = global_training(ham, target_graph, temp_circuit, SEED, initial_beta, initial_gamma)\n",
    "    params_opt, max_loss, avg, value, avg_iterations = search_optimized_parameters(temp_circuit, target_graph)  # Multiple RI to find a set of parameters that maximize the expectation value for p=1\n",
    "    \n",
    "    # Get the optimized parameters corresponding to max_loss\n",
    "    optimized_beta = []\n",
    "    for k in range(0, len(params_opt[0][0])):\n",
    "        optimized_beta.append(params_opt[0][0][k])\n",
    "    \n",
    "    optimized_gamma = []\n",
    "    for k in range(0, len(params_opt[0][1])):\n",
    "        optimized_gamma.append(params_opt[0][1][k])\n",
    "    \n",
    "    function_value.append(max_loss)  # Store the expectation function value in this optimization round\n",
    "    ITR.append(avg_iterations * counts)  # Store the number of iterations consumed in this optimization round\n",
    "    \n",
    "    # 2-layer QAOA+ ansatz\n",
    "    layer = layer + 1\n",
    "    \n",
    "    if layer == 2:\n",
    "        allowed_applied_nodes0 = []  # Initialize an empty list to store the vertices where the mixer is allowed to act\n",
    "        \n",
    "        # Initialize parameters, reuse parameters from previous layers\n",
    "        initial_beta = []\n",
    "        initial_gamma = []\n",
    "        for t in range(0, len(optimized_beta)):\n",
    "            initial_beta.append(optimized_beta[t])\n",
    "            \n",
    "        for t in range(0, len(optimized_gamma)):\n",
    "            initial_gamma.append(optimized_gamma[t])\n",
    "        \n",
    "        # Select the first vertex where the mixer can be applied\n",
    "        # Return the allowed vertex and its corresponding average initial expectation value max_value\n",
    "#         circ += build_U_HD(layer, target_graph)  # Add unitary operation for the target Hamiltonian for this layer\n",
    "#         Based on the average initial expectation value selection\n",
    "#         allowed_node, max_value = select_mixer_vertices(circ, layer, optimized_beta, optimized_gamma, allowed_applied_nodes0)  # Get the vertex where the mixer is allowed to act\n",
    "        \n",
    "        # Combine average gradient and average initial expectation value to select the vertex\n",
    "        allowed_node, max_value, avg_grad_allowed_node = select_mixer_vertices_combined(circ, layer, optimized_beta, optimized_gamma, allowed_applied_nodes0, num_initial_params=10)\n",
    "        \n",
    "        allowed_applied_nodes0.append(allowed_node)\n",
    "        circ = build_latest_PQC(circ, layer, allowed_applied_nodes0, info)  # Build the updated quantum circuit\n",
    "        my_logger.info('max_avg_initial_value = {}'.format(max_value))\n",
    "        my_logger.info('The first selected vertex where the mixer is allowed to act is {}'.format(allowed_node))\n",
    "\n",
    "        # Based on the first selected vertex, determine the subsequent vertices where the mixer can act\n",
    "        # Continue adding the mixer if the current gradient or initial expectation value is not zero, or greater than the given threshold\n",
    "        while (len(allowed_applied_nodes0) <= int(len(V) / 3)) and avg_grad_allowed_node >= 0.15:\n",
    "            allowed_node, max_value, avg_grad_allowed_node = select_mixer_vertices_combined(circ, layer, optimized_beta, optimized_gamma, allowed_applied_nodes0, num_initial_params=10)  # Get the next vertex for the mixer\n",
    "#             my_logger.info('Based on the first selected vertex, the subsequent selected vertex is {}'.format(allowed_node))\n",
    "            allowed_applied_nodes0.append(allowed_node)\n",
    "            circ = build_latest_PQC(circ, layer, allowed_applied_nodes0, info)  # Build the updated quantum circuit\n",
    "        temp_circuit = copy.deepcopy(circ)\n",
    "        \n",
    "        circuit_depth_layer.append(DAGCircuit(temp_circuit).depth())  # Record the circuit depth for layer 2\n",
    "        \n",
    "        my_logger.info('Vertices where the mixer is allowed to act in layer 2: {}'.format(allowed_applied_nodes0))\n",
    "\n",
    "        # Once no more mixers can be added, perform circuit optimization\n",
    "        result, optimized_gamma, optimized_beta, loss, loss0 = global_training(ham, target_graph, temp_circuit, SEED, initial_beta, initial_gamma)\n",
    "        \n",
    "        # If the obtained expectation value from optimization is less than the maximum expectation value from previous optimization, count it as an oscillation\n",
    "        if loss < max(function_value) - (2 * delta):\n",
    "            shock += 1  \n",
    "        function_value.append(loss)  # Store the expectation function value in this optimization round\n",
    "        ITR.append(len(loss0))  # Store the number of iterations consumed in this optimization round\n",
    "        mixer_nodes.append(allowed_applied_nodes0)  # Store the vertices where the mixer is allowed to act in this layer\n",
    "    \n",
    "    # layer = 3\n",
    "    layer = layer + 1\n",
    "#     circ += build_U_HD(layer, target_graph)  # Add unitary operation for the target Hamiltonian for this layer\n",
    "    \n",
    "    if layer == 3:\n",
    "        applied_nodes = []  # Initialize an empty list to store the vertices where the mixer is allowed to act before performing adaptive operations\n",
    "        # Initialize parameters, reuse parameters from previous layers\n",
    "        initial_beta = []\n",
    "        initial_gamma = []\n",
    "        for t in range(0, len(optimized_beta)):\n",
    "            initial_beta.append(optimized_beta[t])\n",
    "            \n",
    "        for t in range(0, len(optimized_gamma)):\n",
    "            initial_gamma.append(optimized_gamma[t])\n",
    "\n",
    "        # max_value is the initial expectation value when the mixer is applied to the vertex applied_node\n",
    "#         applied_node, max_value = select_mixer_vertices(circ, layer, optimized_beta, optimized_gamma, applied_nodes)  # Get the vertex where the mixer is allowed to act\n",
    "        \n",
    "        # Combine average gradient and average initial expectation value to select the vertex\n",
    "        applied_node, max_value, avg_grad_allowed_node = select_mixer_vertices_combined(circ, layer, optimized_beta, optimized_gamma, applied_nodes, num_initial_params=10)\n",
    "        \n",
    "        ITR.append(len(loss0))  # Store the number of iterations consumed in this optimization round\n",
    "        applied_nodes.append(applied_node)\n",
    "        circ = build_latest_PQC(circ, layer, applied_nodes, info)  # Build the updated quantum circuit\n",
    "        my_logger.info('max_avg_initial_value = {}'.format(max_value))\n",
    "        my_logger.info('The first selected vertex where the mixer is allowed to act is {}'.format(applied_node))\n",
    "\n",
    "        # Continue adding the mixer if the current gradient or initial expectation value is not zero, or greater than the given threshold\n",
    "        while (len(applied_nodes) <= int(len(V) / 2)) and avg_grad_allowed_node >= 0.20:\n",
    "            applied_node, max_value, avg_grad_allowed_node = select_mixer_vertices_combined(circ, layer, optimized_beta, optimized_gamma, applied_nodes, num_initial_params=10)  # Get the next vertex for the mixer\n",
    "            applied_nodes.append(applied_node)\n",
    "            circ = build_latest_PQC(circ, layer, applied_nodes, info)  # Build the updated quantum circuit\n",
    "        temp_circuit = copy.deepcopy(circ)\n",
    "        \n",
    "        circuit_depth_layer.append(DAGCircuit(temp_circuit).depth())  # Record the circuit depth for layer 3\n",
    "\n",
    "        # Once no more mixers can be added, perform circuit optimization\n",
    "        my_logger.info('Vertices where the mixer is allowed to act in layer 3: {}'.format(applied_nodes))\n",
    "        \n",
    "        result, optimized_gamma, optimized_beta, loss, loss0 = global_training(ham, target_graph, temp_circuit, SEED, initial_beta, initial_gamma)\n",
    "        # If the obtained expectation value from optimization is less than the maximum expectation value from previous optimization, count it as an oscillation\n",
    "        if loss < max(function_value) - (2 * delta):\n",
    "            shock += 1  \n",
    "        \n",
    "        function_value.append(loss)  # Store the expectation function value in this optimization round\n",
    "        ITR.append(len(loss0))  # Store the number of iterations consumed in this optimization round\n",
    "        mixer_nodes.append(applied_nodes)  # Store the vertices where the mixer is allowed to act in this layer\n",
    "    \n",
    "    # Based on the change in the expectation function value across three consecutive rounds of optimization, decide whether to continue increasing the ansatz layers\n",
    "    while layer >= 3:\n",
    "        layer_depth = len(function_value)  # The number of completed optimization rounds\n",
    "        delta1 = abs(function_value[layer_depth - 1] - function_value[layer_depth - 2])\n",
    "        delta2 = abs(function_value[layer_depth - 2] - function_value[layer_depth - 3])\n",
    "        \n",
    "        # First exit condition (when the expectation function value fluctuates repeatedly and is difficult to improve, avoid excessive iterations based on shock count threshold)\n",
    "        if shock >= 3:\n",
    "            my_logger.info('Shock count shock = {}, it is recommended to stop'.format(shock))\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # Second exit condition: maximum steps reached\n",
    "            if layer > len(V):\n",
    "                my_logger.info('Ansatz layer exceeds graph size, algorithm terminates')\n",
    "                break\n",
    "            else:\n",
    "            \n",
    "                # Third exit condition: minimal improvement in expectation value from increasing ansatz layers\n",
    "                if delta1 <= delta and delta2 <= delta:\n",
    "                    my_logger.info('Increase in ansatz layers results in minimal change in expectation function value, algorithm terminates')\n",
    "                    break\n",
    "                else:\n",
    "                    layer = layer + 1\n",
    "        #             circ += build_U_HD(layer, target_graph)  # Add unitary operation for the target Hamiltonian for this layer\n",
    "                    applied_nodes = []  # Initialize an empty list before performing adaptive operations\n",
    "\n",
    "                    # Initialize parameters, reuse parameters from previous layers\n",
    "                    initial_beta = []\n",
    "                    initial_gamma = []\n",
    "                    for t in range(0, len(optimized_beta)):\n",
    "                        initial_beta.append(optimized_beta[t])\n",
    "\n",
    "                    for t in range(0, len(optimized_gamma)):\n",
    "                        initial_gamma.append(optimized_gamma[t])\n",
    "\n",
    "                    # max_value is the initial expectation value when the mixer is applied to the vertex applied_node\n",
    "#                     applied_node, max_value = select_mixer_vertices(circ, layer, optimized_beta, optimized_gamma, applied_nodes)  # Get the vertex where the mixer is allowed to act\n",
    "                    \n",
    "                    # Combine average gradient and average initial expectation value to select the vertex\n",
    "                    applied_node, max_value, avg_grad_allowed_node = select_mixer_vertices_combined(circ, layer, optimized_beta, optimized_gamma, applied_nodes, num_initial_params=10)\n",
    "                    \n",
    "                    applied_nodes.append(applied_node)\n",
    "                    circ = build_latest_PQC(circ, layer, applied_nodes, info)  # Build the updated quantum circuit\n",
    "                    my_logger.info('max_avg_initial_value = {}'.format(max_value))\n",
    "                    my_logger.info('The first selected vertex where the mixer is allowed to act is {}'.format(allowed_node))\n",
    "\n",
    "                    # Continue adding the mixer if the current gradient is not zero, or the number of allowed mixers to be added is smaller than the limit\n",
    "                    while (len(applied_nodes) <= int(len(V) / 4)) and avg_grad_allowed_node >= 0.25:\n",
    "                        applied_node, max_value, avg_grad_allowed_node = select_mixer_vertices_combined(circ, layer, optimized_beta, optimized_gamma, applied_nodes, num_initial_params=10)  # Get the next vertex for the mixer\n",
    "                        applied_nodes.append(applied_node)\n",
    "                        circ = build_latest_PQC(circ, layer, applied_nodes, info)  # Build the updated quantum circuit\n",
    "                    temp_circuit = copy.deepcopy(circ)\n",
    "                    circuit_depth_layer.append(DAGCircuit(temp_circuit).depth())  # Record the circuit depth for this layer\n",
    "\n",
    "                    # Once no more mixers can be added, perform circuit optimization\n",
    "                    my_logger.info('Vertices where the mixer is allowed to act in layer {}: {}'.format(layer, applied_nodes))\n",
    "                    result, optimized_gamma, optimized_beta, loss, loss0 = global_training(ham, target_graph, temp_circuit, SEED, initial_beta, initial_gamma)\n",
    "                    \n",
    "                    # If the obtained expectation value from optimization is less than the maximum expectation value from previous optimization, count it as an oscillation\n",
    "                    if loss < max(function_value) - (2 * delta):\n",
    "                        shock += 1 \n",
    "                    \n",
    "                    \n",
    "                    function_value.append(loss)  # Store the expectation function value in this optimization round\n",
    "                    ITR.append(len(loss0))  # Store the number of iterations consumed in this optimization round\n",
    "                    mixer_nodes.append(applied_nodes)  # Store the vertices where the mixer is allowed to act in this layer  \n",
    "                    \n",
    "            \n",
    "    my_logger.info('In this run, the expectation function value changes as follows: function_value = {}'.format(function_value))\n",
    "    my_logger.info('In this run, the vertices where the mixer is allowed to act are: mixer_nodes = {}'.format(mixer_nodes))\n",
    "    # Return the expectation function values and the vertices where the mixer is allowed to act after each optimization round in the adaptive ansatz construction\n",
    "    return function_value, mixer_nodes, ITR, circuit_depth_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d8dca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 Erdős–Rényi graphs with 8 vertices, probability = 0.5\n",
    "# E0 = [[(0, 3), (0, 5), (1, 2), (1, 3), (1, 4), (1, 6), (2, 3), (2, 5), (2, 7), (5, 7), (6, 7)], [(0, 1), (0, 2), (0, 3), (0, 4), (0, 7), (1, 3), (1, 4), (1, 5), (1, 7), (2, 3), (2, 6), (3, 4), (3, 5), (4, 7), (5, 6), (5, 7)], [(0, 1), (0, 5), (0, 6), (0, 7), (1, 2), (1, 3), (1, 5), (2, 6), (2, 7), (3, 4), (3, 5), (4, 5), (5, 6), (6, 7)], [(0, 1), (0, 2), (0, 4), (0, 6), (0, 7), (1, 4), (1, 5), (1, 7), (2, 3), (2, 5), (2, 6), (2, 7), (3, 5), (4, 6), (5, 6), (5, 7)], [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (1, 7), (2, 4), (3, 4), (4, 5), (4, 6), (5, 6), (5, 7), (6, 7)], [(0, 1), (0, 3), (0, 4), (0, 7), (1, 2), (1, 3), (1, 4), (1, 5), (2, 4), (3, 4), (4, 5), (5, 7), (6, 7)], [(0, 1), (0, 3), (0, 6), (1, 2), (1, 4), (1, 6), (1, 7), (2, 4), (2, 6), (2, 7), (3, 5), (3, 6), (4, 7)], [(0, 1), (0, 2), (0, 6), (0, 7), (1, 6), (1, 7), (2, 4), (2, 5), (2, 7), (3, 4), (3, 5), (3, 6), (4, 6), (4, 7), (6, 7)], [(0, 2), (0, 4), (0, 7), (1, 3), (1, 5), (2, 5), (2, 6), (3, 5), (3, 6), (3, 7), (4, 5), (5, 6), (5, 7)], [(0, 1), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (1, 5), (1, 6), (2, 4), (2, 5), (3, 4), (3, 5), (3, 6), (3, 7), (4, 7), (5, 7)], [(0, 2), (0, 3), (1, 3), (1, 4), (1, 6), (2, 3), (2, 4), (2, 6), (3, 5), (3, 7), (4, 5), (4, 6), (4, 7)], [(0, 3), (0, 4), (0, 5), (0, 6), (1, 2), (1, 3), (1, 4), (2, 3), (2, 5), (2, 6), (3, 5), (3, 6), (6, 7)], [(0, 1), (0, 2), (0, 3), (0, 5), (1, 2), (1, 6), (2, 4), (2, 5), (2, 7), (3, 6), (4, 5), (4, 7), (5, 7)], [(0, 1), (0, 2), (0, 6), (1, 2), (1, 4), (2, 7), (3, 6), (4, 6), (5, 6), (5, 7)], [(0, 1), (0, 3), (0, 6), (1, 2), (1, 3), (1, 6), (1, 7), (2, 3), (2, 5), (2, 7), (4, 7), (6, 7)], [(0, 2), (0, 4), (0, 6), (1, 2), (1, 4), (1, 5), (1, 7), (2, 4), (2, 5), (2, 6), (3, 4), (4, 5), (4, 6), (4, 7), (5, 6), (6, 7)], [(0, 1), (0, 6), (1, 2), (1, 3), (2, 6), (2, 7), (3, 4), (3, 6), (4, 5), (4, 6), (4, 7), (5, 7)], [(0, 2), (0, 4), (0, 5), (0, 6), (0, 7), (1, 3), (1, 4), (2, 4), (2, 6), (3, 5), (4, 5), (5, 6)], [(0, 2), (1, 2), (1, 4), (1, 6), (2, 6), (2, 7), (3, 4), (3, 5), (3, 7), (4, 5), (4, 6), (4, 7), (5, 6), (6, 7)], [(0, 2), (0, 3), (0, 4), (0, 7), (1, 2), (1, 3), (1, 5), (2, 4), (2, 6), (3, 4), (3, 6), (3, 7), (4, 6), (4, 7), (5, 6), (5, 7)]]\n",
    "\n",
    "# 20 3-regular graphs with 8 vertices\n",
    "E0 = [[(1, 2), (1, 4), (1, 6), (2, 5), (2, 0), (4, 6), (4, 3), (6, 5), (5, 7), (7, 0), (7, 3), (0, 3)], [(2, 7), (2, 3), (2, 0), (7, 4), (7, 6), (0, 1), (0, 5), (1, 4), (1, 6), (4, 3), (6, 5), (5, 3)], [(2, 7), (2, 1), (2, 4), (7, 6), (7, 3), (1, 5), (1, 6), (6, 5), (5, 0), (0, 4), (0, 3), (4, 3)], [(2, 7), (2, 6), (2, 0), (7, 4), (7, 0), (0, 1), (1, 3), (1, 4), (4, 5), (6, 5), (6, 3), (3, 5)], [(0, 1), (0, 6), (0, 3), (1, 2), (1, 3), (2, 7), (2, 4), (7, 5), (7, 3), (4, 6), (4, 5), (6, 5)], [(1, 2), (1, 3), (1, 4), (2, 6), (2, 3), (4, 7), (4, 5), (7, 6), (7, 5), (3, 0), (6, 0), (5, 0)], [(1, 2), (1, 3), (1, 4), (2, 6), (2, 4), (6, 7), (6, 0), (7, 5), (7, 3), (3, 0), (4, 5), (5, 0)], [(2, 7), (2, 5), (2, 0), (7, 4), (7, 3), (0, 1), (0, 4), (1, 3), (1, 6), (4, 6), (3, 5), (6, 5)], [(1, 2), (1, 0), (1, 7), (2, 6), (2, 0), (0, 5), (6, 7), (6, 4), (7, 3), (4, 5), (4, 3), (5, 3)], [(1, 3), (1, 5), (1, 7), (3, 2), (3, 7), (6, 7), (6, 4), (6, 5), (4, 0), (4, 2), (5, 0), (0, 2)], [(1, 2), (1, 4), (1, 6), (2, 6), (2, 5), (4, 7), (4, 3), (7, 6), (7, 0), (0, 3), (0, 5), (3, 5)], [(1, 3), (1, 6), (1, 7), (3, 2), (3, 0), (4, 6), (4, 5), (4, 2), (6, 0), (5, 7), (5, 2), (7, 0)], [(2, 7), (2, 5), (2, 4), (7, 0), (7, 3), (0, 1), (0, 6), (1, 3), (1, 5), (3, 6), (4, 6), (4, 5)], [(0, 1), (0, 2), (0, 7), (1, 6), (1, 7), (4, 7), (4, 3), (4, 2), (5, 6), (5, 2), (5, 3), (6, 3)], [(1, 2), (1, 3), (1, 4), (2, 6), (2, 4), (4, 7), (7, 6), (7, 0), (3, 0), (3, 5), (6, 5), (5, 0)], [(1, 3), (1, 4), (1, 7), (3, 2), (3, 5), (6, 7), (6, 5), (6, 0), (7, 0), (5, 2), (4, 0), (4, 2)], [(1, 2), (1, 3), (1, 5), (2, 7), (2, 6), (7, 4), (7, 0), (4, 6), (4, 0), (3, 6), (3, 5), (0, 5)], [(0, 1), (0, 7), (0, 6), (1, 5), (1, 6), (4, 7), (4, 3), (4, 2), (7, 5), (2, 6), (2, 3), (5, 3)], [(4, 7), (4, 1), (4, 0), (7, 1), (7, 3), (5, 6), (5, 0), (5, 2), (6, 1), (6, 3), (2, 3), (2, 0)], [(2, 7), (2, 1), (2, 3), (7, 0), (7, 3), (1, 5), (1, 6), (4, 6), (4, 5), (4, 0), (6, 5), (0, 3)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fee290da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 Erdős–Rényi graphs with 10 vertices, probability = 0.5\n",
    "# E0 = [[(0, 2), (0, 3), (0, 5), (1, 2), (1, 5), (1, 6), (1, 7), (1, 8), (2, 3), (2, 4), (2, 5), (2, 6), (4, 5), (4, 6), (5, 6), (6, 7), (6, 9), (7, 8)], [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 7), (0, 8), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (2, 3), (2, 6), (2, 7), (2, 8), (3, 5), (4, 6), (4, 7), (4, 8), (4, 9), (5, 6), (5, 9), (6, 9), (8, 9)], [(0, 1), (0, 3), (0, 4), (0, 5), (0, 6), (1, 2), (1, 5), (1, 9), (2, 6), (3, 7), (4, 6), (4, 8), (5, 8), (5, 9), (6, 8), (7, 9), (8, 9)], [(0, 3), (0, 4), (0, 5), (0, 7), (0, 8), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (2, 6), (2, 9), (3, 4), (3, 5), (3, 6), (3, 8), (4, 8), (4, 9), (5, 7), (6, 7), (6, 9), (7, 8), (8, 9)], [(0, 2), (0, 4), (0, 5), (0, 7), (1, 7), (1, 9), (2, 4), (2, 7), (2, 8), (3, 8), (4, 8), (4, 9), (6, 8), (8, 9)], [(0, 2), (0, 4), (0, 5), (0, 6), (0, 9), (1, 3), (1, 4), (1, 6), (2, 3), (2, 4), (2, 5), (2, 7), (2, 8), (2, 9), (3, 4), (3, 5), (3, 6), (3, 9), (4, 6), (4, 7), (4, 8), (5, 6), (6, 8), (7, 8), (7, 9)], [(0, 1), (0, 4), (0, 5), (0, 8), (0, 9), (1, 5), (1, 9), (2, 7), (2, 8), (3, 5), (3, 8), (3, 9), (4, 5), (4, 6), (4, 8), (5, 7), (5, 8), (6, 7), (6, 9)], [(0, 1), (0, 3), (0, 5), (0, 9), (1, 4), (1, 7), (1, 8), (2, 3), (2, 6), (2, 7), (2, 8), (2, 9), (3, 6), (3, 7), (3, 9), (4, 5), (4, 6), (4, 7), (4, 9), (5, 7), (6, 7), (6, 8), (7, 9), (8, 9)], [(0, 1), (0, 2), (0, 3), (0, 4), (1, 3), (1, 4), (1, 5), (1, 6), (2, 4), (2, 5), (2, 9), (3, 4), (3, 8), (4, 8), (6, 7), (6, 9), (7, 8)], [(0, 1), (0, 5), (0, 6), (0, 9), (1, 2), (1, 7), (1, 8), (1, 9), (2, 4), (2, 7), (2, 8), (2, 9), (3, 4), (3, 6), (3, 8), (3, 9), (4, 5), (4, 7), (5, 9), (6, 8), (6, 9), (7, 8), (7, 9), (8, 9)], [(0, 2), (0, 5), (0, 8), (1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5), (2, 6), (2, 8), (3, 5), (3, 7), (4, 5), (4, 6), (4, 7), (5, 6), (5, 8), (5, 9), (6, 7), (6, 8)], [(0, 2), (0, 4), (0, 6), (0, 7), (0, 8), (1, 2), (1, 3), (1, 8), (1, 9), (2, 6), (2, 7), (2, 8), (3, 6), (3, 8), (4, 6), (4, 8), (4, 9), (5, 8), (5, 9), (6, 7), (6, 8), (6, 9), (7, 8), (8, 9)], [(0, 1), (0, 5), (0, 7), (1, 2), (1, 5), (1, 6), (1, 7), (1, 9), (2, 3), (2, 4), (2, 5), (2, 9), (3, 4), (3, 6), (3, 7), (3, 8), (4, 6), (4, 7), (5, 8), (5, 9), (6, 8)], [(0, 1), (0, 5), (0, 7), (1, 2), (1, 5), (1, 6), (1, 7), (1, 9), (2, 3), (2, 4), (2, 5), (2, 9), (3, 4), (3, 6), (3, 7), (3, 8), (4, 6), (4, 7), (5, 8), (5, 9), (6, 8)], [(0, 1), (0, 4), (0, 6), (1, 2), (1, 3), (1, 4), (1, 7), (1, 9), (3, 7), (4, 5), (4, 6), (4, 7), (4, 8), (4, 9), (5, 6), (6, 7), (7, 8), (7, 9), (8, 9)], [(0, 3), (0, 4), (0, 6), (1, 2), (1, 6), (1, 7), (1, 9), (2, 5), (2, 7), (2, 8), (2, 9), (3, 4), (3, 8), (4, 6), (4, 7), (4, 9), (5, 6), (5, 8), (6, 7), (6, 8), (6, 9), (8, 9)], [(0, 3), (0, 4), (0, 5), (0, 7), (0, 9), (1, 2), (1, 3), (1, 7), (1, 9), (2, 3), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (3, 4), (3, 5), (3, 7), (4, 6), (5, 7), (5, 8), (5, 9), (6, 8), (7, 8), (7, 9), (8, 9)], [(0, 1), (0, 2), (0, 5), (0, 7), (0, 8), (0, 9), (1, 2), (1, 7), (1, 8), (2, 4), (2, 5), (2, 7), (3, 5), (3, 7), (3, 8), (3, 9), (4, 6), (4, 7), (5, 6), (5, 8), (5, 9), (6, 8), (6, 9)], [(0, 5), (0, 9), (1, 5), (1, 7), (1, 9), (2, 5), (3, 5), (3, 7), (3, 8), (4, 5), (4, 6), (4, 7), (4, 8), (6, 7)], [(0, 4), (0, 5), (1, 2), (1, 4), (1, 5), (1, 6), (1, 8), (2, 4), (2, 5), (2, 7), (3, 4), (3, 5), (3, 6), (3, 9), (4, 6), (4, 7), (5, 6), (5, 7), (5, 8), (6, 8), (7, 8), (7, 9), (8, 9)]]\n",
    "\n",
    "# 20 3-regular graphs with 10 vertices\n",
    "# E0 = [[(1, 2), (1, 5), (1, 8), (2, 6), (2, 5), (6, 4), (6, 3), (4, 3), (4, 0), (0, 7), (0, 9), (7, 8), (7, 9), (5, 8), (3, 9)], [(2, 7), (2, 8), (2, 0), (7, 1), (7, 3), (4, 9), (4, 6), (4, 5), (9, 8), (9, 1), (6, 5), (6, 0), (5, 1), (8, 3), (0, 3)], [(6, 7), (6, 5), (6, 3), (7, 0), (7, 8), (4, 9), (4, 1), (4, 0), (9, 2), (9, 0), (2, 3), (2, 5), (5, 1), (1, 8), (3, 8)], [(2, 7), (2, 4), (2, 0), (7, 4), (7, 9), (0, 1), (0, 5), (1, 5), (1, 6), (4, 8), (8, 9), (8, 3), (5, 6), (6, 3), (9, 3)], [(1, 2), (1, 0), (1, 8), (2, 9), (2, 4), (0, 7), (0, 8), (6, 9), (6, 5), (6, 3), (9, 7), (4, 8), (4, 5), (5, 3), (7, 3)], [(0, 1), (0, 5), (0, 4), (1, 3), (1, 9), (7, 8), (7, 6), (7, 4), (8, 2), (8, 3), (6, 9), (6, 5), (9, 2), (3, 4), (2, 5)], [(5, 9), (5, 0), (5, 2), (9, 3), (9, 0), (4, 7), (4, 8), (4, 1), (7, 6), (7, 1), (2, 6), (2, 0), (6, 3), (8, 3), (8, 1)], [(0, 1), (0, 9), (0, 3), (1, 2), (1, 4), (2, 8), (2, 4), (6, 9), (6, 4), (6, 5), (9, 7), (5, 7), (5, 8), (8, 3), (7, 3)], [(2, 7), (2, 6), (2, 0), (7, 4), (7, 8), (5, 9), (5, 0), (5, 8), (9, 4), (9, 0), (4, 3), (1, 3), (1, 8), (1, 6), (3, 6)], [(1, 2), (1, 3), (1, 4), (2, 6), (2, 5), (7, 8), (7, 6), (7, 3), (8, 9), (8, 0), (6, 9), (9, 0), (3, 4), (4, 5), (5, 0)], [(0, 1), (0, 3), (0, 8), (1, 5), (1, 6), (6, 9), (6, 5), (9, 8), (9, 7), (4, 7), (4, 5), (4, 2), (7, 3), (2, 8), (2, 3)], [(2, 7), (2, 6), (2, 3), (7, 3), (7, 8), (0, 1), (0, 5), (0, 9), (1, 4), (1, 9), (6, 9), (6, 4), (4, 8), (8, 5), (5, 3)], [(5, 9), (5, 6), (5, 7), (9, 8), (9, 3), (4, 6), (4, 1), (4, 0), (6, 1), (2, 8), (2, 3), (2, 0), (8, 7), (7, 1), (3, 0)], [(2, 7), (2, 1), (2, 8), (7, 5), (7, 0), (5, 9), (5, 6), (9, 6), (9, 3), (1, 3), (1, 8), (3, 0), (6, 4), (4, 8), (4, 0)], [(6, 9), (6, 2), (6, 1), (9, 8), (9, 3), (2, 5), (2, 3), (4, 7), (4, 8), (4, 0), (7, 5), (7, 1), (8, 1), (5, 0), (0, 3)], [(1, 2), (1, 3), (1, 4), (2, 6), (2, 9), (5, 9), (5, 4), (5, 0), (9, 8), (6, 8), (6, 3), (3, 7), (8, 7), (4, 0), (0, 7)], [(1, 2), (1, 6), (1, 7), (2, 6), (2, 0), (6, 9), (9, 4), (9, 8), (4, 0), (4, 3), (5, 7), (5, 8), (5, 3), (7, 0), (3, 8)], [(5, 9), (5, 0), (5, 3), (9, 6), (9, 2), (6, 7), (6, 0), (7, 0), (7, 1), (2, 8), (2, 4), (8, 3), (8, 1), (1, 4), (4, 3)], [(4, 7), (4, 9), (4, 0), (7, 6), (7, 1), (1, 3), (1, 6), (3, 8), (3, 5), (6, 0), (9, 2), (9, 0), (2, 8), (2, 5), (8, 5)], [(1, 2), (1, 9), (1, 7), (2, 3), (2, 4), (6, 9), (6, 7), (6, 3), (9, 4), (4, 5), (7, 8), (5, 0), (5, 8), (3, 0), (0, 8)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acd65f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 Erdős–Rényi graphs with 12 vertices, probability = 0.5\n",
    "# E0 = [[(0, 1), (0, 3), (0, 6), (0, 7), (0, 10), (0, 11), (1, 6), (1, 8), (1, 10), (2, 3), (2, 4), (2, 10), (2, 11), (3, 7), (3, 8), (3, 9), (4, 6), (4, 9), (4, 10), (5, 6), (5, 8), (5, 11), (6, 11), (7, 8), (7, 11), (8, 9), (8, 10), (8, 11), (9, 10), (9, 11), (10, 11)], [(0, 1), (0, 2), (0, 3), (0, 5), (0, 6), (0, 7), (0, 8), (0, 10), (0, 11), (1, 2), (1, 5), (1, 6), (1, 7), (1, 8), (2, 6), (2, 7), (2, 9), (2, 11), (3, 4), (3, 5), (3, 6), (3, 9), (3, 10), (3, 11), (4, 6), (4, 9), (5, 6), (5, 7), (5, 8), (5, 10), (5, 11), (6, 9), (7, 8), (7, 9), (7, 10), (7, 11), (8, 9), (8, 11)], [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 9), (0, 10), (0, 11), (1, 2), (1, 3), (1, 5), (1, 6), (1, 9), (1, 10), (1, 11), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (3, 5), (3, 6), (3, 11), (4, 5), (5, 6), (5, 8), (5, 9), (5, 11), (6, 7), (6, 8), (6, 10), (6, 11), (7, 10), (7, 11), (8, 10), (8, 11), (9, 10), (9, 11), (10, 11)], [(0, 5), (0, 6), (0, 7), (0, 8), (0, 10), (0, 11), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 9), (1, 11), (2, 4), (2, 5), (2, 7), (2, 9), (2, 10), (2, 11), (3, 5), (3, 8), (3, 11), (4, 6), (4, 7), (4, 8), (4, 10), (4, 11), (5, 7), (5, 8), (5, 9), (6, 8), (6, 9), (6, 10), (7, 8), (7, 9), (7, 10), (7, 11), (8, 11)], [(0, 1), (0, 2), (0, 4), (0, 7), (0, 8), (0, 11), (1, 6), (1, 7), (1, 8), (1, 9), (1, 11), (2, 5), (2, 6), (2, 7), (3, 4), (3, 8), (3, 9), (4, 5), (4, 6), (4, 7), (4, 8), (4, 9), (4, 11), (5, 7), (5, 8), (5, 10), (6, 10), (6, 11), (7, 8), (8, 9), (9, 10)], [(0, 2), (0, 3), (0, 4), (0, 6), (0, 7), (0, 8), (0, 11), (1, 4), (1, 6), (2, 7), (3, 7), (3, 8), (3, 9), (4, 5), (4, 9), (4, 11), (5, 6), (5, 10), (6, 7), (6, 9), (6, 10), (6, 11), (7, 8), (10, 11)], [(0, 1), (0, 2), (0, 3), (0, 6), (0, 11), (1, 2), (1, 5), (1, 6), (1, 8), (1, 9), (1, 10), (2, 4), (2, 6), (2, 9), (3, 5), (3, 7), (3, 8), (3, 10), (4, 5), (4, 10), (4, 11), (5, 7), (6, 7), (6, 8), (6, 9), (7, 8), (7, 10), (8, 10), (8, 11), (10, 11)], [(0, 2), (0, 7), (0, 10), (0, 11), (1, 2), (1, 5), (1, 7), (1, 10), (1, 11), (2, 5), (3, 6), (3, 9), (3, 10), (3, 11), (4, 5), (4, 7), (4, 8), (4, 9), (4, 10), (5, 8), (5, 9), (6, 11), (7, 8), (7, 10), (8, 9), (8, 10), (9, 11)], [(0, 1), (0, 2), (0, 3), (0, 5), (0, 6), (0, 7), (1, 2), (1, 4), (1, 7), (1, 8), (2, 3), (2, 8), (2, 10), (2, 11), (3, 8), (3, 11), (4, 5), (4, 7), (4, 9), (5, 7), (5, 10), (5, 11), (6, 10), (9, 11), (10, 11)], [(0, 1), (0, 3), (0, 4), (0, 5), (0, 6), (0, 9), (0, 11), (1, 5), (1, 6), (1, 8), (1, 9), (1, 10), (1, 11), (2, 5), (2, 7), (2, 10), (3, 4), (3, 5), (3, 6), (3, 7), (3, 10), (4, 8), (4, 9), (4, 10), (4, 11), (5, 6), (6, 7), (6, 8), (6, 9), (6, 11), (7, 8), (7, 9), (7, 10), (7, 11), (8, 10), (9, 10)], [(0, 1), (0, 3), (0, 5), (0, 6), (0, 7), (0, 9), (0, 11), (1, 7), (1, 9), (1, 11), (2, 5), (2, 7), (2, 8), (2, 9), (2, 10), (3, 10), (3, 11), (4, 6), (4, 7), (4, 8), (4, 11), (5, 6), (5, 10), (7, 9), (9, 10), (10, 11)], [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 9), (0, 10), (0, 11), (1, 4), (1, 7), (1, 9), (1, 11), (2, 6), (2, 7), (2, 9), (2, 11), (4, 5), (4, 7), (4, 8), (4, 11), (5, 7), (5, 10), (5, 11), (6, 11), (7, 9), (7, 10), (7, 11), (8, 11), (9, 10), (9, 11)], [(0, 1), (0, 2), (0, 6), (0, 8), (0, 9), (0, 10), (0, 11), (1, 2), (1, 3), (1, 4), (1, 6), (1, 8), (1, 9), (1, 10), (1, 11), (2, 4), (2, 10), (2, 11), (3, 5), (3, 6), (3, 7), (3, 9), (3, 10), (3, 11), (4, 5), (5, 9), (5, 11), (6, 10), (7, 9), (7, 10), (9, 10), (9, 11), (10, 11)], [(0, 1), (0, 2), (0, 3), (0, 4), (0, 6), (0, 10), (0, 11), (1, 5), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (2, 4), (2, 8), (2, 11), (3, 4), (3, 10), (3, 11), (4, 5), (4, 6), (4, 9), (4, 10), (4, 11), (5, 7), (5, 9), (5, 11), (6, 7), (6, 9), (6, 10), (6, 11), (7, 10), (8, 10), (9, 10), (9, 11), (10, 11)], [(0, 3), (0, 6), (0, 8), (0, 10), (0, 11), (1, 4), (1, 5), (1, 6), (1, 9), (1, 11), (2, 6), (2, 7), (2, 9), (2, 11), (3, 5), (3, 6), (3, 7), (3, 8), (3, 11), (4, 6), (4, 7), (4, 8), (4, 11), (5, 6), (5, 7), (5, 10), (6, 8), (6, 10), (7, 9), (8, 9), (8, 10), (8, 11), (9, 11)], [(0, 1), (0, 2), (0, 5), (0, 8), (0, 9), (0, 10), (0, 11), (1, 3), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (2, 3), (2, 9), (2, 10), (3, 5), (3, 7), (3, 9), (3, 10), (5, 7), (5, 10), (5, 11), (6, 7), (6, 10), (7, 10), (8, 11), (9, 10), (9, 11)], [(0, 1), (0, 3), (0, 4), (0, 5), (0, 7), (0, 8), (0, 9), (1, 3), (1, 4), (1, 7), (1, 8), (1, 9), (1, 10), (2, 4), (2, 5), (2, 6), (2, 9), (2, 10), (3, 8), (3, 9), (3, 10), (3, 11), (4, 5), (4, 7), (4, 9), (4, 10), (5, 9), (5, 11), (7, 9), (7, 10), (7, 11), (10, 11)], [(0, 1), (0, 4), (0, 6), (0, 7), (0, 8), (0, 10), (0, 11), (1, 2), (1, 3), (1, 4), (1, 8), (1, 9), (2, 4), (2, 5), (2, 7), (2, 11), (3, 7), (3, 8), (3, 9), (3, 10), (4, 6), (4, 7), (4, 8), (4, 9), (4, 10), (5, 6), (5, 8), (5, 10), (6, 7), (6, 8), (6, 10), (6, 11), (7, 8), (7, 9), (7, 10), (8, 10), (9, 11)], [(0, 1), (0, 3), (0, 4), (0, 5), (0, 8), (0, 9), (0, 11), (1, 3), (1, 8), (2, 3), (2, 4), (2, 6), (2, 9), (2, 10), (2, 11), (3, 8), (3, 11), (4, 6), (4, 10), (4, 11), (5, 7), (5, 8), (5, 9), (5, 10), (5, 11), (6, 8), (6, 11), (7, 8), (7, 9), (9, 10), (10, 11)], [(0, 1), (0, 2), (0, 3), (0, 9), (1, 5), (1, 6), (1, 7), (1, 8), (1, 10), (1, 11), (2, 3), (2, 4), (2, 5), (2, 7), (2, 8), (2, 9), (2, 10), (3, 4), (3, 6), (3, 9), (3, 10), (4, 5), (4, 8), (4, 9), (4, 10), (5, 7), (5, 10), (5, 11), (6, 7), (6, 9), (6, 11), (7, 10), (8, 9), (8, 10), (8, 11)]]\n",
    "\n",
    "# 20 3-regular graphs with 12 vertices\n",
    "# beta = [5, 5, 5, 6, 5,    6, 5, 5, 5, 5,    5, 5, 5, 5, 5,   5, 5, 5, 5, 5]\n",
    "# E0 = [[(0, 1), (0, 11), (0, 9), (1, 3), (1, 9), (5, 9), (5, 10), (5, 2), (4, 7), (4, 8), (4, 3), (7, 10), (7, 11), (2, 6), (2, 10), (6, 8), (6, 11), (3, 8)], [(2, 7), (2, 9), (2, 11), (7, 10), (7, 8), (4, 10), (4, 5), (4, 1), (10, 5), (6, 9), (6, 5), (6, 0), (9, 0), (11, 3), (11, 1), (3, 8), (3, 0), (1, 8)], [(0, 1), (0, 10), (0, 3), (1, 4), (1, 5), (2, 6), (2, 9), (2, 3), (6, 7), (6, 5), (7, 10), (7, 8), (4, 9), (4, 11), (9, 10), (5, 8), (8, 11), (11, 3)], [(0, 1), (0, 10), (0, 8), (1, 4), (1, 5), (6, 9), (6, 2), (6, 7), (9, 10), (9, 3), (2, 8), (2, 10), (7, 3), (7, 11), (5, 11), (5, 3), (11, 4), (4, 8)], [(1, 2), (1, 5), (1, 11), (2, 10), (2, 3), (5, 9), (5, 7), (9, 8), (9, 3), (4, 6), (4, 3), (4, 11), (6, 11), (6, 0), (7, 10), (7, 8), (10, 0), (8, 0)], [(4, 10), (4, 5), (4, 1), (10, 11), (10, 7), (5, 9), (5, 1), (9, 2), (9, 3), (6, 7), (6, 11), (6, 0), (7, 3), (11, 2), (2, 8), (8, 1), (8, 0), (0, 3)], [(1, 2), (1, 3), (1, 9), (2, 9), (2, 3), (4, 10), (4, 5), (4, 0), (10, 11), (10, 0), (3, 8), (11, 9), (11, 7), (6, 7), (6, 8), (6, 0), (7, 5), (8, 5)], [(0, 1), (0, 5), (0, 2), (1, 5), (1, 10), (4, 7), (4, 6), (4, 8), (7, 8), (7, 9), (6, 5), (6, 11), (8, 11), (11, 9), (3, 10), (3, 2), (3, 9), (10, 2)], [(1, 2), (1, 8), (1, 7), (2, 9), (2, 4), (5, 9), (5, 7), (5, 3), (9, 11), (10, 11), (10, 8), (10, 0), (11, 6), (6, 0), (6, 3), (7, 8), (0, 4), (4, 3)], [(0, 1), (0, 10), (0, 3), (1, 4), (1, 6), (5, 9), (5, 4), (5, 7), (9, 3), (9, 7), (4, 10), (10, 11), (6, 7), (6, 8), (11, 8), (11, 2), (8, 2), (2, 3)], [(2, 7), (2, 6), (2, 0), (7, 0), (7, 10), (4, 10), (4, 1), (4, 3), (10, 1), (6, 8), (6, 5), (8, 3), (8, 5), (5, 11), (11, 0), (11, 9), (1, 9), (3, 9)], [(1, 2), (1, 0), (1, 9), (2, 11), (2, 3), (4, 10), (4, 8), (4, 0), (10, 5), (10, 9), (0, 8), (5, 7), (5, 3), (6, 7), (6, 8), (6, 3), (7, 11), (11, 9)], [(5, 9), (5, 8), (5, 3), (9, 4), (9, 7), (2, 6), (2, 10), (2, 4), (6, 8), (6, 10), (4, 1), (10, 11), (11, 3), (11, 0), (8, 1), (7, 0), (7, 1), (3, 0)], [(4, 10), (4, 9), (4, 5), (10, 5), (10, 8), (5, 0), (6, 7), (6, 3), (6, 1), (7, 1), (7, 11), (9, 2), (9, 1), (2, 11), (2, 0), (8, 11), (8, 3), (3, 0)], [(1, 2), (1, 3), (1, 8), (2, 8), (2, 10), (5, 9), (5, 7), (5, 3), (9, 10), (9, 3), (4, 7), (4, 6), (4, 11), (7, 6), (6, 0), (8, 11), (11, 0), (10, 0)], [(2, 7), (2, 6), (2, 9), (7, 4), (7, 0), (4, 8), (4, 11), (6, 5), (6, 10), (1, 3), (1, 10), (1, 9), (3, 10), (3, 8), (9, 0), (8, 11), (5, 11), (5, 0)], [(2, 7), (2, 6), (2, 0), (7, 10), (7, 9), (3, 5), (3, 11), (3, 9), (5, 4), (5, 1), (6, 10), (6, 0), (4, 8), (4, 1), (8, 11), (8, 9), (11, 1), (10, 0)], [(4, 10), (4, 6), (4, 1), (10, 5), (10, 3), (1, 3), (1, 9), (3, 8), (5, 0), (5, 2), (6, 8), (6, 11), (8, 7), (11, 2), (11, 9), (2, 0), (0, 7), (7, 9)], [(2, 7), (2, 6), (2, 3), (7, 6), (7, 9), (3, 5), (3, 8), (5, 10), (5, 11), (6, 0), (10, 11), (10, 1), (11, 0), (4, 8), (4, 9), (4, 1), (8, 1), (9, 0)], [(4, 10), (4, 1), (4, 3), (10, 8), (10, 2), (5, 9), (5, 6), (5, 7), (9, 0), (9, 3), (1, 3), (1, 11), (2, 6), (2, 0), (6, 7), (7, 11), (0, 8), (8, 11)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffa75ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1sklEQVR4nO2dd3gc1dWH3yNZlnvBgDEYECVgeiDYdBxTPooIhFBSaKYYCAkGDAEEoSSBCAgQSqimd0IIJEFA6KaZ3jHVRKYbbGzcVc/3x7mLCpa1ZXZmd33e59nnsWdn515Jd3575txTRFVxHMdx4qEs6Qk4juMsTbjoOo7jxIiLruM4Toy46DqO48SIi67jOE6MuOg6juPEiIuu4zhOjLjoOo7jxIiLruM4Toy46DqO48SIi67jOE6MuOg6juPEiIuu4zhOjLjoOo7jxIiLruM4Toy46DqO48SIi67jOE6MuOg6juPEiIuu4zhOjLjoOo7jxIiLruM4Toy46DqO48SIi67jOE6MuOg6juPEiIuu4zhOjLjoOo7jxIiLruM4Toz0SHoCjpMOVTV1g4AtgE2B0cBKQE+gEfgMmAS8BEyur62encwsHad7RFWTnoPjdElVTd2mwPHAT4EGoA9QsZhTm4AFQCVwL3BBfW31S/HM0nHSx0XXKUiqauqGA7cAIzEhLc/g4y2YQL8AHFBfW/1p9DN0nOxw0XUKiqqaOgHGApdi7oPFWbXp0oS5H44GbqivrfbF7iSOi65TMATBvRAYB/SN8NLzgYnABBdeJ2l8I80pCPIouITrjQv/Pi7iaztORnjImFMojCU/gpuiLzCuqqbu4Dxd33HSwt0LTuKETbN3yZ/gtmceMKK+tvqzGMZynO/hlq5TCNyCbZrFQWUYz3ESwUXXSZSqmrqRWFhYLlEKmVABjArxv44TO76R5iTNBMz6XCLbjVie6g2GsdHwQSzXv5IeZcKnsxby2LvTufLJj/h2YVMmY1aGcX+V5ZwdJ2vcp+skRkjt/QLo1d25Nx48ktFrLb/Y9z7+ZgHVlzzF3IbmTIZfBAzzlGEnbty94CTJFljmWLc0Nrdy0+R6qi99irVPe4CfXv4Mn89eCMAqy/Rh35ErZzp2A7B5ph9ynFxx94KTJJuSZsTCsXe+xvzGlu/+/9ons7n+2XpO3XUdAFZfNuPAhz5h/Acz/aDj5IJbuk6SjCbNL/72gpuiskfb8v189qJMx64AfpzphxwnV1x0nSRZKdsPLte/koO2WBWABY3N/PPVrGrarJjt+I6TLS66TpJkFZs7bGAvbj9sc5br34uWVuX4u17ni28ztnQhjagJx4ka9+k6SdKY6QfWWK4vNx2yGSsN6k1TSyvH3/U6D7z1Zbbjp7WJ5zhR4qLrJMlnwIh0T95gpYHcMHYkQ/pVsqCxmaNue4Un3vs6l/E/z+XDjpMN7l5wkmQSVvO2W7ZYfQi3HbYZQ/pV8s38Rva75vmcBFe1taW1qeGZrC/gOFniyRFOYlTV1O0C3A4M7O7cO8ZtzuarD+ny/ec+mskvJj6X9tgti+Yz49/nNS366OWngYfD61VV/X6YhONEiLsXEsCbLH7HZBLazCrr0VMbPnu3BzAmvP4MfCMijxJEWFXrk5hbFPgaK1zc0o0Rb7L4fapq6m4H9iGzHmi50gL8fdo5u40HtgN2DK9VO503lTYr+DFVnR3jHLPC11jh46IbA95ksWuqauo21dbWp6SsrNv6CxGyANi2vrb65dQBERFgDdoEeDs6uj1agRdpE+HnVDXj6It84WuseHDRzSPeZHHJiEhf4E9Df1l7XM/hIygrj6W6YxPwTH1t9Zhu5tYDezTfARPhLenojpuPPaKnRHiKJnAz+RorPlx084Q3WVwyIrI99nOsVt5/SMtKR1zTKj0q4lDdrDpHiEg/zDeasoTX7XTK58AjmAA/qqpfRDDXJeJrrDjxjbQ84E0Wu0ZEBgF/AQ4Lh15vmTvzUOlRsSFmreWzZc98YHw2rXpUdR5QF16IyEqYFZyyhFcEDgwvROQt2qzgJ1V1fhQ/QApfY8WLx+nmh7F4k8XvISJ7AFMwwW0ETgVGqurLwA2YdRWpOLVjPjCxvrb6+igupqqfqeqNqnoAMAzYENvAehBYCKyPCdb9WFTE4yJyioiMFJEoNg3H4musKHH3QsR4k8XvIyJDgUuAfcOhycChqvpO+/NK5XFZRCoxH3DKCt4UkHanzAIeoy007aNMru9rrLhxSzd6vMliQIz9Met2X8LjPbBNZ8EFCII4AdvImUea2Wpd0drSjGrrAuDo+trq4+LyT6pqg6o+rqqnquooYFksLO5q4H/AYGAv4EpgqohMFZErRWQvERmcxhC+xooYt3QjJDRZfAKLjYyLBcDoQouxFJFVMFHZJRx6GDg83YSDYM3dDIwiixAobW6k4bP3ymc+cMmk5tlfjEkisqArRGQN2qzg7YFB7d5uBV6mzR/8bPvQNF9jxY9vpEVLWk0WNxw+kKPHrMmIFQawTN+eVJSXMWtBI699MpurnpzKKx/PzmTMgmqyKCJlwBHAeUA/YDbm27wxE+ELsaJjQrD/BGBP0g/2v6fhs3evn377KXdgEQf7YwJeEKjqVCzx4qrg3/0RbVERW2KxtiOBU4AFIvJdaNoqJ/1nQnBfpMUyfXty9Jg12XiVQawzbACVPey76/R/v8VNk6ele5mCWmPFjlu6EZFJk8W9NxnO+ftstNj3mlpa2fvKZ3n9028zGb4gmiyKyFrANcA24dA/gd+oata1F1OE3+/mmH/0x1i0QCUmxJ9j1t9LwHOp34OIHIRt0M0E1lHVnEqSxUEITduWNkt4/e/eq+zL8KNvpqxH+p6FdYcN4P7x23zveIaiCwWyxkoBt3SjI9VksVvR/d/M+fzuH68zeepMvprbwMrL9OHCfTdio+GDqCgvY48frpSp6KaaLCbS7yskEkwA/oD9/NMxsb07qjHCzf5geJ2V5sduwqzcHbANugOimk++CKFp94cXIjKMIMC9Vl6/WpubliED0Z2zsIlrnv6I1z6ezearD2H/zTtnOqdNomuslPCNtOhIu8niy9NmcdfLn/Lp7IU0trQy9et5/POVts3hppbWTMdONVmMHRHZCHgeOBcT3BuBdaMU3GwJ7owjsRCu/UVkp4SnlDGq+oWq3qyqBy631+8vKqvsk1Gf+U9nL+Ssune4780vmDEvp5rtia2xUsNFNzrSbrLYnvIyYc3l+/GzTaxd2NxFTdz1csap77E3WRSRXiJyFvZIvwnwMbCzqo5V1W/inMuSCP7TM8N/rwypx0WJiIwOTxVJ4I08I8LdC9GRcZPFp08cw/DBbZvQ0+cs4vCbX+LDr+ZlPHjjjI+3F5EkHfSrAA9a3ZiCpQqYV+Bz7JJh466g55CVk5yCN/KMALd0oyPnuMmhA3px/dhRjFihf8aflXiKxTgJImWJ20jeyDMCXHSjI+Myf1uf9zhrnno/213wBHVvWn2UZfr25Pgd18p48IrBw95RVcnXC/g/oD4M14IV/e6dzzHz8DNcEOb/GtAz6flk+qoYPOzdjBdGtHgjzwhw0Y2OrNIkm1uVj2bM57LHP/zu2GrL9svmUnlpsigig0XkOuAh7PH8VWBTtWyrrPqeJ8gZ2BfHD7Foi2Ij6VRcb+QZAS660ZF2k8XTqtdhx3WGMmxgLyrKhZUH9+bI0at/9/60bzKr+aKtLbrwo5dni0ikPjcR+RmWwnswZuXUAJup6mtRjhMXapW+jgj/PVNE1kxyPlmQ9hpLIQKD+1QwuE8FvSrakvr6VJR/dzxNmrBYaCdHEncSlRAvYRlR3TZZ3Gm9FTh069UX+978hmYufvSDjAZubVwkc178117AXiIyhbYU0kkh7jMjRGQF4G9YfQCAp4HDVPW9TK9VaKjqQyJyMxaze5WI7BBCy4qBtNdYipUG9ubpk7b73vGTd1mHk3dZB4Cqmrp0LrUgjO/kiFu60ZF2k8Xbnv+YF+u/4eu5DTQ2t7KwsYWpX83j1uenUX3pU7yRWWIEZT17NTdOn/oQVlBmXeAY4D6spOAkEfm9iGzWXUnBUKDmIMy63QsrOvNbYHQpCG47JgAzsJY8Y5OdSkYk1sgzjJt+u2WnSzwNOEKSbLJYX1v9KxHpiWUNpfL4R9Lxi3U28DhtlvDUlJUnIqsCVwGpBIIHgSNVNaNc0WJBRPbDqmfNwlKEpyc8pbRIeo3FOGbJ4pZutFxA/Du8DWFcVLVRVZ9U1dNUdXOspGCqhOCHWDWrPYHLgQ+Aj0TkahG5FngbE9xvsO4Hu5aq4AZuA/6LlVm8KNmpZESia8zJHbd0I6aqpu5xYCtyaxCYFq0tzbTMnTH18ysPW1tVW7o7X0SqaLOCtweW6XTKLKwa17+AZ1S1pEOEwu/jbSzFdTdVTcu5mTRxrjHSbOTppI9butFzAFnE7GZFSxPTbzlpDeBZEVm/u9NVtV5VJwL7YQVgUjvhjUAzZvWNBx4FZonIgyJyvIhsKMWaxrUE1Gr7nhb+e4WIZJ6VkgzxrTGzcvePaaylAhfdiAl1YI8mf72+Usxf+NErF7fMm/kZVuj7FRE5I/h1u0RENgZewCp1VQDXAStgO+I7Y4+RbwC9MXfD+cDrwJcicquIjA1NGUuFS7Bd+ZVJv3pZosS5xsiykafTNS66+eEGYmiy+PU9fz4WWA/bAKvACru8LCKjOn8gFKipBV7EkgPqgR1V9VBVnaWqC1T1v6p6gqpuhAnx/ljVsM+B5bEi1tcDn4rIFBG5WER2KyIL8XuoajPWKLMFOFpENkt4SulyA0XUyNNpw0U3D7Tr9ZWPm+K7JosAqvqtqh4JjME2y9YHJovIBSLSB0BEtsas1ZOxv/lFwAaq+khXg6jqdFW9VVXHAsPpGIo2D1gHc0X8BwtNe0pETheRLRKshJUVqvo6ZtELMLG7p4VCIM415kSLb6TlkdDddiz2CFtJbhsfTZh/bXxX1kcQ2TOxVuBlWBPE14GfhlPewbrwTs5hHohIBR1D00bR8Qv8WzqGpn1Y6AkIItIbeBNYA/i9qp6d8JTSIso11trSDC1NNH5df/qXN53wp4im6HTCRTcGcm2yiIntC8D+6fjXRGRT4O/AauGQAn8BTs9HRIKIDMJqraZE+AedTvmYNgF+VFVnRD2HKBCR7bBNxAZgQ1V9P+EppU0Ua6xxxsezv7rjtBVb5s18AdgynYgYJ3NcdGMk2yaLwIXpdmIVkSFYZMKB4ZBij82fY8kO/8nlZ0hzDqvSMTRtSLu3FSuakxLhZwqpcE4o7nMwVudgO1XNuI1HkuSyxqads9v7WDbiSsAxqnpJLJNeynDRTYBsmix2Rwjp2gu4DNv0WgScjiUAXA2kNojuAMZrTE0aQ3fgH9ImwlvTMZV1EfAUbSL8RpJCJyLLYG6Y5bGW8ROTmksuZLvGRGR3LE57PrBeiSfIJIKLbgkQmhdehlk3AE8C41KPx6HmwtHA2ZjlMxPbBLs9bl9r8DtvTZsId26L/DXwCEGEVTXj3kW5IiI/x76cvsVShL+Iew5JIiJ3AXtjzTF3K3R/fLHholvEBOt2LOZOGATMBU4Erl6ctSgiq2NW7/bhUB3wa1X9JI75Lg4RWT7MJyXCwzud8h5tVvATqjonhjkJFpVRDfxDVffJ95iFRPgSfweL3f6lqt6R8JRKChfdIkVEVsMEdIdw6H7MZ7tEAQ2CcjAm1APpRqjjJMxtbdoE+MdA+xjgFqzSVUqEX1TVjOrLZjCXVbAU4X7AT1X1X/kYp1ARkcOwsLGvMWt/ZsJTKhlcdIuM4Cr4DVBLm6vgGOC2TB4DQ8Hzy4E9wqFJmEsis2K+eSSEpo2iTYQ3o+Ou/Fw6hqa9H+WjsIiMBy7GOjasG4eVXSiEL8DHsS7XN6jqwQlPqWRw0S0iRGRd4Bpgi3DoDmyX+assryeY7+5vdNx8+2vI1CooRGQgHUPTOjeT+4SOoWk5bRaGL7hnMLG/XFV/k8v1ig0RWQtLCa8EdlDVRxOeUkngolsEBIvvJKw4S09s9/nXqvrviK4/BPgrVkgFbFf7UFV9I4rr54vgAtgBE+AdsFKW7XmNNhF+WlUXZjHGBsArmIW9tao+m8uciw0ROQXbgJ2KxS4vSHhKRY+LboEjIj/CitJsGA5NBE5U1dl5GGsXrI7DyljVsVrg7GIo8RhC0zaizQreho6haQ10DE17PV0ftoicBZyKbS5tXAy/j6gIX/gvAxsA56nqSQlPqehx0S1QQlrqmcAJWIrtR5jP9bE8jzsAE9ujwqFIUofjJvz+tqJNhDfudMoMLPssFZr28RKu1QtLp14LOFNV/5CXSRcooQjQZKAVGKmqryY8paLGRbcAEZFtMd/tD7CFfhFwWpyPdiKyDXBtmINiuf2nho66RYeILEfH0LSVO53yPh1D077t9PnRWEJBI/BDVX0n33MuJETkYiy2+2Vg80L0+RcLLroFRLAyzwF+HQ69jVmZzyc0n97YxtrvMJ9mPWZtd1mdrBgIG4hr0eYPHgMMaHdKC/A8bUkaz6tqk4hcDYzDNte2TTrELk5C+c63gFWAE1TV2/dkiYtugSAiu2L+1OFYXvyfgT+ralwdArok+JWvpS177Drg+Hz4lZMglKJsH5q2Od8PTXsCa0V/ArAccJSqXhHvTJMlrNE6rGbD+qr6v4SnVJS46CaMiCyLuQ/2C4dexKzbNxOb1GIIGyq/A87AIii+wITn3iTnlQ/CE8ePabOERyzmtCbgOOCubEP2ihERuR34BfAQsLOnCGeOi25ChEfcfYFLMctpIRYSdlEhl9QTkXUwqzcVK3wXcHSxtDDPBhFZmY6hact1OuV12vzBT2UTmlYsiMhQbHN1MHCAqt6S8JSKDhfdBAjZYFcAu4dDT2C+0g8Tm1QGhKSBo7Aoh75YF+FjgZtL3fIJoWnbY7UZKrGNtfadJhown29KhF8tNd+viIzF2jbNxFKEY6lYVyq46MZIsG4PxVrDDATmYD7Ca4pRrEIL86sxCxDgQeCIJYVflQoichRW2e1L4AhgS9pC09p3Tp5Jx9C0oi+VGNbxw9iXzy2qekA3H3Ha4aIbE6HC10Rgu3DoP1hWWVF3Wg034EFYRtsgrH/aycAVpWbhtSdYvE9hYnu1qh4Rji9Lx9C0VTp99APaoiIeL9bNSBFZE2tv1Avz7f434SkVDS66eSY8io/HUil7Y0H5RwN3FqN12xUisgJm+f0sHHoaOExV30tuVvkl1MJ4DevMMFpVn+z0vgBr0ibA29ExNK0Va8OUckU8XwjRKukiIidhIY71WDRDUcZwx81SKbqhqv4WWFX90Vh7kp6Yf+4zrOLWS8DkdDs3LA4RWR/bdEq1RL8NK1BTkD3CokBEUt0rhmL+zTOB80s1mF5EzsQiOt7Dkia6bD0UQtNG0rYhtwXQvnPyPGztpUT4nUL+Yg4RLS9gnUEuVNXjU+/FdY8VI0uV6Ib+Ucdj3XHT7R91L3BBuj3KAEIL7xosX78CW2RHqup9OUy/aAgtby7E3A5gBWMOVdXXEptUnhCRSqzn2zrAWap6Wgaf7Y8JUsoSXqfTKZ/R5op4pBAjREIM9wvhv5utevJ9EMM9VswsFaIbOqXeglkZuXTjPaC+tnqJ7WNEZCSWPLB+OHQlcHLntNKlARHZCUv4WBX7PZ4L/GlJ1mAxIiJbYe6UZqwgzltZXmc4ZgGnXkM7nfImbVbwk4VS8UtELijvP2TCcnueMq/nsLXKwhdR3u6xYqekRbeqpi7VzuZS7NFmcd+46dKEPRodDdxQX1vd4RcXen/9EQuYLwM+xHyak3IYs+gRkX5Ydt1vsV399zCr95lEJxYxInI5lr79PLBVrrHWwR+8AW1W8LbYnkCKRr4fmhZ7fHdVTZ20Lpp3OOU9rqCsXMrKc7nFlnyPlQolK7pBcC/EcuX7Rnjp+VgUwoTUohCRH2MFatbANkcuwKpRFYQlUggEa/BarB2PYoXTT1HVeYlOLCJCgfUpWNfd8ap6acTX70VbWNoOwI/oGJr2DfAYbaFpeU/RjfMeKyVKUnTzuBhSzAcmTjtntzOB84DDw/E3gUNUdanwTWVKEI7TsILs5cA0rM35Q4lOLCJE5KfAPdiG2Lrd9avLcawhWDREyhKu6nTKVNqs4MdVdVaU48d1j9XXVh+Xh2snSlnSE8gTY8nfYgDoq60tv+73w53rMcFtwqpxbeqC2zWqukhVT8V2tF/FfL3/FZHrw+ZbURPqUNyNNbO8PLgI8jXWTFW9S1UPB1bHSnAehYn+t9hT15FhPjNE5HkROUtERoeN3lwZS57vMWBcVU1dyfVmKzlLN2yavUv+FsN3tDYu5Itrf/tK87fTD1TVt/M9XikRwo0mAH/ANjenA79R1bsTnViOdGpf/nNV/XsCc+iBuR9SVvAWdNzPmE/H0LQpmYSmxXmPYU8NI+prq4s6iag9pWjp3kLHXPi8IT0qW1Y88pq5LriZo6pNqnouVi7yaWyn/h8icncQrqJEVb/AWtoDXJqEBa+qzar6vKqepaqjgWWA3bDOxlMwsdwVyyJ8C/hMRG4SkQPS/N3Hdo9hX8glVVSnpCzdqpq6kVjxmD6ZfK5vz3IePm40Kw6yzeE3Pp3N7pelvbm+ABi9tMQY5oOQUnskFlLWD5iNRYHcWMjJAV0Rfp4nsD5t16nqocnOqCOh4FL7qmkrdDrlLTqGpn2XaZbpPTawdwXHbP8D/m/doSzXv5LZC5qY9P7X/PWR9/ni27QjB0vqHis1S3cCHZsRpsWJO4/4TnCzoDKM62SJqraq6uVYbPODWA2H6zF/b1WCU8uKUHNiHBb+dIiIjEl4Sh1Q1c9V9aZQqGZFrOnp8djvfiH2dzgOuB+YJSJPiMipIjJKtfV40rzH+lf24O4jt+SQrVZj+OA+VPYoZ+iAXuy76crce9RWrJT+PVdS91jJiG5IO/wpmQVls/HKg9h/s1WZ35B1lmo5sGcY38mBUIFrV+BALARqR+AtETk6WI9FQ6g58afw36tD66OCQ403VfVCVd0Fq5M7BoutfhFLUx4NnCWVfZ/Xluafk+Y9Nn77H7Dm8v0AuHLSVDb640Oc8W/zxA0d0ItTd+2cgNclJXWPFdVC7oYtsKyWtOlRJtT+bAPKy4QLHs6pLksD1uLFyZEgAjcD62IF0vtiTTGfCgXUi4nzsEf1NbHoloJHVRtU9QlVPVVVRwHLAvsAV/daZYMvtbkp7WvttclwABY0NnPBw+/x7cImbpxcz7SZ5q3Ycd2hDOjVY0mXaE/J3GOlJLqbkuFu6hHbrsGIFQbwwFtf8NDbOaW19wnjOxGhqtNVdV+satmXWGLAayJySoh8KHhCxbBxWDLI70Rko24+UnCo6jeq+g9VPWL5vX5/eVlln7QeCVce3Jtl+tpe27SZC2hqaXPNvz/d8mEqystYb8WB6U6lZO6xUhLd0XSs2LREqob04ejt1mTOwiZO/3fOwQcVWE8tJ2JU9R7M6r0W2zE/G3hRRDZJdGJpoqrPYdl35cA1odRnsTI6hKN1y3L929y+cxZ1tI7nNrT9f9l+aQdBlMw9Vkqiu1ImJ/95zw3oVVFO7QPv8PXcjLwSXbFiFBdxvo+qzlLVwzAfbz0WZvaCiJxTqL7STpwKfIJZauMTnksuZHSPdYWQdc5ISdxjpSS6aX9lbrnGELZcY1mmfj2PNz79lnWHDWDNof2+e79XRTnrDhvAwN4ZPcVmHDXhZIaqPoLtrF+Erd2TMJfDNknOqztUdS6WLQZwVjFGZATSvsfaGzIDenW8j/pVthnLM+ZlVLO9JO6xUhLdtP96qT/6Gsv1o278Ntw/fhtuGDvqu/fXGtqf+8dvw47rdK6st0QiMZedJaOq81X1OGArLPNrLeBJEbks1KctSEIt5Tsx3+QV+UwRziNp32OfzFrIN/Pt9Kohfakob/tx1woGTlNLK29/nlHF05K4x0pJdJNOE/w84fGXKlR1MtYE8k9YHdujgLdFZJdEJ7ZkjsE6J+8M/DLhuWRDRvfY3a9YWdzePcs5fse1GdCrBwdtUcWqQ2y/++Ep05mzKKNQzZK4x9LeeCoCJmE1R7v1CTw0ZTpVNXUdjg0f1JunT7KekRlmpIEVvHkikw84uaOqDcDpIvIPrHD8j4D7ReRm4DhVnZnoBDuhqtNF5ARsU/BiEXmoyFo3pX2PAVzy6AeMWXt51ly+H0eOXoMjR6/x3XtfzVnE2fe/k8nYJXOPlZKl+xKWLpgEC8L4TgKo6htYDOeJwCLgAOAdEdm3AB/jrwcex+JfL0h4LpmS0T02t6GZva58luuf+R+fzlpAY3MrX81ZxF0vfcIelz/DZ7MXZjJ2ydxjJVN7IWSrfIG1hI6bRcCwpa3BXiEiIj/ACspvGw7di1UvK5hH0zDHN7C1+n+q+nDCU0oLv8eioWQs3fDHuBfrtxQnLcA9pbAYSgFV/QBLY/01MBdLDZ8iIocWitUb5viH8N+rQqungsfvsWgoGdENXED8O5wNFN9jYkkTCuhcCayHFW0ZiFm/D4vI6olOro0LgNeB1WgT4GLgAtXW9HOBo6Gk7rGSEt1Q+u0FzOmed1pbmmj8un7utHN2q49jPCczQruc3YD9gZnA9sCbInJs0plhqtqEpQi3AhOKIcNORCqnnbPbTxo+ebuytSU23W0CXqivrX45rgHzTUmJbuAAMognzImWZr6684yh2OPrPoXy+Oq0EQro3IqlEt+Bxcn+FXhGRNZLeG4vYoXFy7AU4YKNJhKRzYCXgdNn/Od8ESXrsnwZ0oB9aZYMJSe69bXVn2ItnOd3d26OzG+e9cXJLfNmPgksD/wd+Gcxdz0oZVT1K1X9JbAHFu+5GfCqiJwWUc+wbDkda9C5MVbDtqAQkb4iciEwGXPXfNAyd+Zo6VFxODHcY8D4UmrVAyUouoEbsBbO+VoU84GJn1939LnYps2RtG3avCMih7jVW5io6r8xq3ciFm/6R+AlERmZ0HzmYesH4A8F5HNGRLbDoiyOw9wg5wIbqeqTxHSP1ddWX5+n6ydGSYpufW21YpXm87Eo5ofrToDvNm2uwm7kOmzT5lrgIRFZLeKxnQhQ1W9DF93tgY+ADYDnROS8JCIJVPVB4FagNxbNkOgXtogMEpGJwKNYp+HXgc1U9WRVXQjx3mOlRsnE6S6Oqpo6wVpFX4IVy8i6DmtrSxOoNpf16Hl4V9++4Wb5ZRhvCBbQfQrwN1WNO8zGSYMgsn8CjsWMkA+Bw1R1UszzWA6rJTEEOEhVb4pz/Hbz2AO4AhiG7Y38ETgvbPx9jyjvMWzTrAFzKZSchZuipEU3RWgZfTMwClsYmexct6i2NjZ8MqVyxr//UtYyb+auqvrAkj4QbqBLgF+EQ88Bh6rqlCym78RA2Ci6FvNbAlwFnKSqGVVkyXEOBwI3Yq2K1lHVr2Ice3lszf48HJqMrdm0cnVzvccwsX0B2L/UfLidWSpEN0VVTd2m2CPLntgfuQ+L/2ZuwqzUSuAe4MJp5+w2Bmu/Mg1YP/jiloiI7I5ZDStiVsNZwLmho4BTYIQNtRqs/m0FVuDlCFWtW+IHoxtfgP9idYNvU9X9YhpzPyyKYhls3dcAl2XzdJbLPVYq3X67Y6kS3RQhnXFzrKj0jzFRrMQWyedYYY2XgOdSWTAhnOcFbJf5r6qalr9JRAYCf8FiMsE2Jg5V1aVigRUjIrI+ZvWm6n3eBhyrql/HMPbqWF+13kC3T1U5jrUycCXWDBSs5foRqvq/XK+dzT221KCq/krzBWyClRFsAUZm+NntgKlYv6wWzGrunfTP5K8u/17lmMW2IPzNvsbcRRLD2CeEMeuBfnm4fhmWJj0njDML88vm/Wfzl5Zm9EK+UNVXsMD6VDB72psGqvoYtkueSmf8HfCGiIyOfKJOzqhqi6peiP3NUlXBbgf+JSKRtK1ZAhcBrwCr0tbGPRJEZC3s57kc6I892q+rqjdoUGQnzySt+sX2wnxUH2EWwslZXmMU8Ga4hmJ+3wFJ/2z+6vLvJZh76Nvw9/o2/D9vliE5PFV1cb0eWOnLheFn+BLYK+nf7dL4Wip9urkiIjsCD2Hl5jZUqxqV6TU6b9p8ChypMW3aOJkTLNwrgJ+EQ48Dh6vqh3ka7zzCExGwqXYRtpXGdTbCiryn6jvcCExQ1W8imaiTEe5eyAK1+qc3YXVFswpmV9VGVf0DdiO8AAwH7hORW0Rk2Ugn7ESCqn6GpRH/EpiBZSO+ISLH56mAzpnYU9WGmJ83I0SkUkT+hG1YbQJ8DOysqmNdcJPDLd0sCcL4DubrO1RVr8vhWuVY/6yzsF3rGVj9iDvV/0AFSfj7X4SFWwG8CByiqm9FPE7qqaoB2CDdpyoR2QKLwFgHcydcBpyi1pnYSRC3dLNErbfVseG/54vICjlcq6tNm3tj2LRxskBVZ6jq/ljpyE+BkcArInJmlAV0wlPVjVi4VbdPVSLST0QuAp7BBPc9YFtVPdoFt0BI2qlczC9sg+UBzJK4M8JrHkaMmzb+yvlvNgDz9aY2Rt8CRkV4/SHAV+HahyzhvB2B/4XzmoE/A72S/v34q+PL3Qs5IiJVwNtYVMNPVPW+iK67uE2bcao6NYrrO9ETwv+uAdbEqnJdBJymqjk3TBWRX2FFcWZjKcJftntvMBaKeHA49Bomzq/mOq4TPe5eyBFVrQd+H/57hYj0j+i6qU2bX2CB+WOwrgcTku564CwetSI5G2EZiGDJFW+GEom5cjvwIDAIS9kFQET2BKZggtuAFVga5YJbuLilGwFBBJ/DUh4vVdXxEV+/86bNC9jmXaSbNk50iMimWJjWBuHQNcDvVHV2DtdcFXuq6ot1SNkD2Du8/QxWHe3dbK/vxIOLbkSEWMiXsaeHrVR1ch7GqMZy5YdjBUPOBmrVC+gUJGFD7UTgNKAnVnPg12qF1LO95rFYVmQrttbmAScDV6hqa65zdvKPuxciQlVfxx4rBZiYjxYwaokT62HCW4HFcb4sIqOW9DknGdRisc/CiiQ9hxV9+ZeI3BFKKWZEsHR3Dv8tw+Ju11fVy1xwiwcX3Wj5I1YEez3MwokcVZ2jqr/GKjd9CKwPTBaR85PoeuB0j1od5a2xEMMFWM3aKSKyXzqJNSJSJiK/xVwLO2GFalqBlTEhd4oIF90IUWtlcnj472kiMiKPY03CMpXOC4eOxzZtxuRrTCd71GKxL8Z8vI9iYWC3AP8JJRYXi4isDTwJXIr5cv8BrIX1K8vbU5WTP1x0I0ZVH8c2UHoCV4tI3n7HqrpQVU/COtu+ifWzekxErgp1fJ0CQ1U/wuJpD8VisKuBt0XkyPZrRUQqRKQG60+2FVag5mequo+qTseqj6Weqk6K+cdwcsA30vKAiCyDpQgvjxWFvjqGMRe3aXOkqv4n32M72SEiK2LpuT8Nh57EEmP6YSm8G4fj1wEnqOqsTp8fAzyGdSXZyCMXigMX3TwhIj8H7sCsmXVU9YvUe6Gq/hZYiNloYCVMKBuxFjGTsCIlkzOtqi8i62I37Obh0B3AeI2h64GTOcGnuzfwN+xLuhl7Ai3DipiPU9VHlvD5a4FDgKeAH6c21PK5xpzccNHNE+Fm+jeWm3+3qu4d+kcdj1k26faPuhe4IJP+USFu+LdYGmgfYCYwHrhd/Q9ekIjIrlgCxIBw6CtgD1V9rpvPLYMlRwwFjlj15PteIYY15mSPi24eCRskU8r7D+k37KCL3i7vN3g1cuuUekB9bfWnGYy/GnA1sEM4VIfFiX6SwfhOHgkZjLXAb8Khj7E1MhSzes8BzlLVhiVcY9/y/kPuXHb3E1sqh6/bGFxNsawxJ3NcdPNIVU2dzH3l/pv7rj9mP8ortKy8R8Z1d9vRhD0aHg3cUF9bndYfLljcBwMXAgOBuVhh7Ike25ksIrIT9qW4Cu0EFnMDtBfid7AMxO8l3FTV1ImqjtWWpomIlJeVp91BanFktcaczHDRzRNVNXUCXKiq40Skb4SXng9MBCZkclMsZtNmEuYvzLjrhZMbwSXwV+DAcOhlTFRf73TeNlj68FpY5bBLgN+r6jxoW2NYFbrE15iTHh4ylgfa3wwRCy7YzTUuXD9tVPVz4GfAvpi/cDTW9eB3ob28EwMisjdmuR6ItXs6Edi8s+ACqOpTWAGdc7BkiGOwWOwd8yi4kOUac9LDRTc/jCU/N0OKvsC4qpq6g7s9sx1q3AWsS1u7ofOwjLYNo5+mk0JEhonI3cBdWJTCk1iY119Utbmrz6nqIlWtwZqZvgZUAQ/Nfuq2Sap6OAW2xpzucfdCxFTV1A0H3iV/N0N75gEj6murP8vmwyKyM3AVbT7FWuDsJW3aOJkRfOpjMatxEOZTPxG4OlOfuohUAL8r77/sGSuOu6JnWc/eEc92seS0xpzv45Zu9NyCbYTEQWUYLytU9UGsdsNlWIvu07CWM5sv8YNOWoTokYew5IZBWJeR9VT1ymw2MVW1SVX/vOK4K16X8oq4rKWc1pjzfdzSjZCqmrqRwBNYbGSX7L3JcM7fZ6Mu39/+wieY+vX8dIddAIzONcZyMZs2F2ObNmlPxDFCnPRvsCeHVJz0McBtucZJp7vGAJ4+cQzDB3d92qezFrD1eY+nM2wka8wx3NKNlgmYZRAnlWHcnFjMps2x2KbNDkv6nNMREVkHyw67GBPGO4B1VfXWiBJTIltj8xq6dCV3JpI15hhu6UZESLv8AtucWiLtLd2qmroohl8EDIsqnVNENsFSiX8YDl0HHJ9L14NSJ/hbTwROJ6KC5Z3JZI11xTHb/4DjdlgLgLPvf4eJT32U7kcjXWNLM27pRscWWFZPEjTQVmshZ1T1FWy3/FQsWP4QrP7rT6Mao5QQkR9hdQxSiQ0TMd9tZIIbyGmN9SgTfjVqFQDmNzRz54sfZ/LxSNfY0oyLbnRsShYRCy+esj0fnLULL56yPZf+YmPWGtovm7H7hPEjI7Vpg7kcngWGAfeIyN9FZGiUYxUrItJbRM7F0mc3BD4CtlfVw/P0VJDVGkux6wbDGDrAjOR/vvoZcxal7V6APKyxpRUX3egYjUUAZMRy/XtRUV7Gcv178ZONVuRfR23NhsMzLoVbgXWSiJxQLnAbLDV0PrAPZvUekE7Xg1JFRLbFat2mOoRcCGyoqo/lcdis1liKg7esAqC1Vbnh2fpMP563Nba04ZlI0bFSuifWz5zPqfe8ydNTZ/Dlt4sYNrAXZ/xkPcasvTy9e5Zz4k4j2P/a5zMavHHGx9uLSFwO+mWw5IqblmLdbU8ZttE0IZ+/j2HjrqDnkC6bTCyRDYcPZONVBgPw9IczmPr1vGwu462BIsAt3ehIOzb3pWmzuPWFj5k2cwENza3Uz1zAyf9847v3N155UMaDS26FTpwiQMqyt5HGBisX4Lpn/5ftZeKOzClJXHSjI+026IszhtoHkWRjrlYMHvaOqkpcL8zHe3e7KTwNjIhzDjH+rMvRMUHgRcyVEOs8KgYPy6ozxLL9elK9wTAAPpoxjyfey7qevWcqRoCLbnSknSZ53UEjOWLb1Vlt2b5UlAtVQ/pw7l5tpQ9erP8mm/E/z+ZD2aKqX6rq3ljXg+lYt9vXReTkUimgI8bPsSLh+wMLgROALVT1zQSmlFUq7q9GrUJlDyuvm4Uvtz2xrrFSpSRujgJhErAti6/S34Gh/Sup2WUdanZZ53vvzV7QyJ/vfyejgbWlWee/81SFyG7bA8+o6qKMLpADqnq3iDwOXIDVGKgF9hGRQ1X1tbjmETWhFOYVwO7h0BNYKcwPE5tUBmssRY8yYb/NVgVgzqIm/vFy1vXJm7DfgZMjbulGx0tYumS3nP/w+9z9yqdM/Xoecxc10dDcwsffLODW56ex6yVP8cFXmW1ytDY1yPy3H98WeAT4RkT+KyIniMhG+exGnEJVv1HVg4GdgGnAJsBLInK2iGQdyJ8Ewbo9DLNudwfmAEdgoWBJCi5ksMZStA8Tu+ulT1jQ2JLt2AvC+E6OeEZaRESRLZQt2tra+NkVB1/VMnfmtlhcbXu+wsT4YeARVc1rKxYR6QecjYWYCVZx7VBVfTaX68bRaFFEVscSG7YLh+7DssoKon1NkmsMz0iLDBfdCKmqqbsdi2PNpD9VrrQAf6+vrf4VQEhc2B7YMbw6h7K9iwnww8ATqjo3H5MSka2wAjojsL3BvwGnaOh6kC5xNPMMBWrGY18WvYEZ2JfGnVpgN0ghrDEnN1x0IyQIxCTSqAAVIQuAbetrq1/u/EZIXhiBie8OwBigfcpbM/AcbSL8oi6hoHamBNfC74GTMZGYBhyuqg9199lQl/gWYCR5bOYpIutjXw6bhUO3Aceo6owMxouNQltjTua46EZMVU3d48BWZLDZkQNNwDP1tdVj0jk5FGXZjDYreBQdxWwO8DhtIvxBFJaeiPwQK5qzcTh0A1ZA53thGqENzVjgUsx9kMvvsctGi6Fjbg1WX6ICc1Ecqar35TBeLBTyGnO6xzfSoucAMojZzZEGLJQpLdTqKTytqmeo6pbAEGBP4HLgfWAAsAfmCngPqBeRa0TkFyKyXLaTDFEMozCLtwET1Skislf789r1/boUqzGQq6hUhOtcClwYro+IjMSaQZ4ZzrkKK1BT8IIbKNg15nSPW7p5IPSVSglHvpgPHF1fW319VBcUkVUxN0TKHTGk0ymv0mYFP51NaJqIrI1tVm0TDt0N/HbVk++bTv4aLQLM1+bG6z8+/2cNwHGYwTEVOExVn8jDeHmlWNeY45ZuvrgBE5Z8dV2YD0yM+mZQ1Wmqeq2q/gJrnvgjzDp9FLN4NsYKvDwMzBKRh0I34Y3TDU1T1fewwim/wfpv7QVMmffGwxNVNa/NPFX1N3032OH48P+/YFllT+RpvHxzA0W4xhy3dPNGHltkz8dutgntfZT5RkR6Y1lnKX/wDzud8jUmzg8DD6vqJ2lccxXgqvL+Q3ZecdyVxNFosbVpUes3/718t3lvPvpA3gfLM6W2xpYWXHTzSLtNoUuwHfhcN4UagPGFYH2IyPJ0DE0b3umU9+gYmjani+vISkfdMKWs76ARZeX5T5BU1SYRKZmNoVJeY6WKi24MhPCnm7HNpFzCn/YvxFbYITRtbdr8wWOA/u1OaQGep02EX1DVJsis0SLABisN5MjRazCqajADe/dkzqImPpg+jyufnMqk99Mu5FJyjRZLfY2VEi66MRJiLCdgEQPpBvrfA1xYTAIRQtNG0WYFb0ZHEZhLCE0bPv62Xcp6998pJCgskT03Xom/7LUhPcq/7z6+9LEPuODh99OdYskG+y8ta6yYcdFNgJDOuTmW0vpjrDh0JXaTfI5Zfi8Bz5VC2qWIDMR+zpQlvDaAVPZl+G9voqyi+zKtqy3blwfHb0NlRTmfzV7Iaf96ixf+9w09e5Sx4UoDaVXlyQ8yymco6bTWpW2NFRMuuk7shA20HfpusMOBy+wwbtuyyr7dtlv4w+7rcdAWVQD86prneHbqzFyn8S3wi/ra6gdzvZDjZIKXdnRiR1U/Bq6rqqlbSVW3Io11uNUaywLQ2NzKtj9YjnN/tiHLD6jkk28WctNz9dw0eVqm00g1WnTRdWLF43SdJBmdbsHzFQdZYa2ePco4cvQarLxMHyp7lLPm8v344+7rc/LOIzId2xstOongouskSdrNPHuUtS3Vx9/7ig3/8F92u/Qp5jVYfZ7Dtl6NIX3TblOXwhstOrHjouskSdoqOWtBW6mBW5+fxpxFzbz1+Rye+dA2z3qUlzFihf5dfbwrvNGiEzsuuk6SpF205c3Pvu32nIVNrZmO740Wndhx0XWSJO0g/LtfaSuJ+6tRqzKgVw/WX3EAW61pG2yzFzTy9ufdC3MnvNGiEzseveAkSdqNFh9460vuf/MLdt1gGNuNWJ43ztjpu/daW5U/3jeFhuaMLF1vtOgkgouukySpRosD0zl5/B2v8vqns9l7k+GsMqQPDc2tvPbJbK6cNDWbuF1vtOgkgouukySTyWAzq7lVuerJj7jqyY+iGLsSa1XkOLHiPl0nMUL66b1YLYQ4aQHu8fRXJwlcdJ2kuYD4owgawriOEzsuuk6ihMpWL2AbW3HQBLzgnW2dpHDRdQoBb7ToLDW46DqJU19b/SnWJj1f/b5SzMe6IniRbicxXHSdQuEGvNGisxTgousUBKEB4gTyI7zfNVqM+LqOkzFexNwpKLzRolPquOg6BYk3WnRKFRddp6DxRotOqeGi6xQF3mjRKRVcdB3HcWLEoxccx3FixEXXcRwnRlx0HcdxYsRF13EcJ0ZcdB3HcWLERddxHCdGXHQdx3FixEXXcRwnRlx0HcdxYsRF13EcJ0ZcdB3HcWLERddxHCdGXHQdx3FixEXXcRwnRlx0HcdxYsRF13EcJ0ZcdB3HcWLERddxHCdGXHQdx3FixEXXcRwnRlx0HcdxYsRF13EcJ0ZcdB3HcWLERddxHCdGXHQdx3FixEXXcRwnRlx0HcdxYuT/AZNVgoaQTfGvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "V = [0,1,2,3,4,5,6,7]\n",
    "# V = [0,1,2,3,4,5,6,7,8,9]\n",
    "# V = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "\n",
    "V.sort()\n",
    "print(V)\n",
    "\n",
    "E = E0[4]\n",
    "\n",
    "n = len(V)\n",
    "\n",
    "\n",
    "target_graph = nx.Graph()\n",
    "target_graph.add_nodes_from(V)\n",
    "target_graph.add_edges_from(E)\n",
    "\n",
    "target_graph = nx.Graph()\n",
    "target_graph.add_nodes_from(V)\n",
    "target_graph.add_edges_from(E)\n",
    "pos = nx.circular_layout(target_graph)\n",
    "options = {\n",
    "    \"with_labels\": True,\n",
    "    \"font_size\": 16,\n",
    "    \"font_weight\": \"bold\",\n",
    "    \"font_color\": \"white\",\n",
    "    \"node_size\": 1000,\n",
    "    \"width\": 2\n",
    "}\n",
    "nx.draw_networkx(target_graph, pos, **options)\n",
    "ax = plt.gca()\n",
    "ax.margins(0.20)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Get the neighbors' information for building the circuit\n",
    "info = get_info_neighbors(target_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3545469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seeds total_SEED = [19904, 18864]\n",
      "The vertices where the mixer can be applied in the first layer: [7, 0, 3, 4, 5]\n",
      "\n",
      "\n",
      "\n",
      "The 1-th global random initialization\n",
      "SEED = 781, initial_beta = [0.54655486], initial_gamma = [0.7025923]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [0.7025923, 0.54655486]\n",
      "weight = [0.7025923  0.54655486]\n",
      "lr = 0.05, ITR = 600\n",
      "train_step = 50, loss = -2.9405200481414795\n",
      "Convergence condition met, iterations = 63, loss changes = [-0.34374985, -0.4032647, -0.4659761, -0.5315037, -0.59946066, -0.66945493, -0.74109304, -0.8139845, -0.88774633, -0.96200824, -1.0364186, -1.1106489, -1.1843994, -1.2574033, -1.3294284, -1.4002815, -1.4698068, -1.5378865, -1.6044389, -1.6694151, -1.7327954, -1.794584, -1.8548052, -1.9134972, -1.9707075, -2.0264878, -2.0808895, -2.1339598, -2.185739, -2.2362564, -2.2855291, -2.3335607, -2.3803399, -2.4258409, -2.4700224, -2.512831, -2.5542, -2.5940533, -2.6323075, -2.6688747, -2.703666, -2.7365947, -2.7675805, -2.7965531, -2.8234553, -2.848246, -2.870904, -2.8914282, -2.9098399, -2.9261823, -2.9405212, -2.9529426, -2.963551, -2.9724667, -2.979823, -2.9857624, -2.9904323, -2.9939835, -2.9965653, -2.9983222, -2.999393, -2.999907, -2.9999835]\n",
      "Number of iterations consumed in this optimization: 63\n",
      "Optimized circuit parameters: [0.7025923, 3.1605685]\n",
      "\n",
      "\n",
      "\n",
      "Global random initialization completed, outputting related information... ...\n",
      "value = [2.99998]\n",
      "\n",
      "\n",
      "\n",
      "params = [[beta_optimized, gamma_optimized], ...] = [[[3.1605685], [0.7025923]]]\n",
      "\n",
      "\n",
      "\n",
      "measure_result = [{'10010001': 1000}]\n",
      "\n",
      "\n",
      "\n",
      "consumed_iterations = [63]\n",
      "\n",
      "\n",
      "\n",
      "avg_loss = 2.99998\n",
      "Average iterations consumed by multiple random initializations: avg_iterations = 63.0\n",
      "max_loss = 2.9999799728393555\n",
      "params_opt = [[[3.1605685], [0.7025923]]]\n",
      "\n",
      "\n",
      "SEED_opt = [781]\n",
      "max_avg_initial_value = 1.9998596584836976\n",
      "The first selected vertex where the mixer is allowed to act is 1\n",
      "Vertices where the mixer is allowed to act in layer 2: [1]\n",
      "SEED = 19904, initial_beta = [3.1605685, 0.50186425], initial_gamma = [0.7025923]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [0.7025923, 3.1605685, 0.50186425]\n",
      "weight = [0.7025923  3.1605685  0.50186425]\n",
      "lr = 0.05, ITR = 600\n",
      "Convergence condition met, iterations = 3, loss changes = [-2.9997356, -2.9992962, -2.9997933]\n",
      "Number of iterations consumed in this optimization: 3\n",
      "Optimized circuit parameters: [0.7025923, 3.1480682, 0.6400913]\n",
      "\n",
      "\n",
      "\n",
      "max_avg_initial_value = 1.99998541162199\n",
      "The first selected vertex where the mixer is allowed to act is 1\n",
      "Vertices where the mixer is allowed to act in layer 3: [1]\n",
      "SEED = 19904, initial_beta = [3.1480682, 0.6400913, 2.4231322], initial_gamma = [0.7025923]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [0.7025923, 3.1480682, 0.6400913, 2.4231322]\n",
      "weight = [0.7025923 3.1480682 0.6400913 2.4231322]\n",
      "lr = 0.05, ITR = 600\n",
      "Convergence condition met, iterations = 3, loss changes = [-2.999979, -2.9990532, -2.999932]\n",
      "Number of iterations consumed in this optimization: 3\n",
      "Optimized circuit parameters: [0.7025923, 3.161935, 0.72919106, 2.5122318]\n",
      "\n",
      "\n",
      "\n",
      "Increase in ansatz layers results in minimal change in expectation function value, algorithm terminates\n",
      "In this run, the expectation function value changes as follows: function_value = [2.99998, 2.99979, 2.99993]\n",
      "In this run, the vertices where the mixer is allowed to act are: mixer_nodes = [[7, 0, 3, 4, 5], [1], [1]]\n",
      "The vertices where the mixer can be applied in the first layer: [2, 4, 6, 5, 3]\n",
      "\n",
      "\n",
      "\n",
      "The 1-th global random initialization\n",
      "SEED = 456, initial_beta = [3.0802817], initial_gamma = [1.5691029]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [1.5691029, 3.0802817]\n",
      "weight = [1.5691029 3.0802817]\n",
      "lr = 0.05, ITR = 600\n",
      "Convergence condition met, iterations = 4, loss changes = [-2.9981203, -2.999936, -2.999597, -2.9990726]\n",
      "Number of iterations consumed in this optimization: 4\n",
      "Optimized circuit parameters: [1.5691029, 3.179359]\n",
      "\n",
      "\n",
      "\n",
      "Global random initialization completed, outputting related information... ...\n",
      "value = [2.99907]\n",
      "\n",
      "\n",
      "\n",
      "params = [[beta_optimized, gamma_optimized], ...] = [[[3.179359], [1.5691029]]]\n",
      "\n",
      "\n",
      "\n",
      "measure_result = [{'01000100': 1, '01001100': 999}]\n",
      "\n",
      "\n",
      "\n",
      "consumed_iterations = [4]\n",
      "\n",
      "\n",
      "\n",
      "avg_loss = 2.99907\n",
      "Average iterations consumed by multiple random initializations: avg_iterations = 4.0\n",
      "max_loss = 2.999069929122925\n",
      "params_opt = [[[3.179359], [1.5691029]]]\n",
      "\n",
      "\n",
      "SEED_opt = [456]\n",
      "max_avg_initial_value = 1.9995246693866147\n",
      "The first selected vertex where the mixer is allowed to act is 0\n",
      "Vertices where the mixer is allowed to act in layer 2: [0]\n",
      "SEED = 18864, initial_beta = [3.179359, 1.9114044], initial_gamma = [1.5691029]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [1.5691029, 3.179359, 1.9114044]\n",
      "weight = [1.5691029 3.179359  1.9114044]\n",
      "lr = 0.05, ITR = 600\n",
      "Convergence condition met, iterations = 3, loss changes = [-2.999287, -2.9999251, -2.9994678]\n",
      "Number of iterations consumed in this optimization: 3\n",
      "Optimized circuit parameters: [1.5691029, 3.117082, 1.9460418]\n",
      "\n",
      "\n",
      "\n",
      "max_avg_initial_value = 1.9997997686825215\n",
      "The first selected vertex where the mixer is allowed to act is 7\n",
      "Vertices where the mixer is allowed to act in layer 3: [7]\n",
      "SEED = 18864, initial_beta = [3.117082, 1.9460418, 2.0365067], initial_gamma = [1.5691029]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [1.5691029, 3.117082, 1.9460418, 2.0365067]\n",
      "weight = [1.5691029 3.117082  1.9460418 2.0365067]\n",
      "lr = 0.05, ITR = 600\n",
      "Convergence condition met, iterations = 3, loss changes = [-2.9996996, -2.9996753, -2.9997606]\n",
      "Number of iterations consumed in this optimization: 3\n",
      "Optimized circuit parameters: [1.5691029, 3.1442854, 1.9585472, 2.0428007]\n",
      "\n",
      "\n",
      "\n",
      "Increase in ansatz layers results in minimal change in expectation function value, algorithm terminates\n",
      "In this run, the expectation function value changes as follows: function_value = [2.99907, 2.99947, 2.99976]\n",
      "In this run, the vertices where the mixer is allowed to act are: mixer_nodes = [[2, 4, 6, 5, 3], [0], [7]]\n"
     ]
    }
   ],
   "source": [
    "ham = build_ham(target_graph)\n",
    "k = 3 # the degree of the regular graphs\n",
    "counts = 1  # The number of repeated RI processes when the number of ansatz layers is 1\n",
    "delta = 0.1  # If the difference in the change of the expectation function value between consecutive optimizations is smaller than the given threshold delta, the current run terminates\n",
    "iterations = []  # Store the number of iterations consumed in each round of optimization in one run\n",
    "mixers = []  # Store the vertex indices where mixers are allowed to be applied in each run\n",
    "values = []  # Store the changes in the expectation function value in one run\n",
    "running_time = []  # Store the simulation time consumed in each run\n",
    "depth = []  # Store the circuit depth for each run\n",
    "\n",
    "times = 100*n  # The number of times the adaptive ansatz is repeated\n",
    "\n",
    "    \n",
    "# Randomly initialize, and keep the optimal parameters corresponding to the best expectation value\n",
    "total_SEED = [] \n",
    "for i in range(0, times):\n",
    "    total_SEED.append(random.randint(1, 25000))\n",
    "my_logger.info('Random seeds total_SEED = {}'.format(total_SEED))\n",
    "\n",
    "for i in range(0, len(total_SEED)):\n",
    "    start_time = time.time()  # The start time of the optimization run\n",
    "    SEED = total_SEED[i]\n",
    "    function_values, mixer_nodes, ITR, circuit_depth_layer = adaptive_ansatz(SEED)  # The returned values are the expectation function values at the end of each optimization round, the vertex indices where mixers are allowed, and the iterations consumed in each round\n",
    "    iterations.append(ITR)\n",
    "    mixers.append(mixer_nodes)\n",
    "    values.append(function_values)\n",
    "    depth.append(circuit_depth_layer)\n",
    "\n",
    "    end_time = time.time()  # End time\n",
    "    delta0 = end_time - start_time\n",
    "    running_time.append(delta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18547ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth = [[16, 19, 22], [16, 19, 22]]\n",
      "max_depth = [22, 22]\n"
     ]
    }
   ],
   "source": [
    "my_logger.info('depth = {}'.format(depth))\n",
    "\n",
    "# Record the final circuit depth in each run\n",
    "max_depth = []\n",
    "for i in range(0,len(depth)):\n",
    "    max_depth.append(max(depth[i]))\n",
    "my_logger.info('max_depth = {}'.format(max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10465f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values = [[2.99998, 2.99979, 2.99993], [2.99907, 2.99947, 2.99976]]\n",
      "\n",
      "\n",
      "mixers = [[[7, 0, 3, 4, 5], [1], [1]], [[2, 4, 6, 5, 3], [0], [7]]]\n",
      "\n",
      "\n",
      "iterations = [[63.0, 3, 3, 3], [4.0, 3, 3, 3]]\n",
      "\n",
      "\n",
      "classical_running_time = [15.389078140258789, 13.294432878494263]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_logger.info('values = {}'.format(values))\n",
    "my_logger.info('\\n')\n",
    "my_logger.info('mixers = {}'.format(mixers))\n",
    "my_logger.info('\\n')\n",
    "my_logger.info('iterations = {}'.format(iterations))\n",
    "my_logger.info('\\n')\n",
    "\n",
    "my_logger.info('classical_running_time = {}'.format(running_time))\n",
    "my_logger.info('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b017fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_loss_run = [2.99998, 2.99976]\n",
      "\n",
      "\n",
      "total_iter_run = [72.0, 13.0]\n"
     ]
    }
   ],
   "source": [
    "max_loss_run = [] # Store the expectation function value in each run\n",
    "for i in range(0,len(values)):\n",
    "    max_loss_run.append(max(values[i]))\n",
    "my_logger.info('max_loss_run = {}'.format(max_loss_run))\n",
    "\n",
    "total_iter_run = [] # Store the consumption of iterations in each run\n",
    "for i in range(0,len(iterations)):\n",
    "    s = 0\n",
    "    for j in range(0,len(iterations[i])):\n",
    "        s = s+iterations[i][j]\n",
    "    total_iter_run.append(s)\n",
    "my_logger.info('\\n')\n",
    "my_logger.info('total_iter_run = {}'.format(total_iter_run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d10c6da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degrees = [[[3, 3, 3, 3, 3], [3], [3]], [[3, 3, 3, 3, 3], [3], [3]]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the degree of the vertices where mixers are allowed to be applied in each run, used for the subsequent calculation of CNOT gate numbers corresponding to multi-qubit controlled gates\n",
    "degrees = []  # Store the degree information of the vertices where mixers are allowed to be applied in multiple runs\n",
    "\n",
    "# For the i-th run\n",
    "for i in range(0, len(mixers)):\n",
    "    degrees_run = []  # Store the degree of the vertices where mixers are allowed to be applied at each layer during this run\n",
    "\n",
    "    for j in range(0, len(mixers[i])):\n",
    "        degrees_round = []  # The degree of the vertices where mixers are allowed to be applied at layer j\n",
    "        \n",
    "        # Visit the vertices where mixers are allowed to be applied at layer j and store their degrees\n",
    "        for t in range(0, len(mixers[i][j])):\n",
    "            node = mixers[i][j][t]  # The vertex where a mixer is allowed to be applied\n",
    "            d = len(info[node])  # The degree of the vertex\n",
    "            degrees_round.append(d)\n",
    "        degrees_run.append(degrees_round)  # The degree of the vertices allowed to apply the mixer at layer j during this run (multiple vertices, multiple degrees)\n",
    "    degrees.append(degrees_run)  # Store the result for this run\n",
    "    \n",
    "my_logger.info('degrees = {}'.format(degrees))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mind_case",
   "language": "python",
   "name": "mind_case"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
