{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c9c5380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindquantum.core.circuit import Circuit, UN\n",
    "from mindquantum.core.gates import H, ZZ, RX,RZ,X,I,Measure\n",
    "from mindquantum.core.operators import Hamiltonian, QubitOperator\n",
    "from mindquantum.framework import MQAnsatzOnlyLayer,MQLayer,MQAnsatzOnlyOps\n",
    "from mindquantum.simulator import Simulator\n",
    "from mindspore.common.initializer import Normal,initializer\n",
    "from mindspore import Tensor,ops\n",
    "from mindspore import dtype as mstype\n",
    "from mindspore.common.parameter import Parameter\n",
    "from mindspore.nn import Adam, TrainOneStepCell                   # 导入Adam模块和TrainOneStepCell模块\n",
    "\n",
    "import networkx as nx\n",
    "import mindspore.nn as nn\n",
    "import mindspore as ms\n",
    "import mindquantum as mq\n",
    "import seaborn as sns\n",
    "import heapq\n",
    "import copy\n",
    "from math import pi\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "import time\n",
    "\n",
    "from math import pi\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 将数据保存在服务器上所需代码\n",
    "import logging\n",
    "import sys\n",
    "import datetime\n",
    " \n",
    "def init_logger(filename, logger_name):\n",
    "    '''\n",
    "    @brief:\n",
    "        initialize logger that redirect info to a file just in case we lost connection to the notebook\n",
    "    @params:\n",
    "        filename: to which file should we log all the info\n",
    "        logger_name: an alias to the logger\n",
    "    '''\n",
    " \n",
    "    # get current timestamp\n",
    "    timestamp = datetime.datetime.utcnow().strftime('%Y%m%d_%H-%M-%S')\n",
    "    \n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO, \n",
    "        format='%(message)s',\n",
    "#         format='%(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(filename=filename,encoding='utf-8'),\n",
    "            logging.StreamHandler(sys.stdout)\n",
    "        ]\n",
    "    )\n",
    " \n",
    "    # Test\n",
    "    logger = logging.getLogger(logger_name)\n",
    "   #logger.info('### Init. Logger {} ###'.format(logger_name))\n",
    "    return logger\n",
    "\n",
    "\n",
    "# Initialize\n",
    "my_logger = init_logger(\"data/n = 8/ER/graph18.log\", \"ml_logger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49589e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the circuit depth using the interface\n",
    "\n",
    "# right 2021 Huawei Technologies Co., Ltd\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ============================================================================\n",
    "\"\"\"DAG Circuit.\"\"\"\n",
    "import typing\n",
    "\n",
    "from mindquantum.core import Circuit, gates\n",
    "from mindquantum.utils.type_value_check import _check_input_type\n",
    "\n",
    "# pylint: disable=invalid-name\n",
    "\n",
    "\n",
    "class DAGNode:\n",
    "    \"\"\"\n",
    "    Basic node in Directed Acyclic Graph.\n",
    "\n",
    "    A DAG node has local index, which label the index of leg of node, and child nodes and father nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize a DAGNode object.\"\"\"\n",
    "        self.child: typing.Dict[int, \"DAGNode\"] = {}  # key: local index, value: child DAGNode\n",
    "        self.father: typing.Dict[int, \"DAGNode\"] = {}  # key: local index, value: father DAGNode\n",
    "        self.local: typing.List[int] = []\n",
    "\n",
    "    def clean(self):\n",
    "        \"\"\"Clean node and set it to empty.\"\"\"\n",
    "        self.child = {}\n",
    "        self.father = {}\n",
    "        self.local = []\n",
    "\n",
    "    def insert_after(self, other_node: \"DAGNode\"):\n",
    "        \"\"\"\n",
    "        Insert other node after this dag node.\n",
    "\n",
    "        Args:\n",
    "            other_node (:class:`~.algorithm.compiler.DAGNode`): other DAG node.\n",
    "        \"\"\"\n",
    "        _check_input_type(\"other_node\", DAGNode, other_node)\n",
    "        for local in self.local:\n",
    "            if local in other_node.local:\n",
    "                other_node.father[local] = self\n",
    "                if local in self.child:\n",
    "                    other_node.child[local] = self.child.get(local)\n",
    "                    self.child.get(local).fathre[local] = other_node\n",
    "                self.child[local] = other_node\n",
    "\n",
    "    def insert_before(self, other_node: \"DAGNode\"):\n",
    "        \"\"\"\n",
    "        Insert other node before this dag node.\n",
    "\n",
    "        Args:\n",
    "            other_node (:class:`~.algorithm.compiler.DAGNode`): other DAG node.\n",
    "        \"\"\"\n",
    "        _check_input_type(\"other_node\", DAGNode, other_node)\n",
    "        for local in self.local:\n",
    "            if local in other_node.local:\n",
    "                other_node.child[local] = self\n",
    "                if local in self.father:\n",
    "                    other_node.father[local] = self.father.get(local)\n",
    "                    self.father.get(local).child[local] = other_node\n",
    "                self.father[local] = other_node\n",
    "\n",
    "\n",
    "def connect_two_node(father_node: DAGNode, child_node: DAGNode, local_index: int):\n",
    "    \"\"\"\n",
    "    Connect two DAG node through given local_index.\n",
    "\n",
    "    Args:\n",
    "        father_node (DAGNode): The father DAG node.\n",
    "        child_node (DAGNode): The child DAG node.\n",
    "        local_index (int): which leg you want to connect.\n",
    "    \"\"\"\n",
    "    if local_index not in father_node.local or local_index not in child_node.local:\n",
    "        raise ValueError(\n",
    "            f\"local_index {local_index} not in father_node\" f\" {father_node} or not in child_node {child_node}.\"\n",
    "        )\n",
    "    father_node.child[local_index] = child_node\n",
    "    child_node.father[local_index] = father_node\n",
    "\n",
    "\n",
    "class DAGQubitNode(DAGNode):\n",
    "    \"\"\"\n",
    "    DAG node that work as quantum qubit.\n",
    "\n",
    "    Args:\n",
    "        qubit (int): id of qubit.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, qubit: int):\n",
    "        \"\"\"Initialize a DAGQubitNode object.\"\"\"\n",
    "        super().__init__()\n",
    "        _check_input_type(\"qubit\", int, qubit)\n",
    "        self.qubit = qubit\n",
    "        self.local = [qubit]\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Return a string representation of qubit node.\"\"\"\n",
    "        return f\"q{self.qubit}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Return a string representation of qubit node.\"\"\"\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class GateNode(DAGNode):\n",
    "    \"\"\"\n",
    "    DAG node that work as quantum gate.\n",
    "\n",
    "    Args:\n",
    "        gate (:class:`~.core.gates.BasicGate`): Quantum gate.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gate: gates.BasicGate):\n",
    "        \"\"\"Initialize a GateNode object.\"\"\"\n",
    "        super().__init__()\n",
    "        _check_input_type(\"gate\", gates.BasicGate, gate)\n",
    "        self.gate = gate\n",
    "        self.local = gate.obj_qubits + gate.ctrl_qubits\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Return a string representation of gate node.\"\"\"\n",
    "        return str(self.gate)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Return a string representation of gate node.\"\"\"\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class BarrierNode(GateNode):\n",
    "    \"\"\"DAG node that work as barrier.\"\"\"\n",
    "\n",
    "    def __init__(self, gate: gates.BasicGate, all_qubits: typing.List[int]):\n",
    "        \"\"\"Initialize a BarrierNode object.\"\"\"\n",
    "        super().__init__(gate)\n",
    "        self.local = all_qubits\n",
    "\n",
    "\n",
    "class DAGCircuit:\n",
    "    \"\"\"\n",
    "    A Directed Acyclic Graph of a quantum circuit.\n",
    "\n",
    "    Args:\n",
    "        circuit (:class:`~.core.circuit.Circuit`): the input quantum circuit.\n",
    "\n",
    "    Examples:\n",
    "    from mindquantum.algorithm.compiler import DAGCircuit\n",
    "    from mindquantum.core.circuit import Circuit\n",
    "    circ = Circuit().h(0).x(1, 0)\n",
    "    dag_circ = DAGCircuit(circ)\n",
    "    dag_circ.head_node[0]\n",
    "        q0\n",
    "    dag_circ.head_node[0].child\n",
    "        {0: H(0)}\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, circuit: Circuit):\n",
    "        \"\"\"Initialize a DAGCircuit object.\"\"\"\n",
    "        _check_input_type(\"circuit\", Circuit, circuit)\n",
    "        self.head_node = {i: DAGQubitNode(i) for i in sorted(circuit.all_qubits.keys())}\n",
    "        self.final_node = {i: DAGQubitNode(i) for i in sorted(circuit.all_qubits.keys())}\n",
    "        for i in self.head_node:\n",
    "            self.head_node[i].insert_after(self.final_node[i])\n",
    "        for gate in circuit:\n",
    "            if isinstance(gate, gates.BarrierGate):\n",
    "                if gate.obj_qubits:\n",
    "                    self.append_node(BarrierNode(gate, sorted(gate.obj_qubits)))\n",
    "                else:\n",
    "                    self.append_node(BarrierNode(gate, sorted(circuit.all_qubits.keys())))\n",
    "            else:\n",
    "                self.append_node(GateNode(gate))\n",
    "        self.global_phase = gates.GlobalPhase(0)\n",
    "\n",
    "    @staticmethod\n",
    "    def replace_node_with_dag_circuit(node: DAGNode, coming: \"DAGCircuit\"):\n",
    "        \"\"\"\n",
    "        Replace a node with a DAGCircuit.\n",
    "\n",
    "        Args:\n",
    "            node (:class:`~.algorithm.compiler.DAGNode`): the original DAG node.\n",
    "            coming (:class:`~.algorithm.compiler.DAGCircuit`): the coming DAG circuit.\n",
    "\n",
    "        Examples:\n",
    "        from mindquantum.algorithm.compiler import DAGCircuit\n",
    "        from mindquantum.core.circuit import Circuit\n",
    "        circ = Circuit().x(1, 0)\n",
    "        circ\n",
    "            q0: ────■─────\n",
    "                    ┃\n",
    "                  ┏━┻━┓\n",
    "            q1: ──┨╺╋╸┠───\n",
    "                  ┗━━━┛\n",
    "        dag_circ = DAGCircuit(circ)\n",
    "        node = dag_circ.head_node[0].child[0]\n",
    "        node\n",
    "            X(1 <-: 0)\n",
    "        sub_dag = DAGCircuit(Circuit().h(1).z(1, 0).h(1))\n",
    "        DAGCircuit.replace_node_with_dag_circuit(node, sub_dag)\n",
    "        dag_circ.to_circuit()\n",
    "            q0: ──────────■───────────\n",
    "                          ┃\n",
    "                  ┏━━━┓ ┏━┻━┓ ┏━━━┓\n",
    "            q1: ──┨ H ┠─┨ Z ┠─┨ H ┠───\n",
    "                  ┗━━━┛ ┗━━━┛ ┗━━━┛\n",
    "        \"\"\"\n",
    "        if set(node.local) != {head.qubit for head in coming.head_node.values()}:\n",
    "            raise ValueError(f\"Circuit in coming DAG is not aligned with gate in node: {node}\")\n",
    "        for local in node.local:\n",
    "            connect_two_node(node.father[local], coming.head_node[local].child[local], local)\n",
    "            connect_two_node(coming.final_node[local].father[local], node.child[local], local)\n",
    "\n",
    "    def append_node(self, node: DAGNode):\n",
    "        \"\"\"\n",
    "        Append a quantum gate node.\n",
    "\n",
    "        Args:\n",
    "            node (:class:`~.algorithm.compiler.DAGNode`): the DAG node you want to append.\n",
    "\n",
    "        Examples:\n",
    "        from mindquantum.algorithm.compiler import DAGCircuit, GateNode\n",
    "        from mindquantum.core.circuit import Circuit\n",
    "        import mindquantum.core.gates as G\n",
    "        circ = Circuit().h(0).x(1, 0)\n",
    "        circ\n",
    "                  ┏━━━┓\n",
    "            q0: ──┨ H ┠───■─────\n",
    "                  ┗━━━┛   ┃\n",
    "                        ┏━┻━┓\n",
    "            q1: ────────┨╺╋╸┠───\n",
    "                        ┗━━━┛\n",
    "        dag_circ = DAGCircuit(circ)\n",
    "        node = GateNode(G.RX('a').on(0, 2))\n",
    "        dag_circ.append_node(node)\n",
    "        dag_circ.to_circuit()\n",
    "                  ┏━━━┓       ┏━━━━━━━┓\n",
    "            q0: ──┨ H ┠───■───┨ RX(a) ┠───\n",
    "                  ┗━━━┛   ┃   ┗━━━┳━━━┛\n",
    "                        ┏━┻━┓     ┃\n",
    "            q1: ────────┨╺╋╸┠─────╂───────\n",
    "                        ┗━━━┛     ┃\n",
    "                                  ┃\n",
    "            q2: ──────────────────■───────\n",
    "        \"\"\"\n",
    "        _check_input_type('node', DAGNode, node)\n",
    "        for local in node.local:\n",
    "            if local not in self.head_node:\n",
    "                self.head_node[local] = DAGQubitNode(local)\n",
    "                self.final_node[local] = DAGQubitNode(local)\n",
    "                self.head_node[local].insert_after(self.final_node[local])\n",
    "            self.final_node[local].insert_before(node)\n",
    "\n",
    "    def depth(self) -> int:\n",
    "        \"\"\"\n",
    "        Return the depth of quantum circuit.\n",
    "\n",
    "        Examples:\n",
    "        from mindquantum.core.circuit import Circuit\n",
    "        from mindquantum.algorithm.compiler import DAGCircuit\n",
    "        circ = Circuit().h(0).h(1).x(1, 0)\n",
    "        circ\n",
    "                  ┏━━━┓\n",
    "            q0: ──┨ H ┠───■─────\n",
    "                  ┗━━━┛   ┃\n",
    "                  ┏━━━┓ ┏━┻━┓\n",
    "            q1: ──┨ H ┠─┨╺╋╸┠───\n",
    "                  ┗━━━┛ ┗━━━┛\n",
    "        DAGCircuit(circ).depth()\n",
    "            2\n",
    "        \"\"\"\n",
    "        return len(self.layering())\n",
    "\n",
    "    def find_all_gate_node(self) -> typing.List[GateNode]:\n",
    "        \"\"\"\n",
    "        Find all gate node in this :class:`~.algorithm.compiler.DAGCircuit`.\n",
    "\n",
    "        Returns:\n",
    "            List[:class:`~.algorithm.compiler.GateNode`], a list of all :class:`~.algorithm.compiler.GateNode`\n",
    "            of this :class:`~.algorithm.compiler.DAGCircuit`.\n",
    "\n",
    "        Examples:\n",
    "        from mindquantum.algorithm.compiler import DAGCircuit\n",
    "        from mindquantum.core.circuit import Circuit\n",
    "        circ = Circuit().h(0).x(1, 0)\n",
    "        dag_circ = DAGCircuit(circ)\n",
    "        dag_circ.find_all_gate_node()\n",
    "            [H(0), X(1 <-: 0)]\n",
    "        \"\"\"\n",
    "        found = set(self.head_node.values())\n",
    "\n",
    "        def _find(current_node: DAGNode, found):\n",
    "            if current_node not in found:\n",
    "                found.add(current_node)\n",
    "                for node in current_node.father.values():\n",
    "                    _find(node, found)\n",
    "                for node in current_node.child.values():\n",
    "                    _find(node, found)\n",
    "\n",
    "        for head_node in self.head_node.values():\n",
    "            for current_node in head_node.child.values():\n",
    "                _find(current_node, found)\n",
    "        return [i for i in found if not isinstance(i, DAGQubitNode)]\n",
    "\n",
    "    def layering(self) -> typing.List[Circuit]:\n",
    "        r\"\"\"\n",
    "        Layering the quantum circuit.\n",
    "\n",
    "        Returns:\n",
    "            List[:class:`~.core.circuit.Circuit`], a list of layered quantum circuit.\n",
    "\n",
    "        Examples:\n",
    "        from mindquantum.algorithm.compiler import DAGCircuit\n",
    "        from mindquantum.utils import random_circuit\n",
    "        circ = random_circuit(3, 5, seed=42)\n",
    "        circ\n",
    "                  ┏━━━━━━━━━━━━━┓   ┏━━━━━━━━━━━━━┓\n",
    "            q0: ──┨             ┠─╳─┨ RY(-6.1944) ┠───────────────────\n",
    "                  ┃             ┃ ┃ ┗━━━━━━┳━━━━━━┛\n",
    "                  ┃ Rxx(1.2171) ┃ ┃        ┃        ┏━━━━━━━━━━━━━┓\n",
    "            q1: ──┨             ┠─┃────────╂────────┨             ┠───\n",
    "                  ┗━━━━━━━━━━━━━┛ ┃        ┃        ┃             ┃\n",
    "                  ┏━━━━━━━━━━━━┓  ┃        ┃        ┃ Rzz(-0.552) ┃\n",
    "            q2: ──┨ PS(2.6147) ┠──╳────────■────────┨             ┠───\n",
    "                  ┗━━━━━━━━━━━━┛                    ┗━━━━━━━━━━━━━┛\n",
    "        dag_circ = DAGCircuit(circ)\n",
    "        for idx, c in enumerate(dag_circ.layering()):\n",
    "            ...     print(f\"layer {idx}:\")\n",
    "            ...     print(c)\n",
    "            layer 0:\n",
    "                  ┏━━━━━━━━━━━━━┓\n",
    "            q0: ──┨             ┠───\n",
    "                  ┃             ┃\n",
    "                  ┃ Rxx(1.2171) ┃\n",
    "            q1: ──┨             ┠───\n",
    "                  ┗━━━━━━━━━━━━━┛\n",
    "                  ┏━━━━━━━━━━━━┓\n",
    "            q2: ──┨ PS(2.6147) ┠────\n",
    "                  ┗━━━━━━━━━━━━┛\n",
    "            layer 1:\n",
    "            q0: ──╳───\n",
    "                  ┃\n",
    "                  ┃\n",
    "            q2: ──╳───\n",
    "            layer 2:\n",
    "                  ┏━━━━━━━━━━━━━┓\n",
    "            q0: ──┨ RY(-6.1944) ┠───\n",
    "                  ┗━━━━━━┳━━━━━━┛\n",
    "                         ┃\n",
    "            q2: ─────────■──────────\n",
    "            layer 3:\n",
    "                  ┏━━━━━━━━━━━━━┓\n",
    "            q1: ──┨             ┠───\n",
    "                  ┃             ┃\n",
    "                  ┃ Rzz(-0.552) ┃\n",
    "            q2: ──┨             ┠───\n",
    "                  ┗━━━━━━━━━━━━━┛\n",
    "        \"\"\"\n",
    "\n",
    "        def _layering(current_node: GateNode, depth_map):\n",
    "            \"\"\"Layering the quantum circuit.\"\"\"\n",
    "            if current_node.father:\n",
    "                prev_depth = []\n",
    "                for father_node in current_node.father.values():\n",
    "                    if father_node not in depth_map:\n",
    "                        _layering(father_node, depth_map)\n",
    "                    prev_depth.append(depth_map[father_node])\n",
    "                depth_map[current_node] = max(prev_depth) + 1\n",
    "            for child in current_node.child.values():\n",
    "                if not isinstance(child, DAGQubitNode):\n",
    "                    if child not in depth_map:\n",
    "                        _layering(child, depth_map)\n",
    "\n",
    "        depth_map = {i: 0 for i in self.head_node.values()}\n",
    "        for current_node in self.head_node.values():\n",
    "            _layering(current_node, depth_map)\n",
    "        layer = [Circuit() for _ in range(len(set(depth_map.values())) - 1)]\n",
    "        for k, v in depth_map.items():\n",
    "            if v != 0:\n",
    "                if not isinstance(k, BarrierNode):\n",
    "                    layer[v - 1] += k.gate\n",
    "        return [c for c in layer if len(c) != 0]\n",
    "\n",
    "    def to_circuit(self) -> Circuit:\n",
    "        \"\"\"\n",
    "        Convert :class:`~.algorithm.compiler.DAGCircuit` to quantum circuit.\n",
    "\n",
    "        Returns:\n",
    "            :class:`~.core.circuit.Circuit`, the quantum circuit of this DAG.\n",
    "\n",
    "        Examples:\n",
    "        from mindquantum.core.circuit import Circuit\n",
    "        from mindquantum.algorithm.compiler import DAGCircuit\n",
    "        circ = Circuit().h(0).h(1).x(1, 0)\n",
    "        circ\n",
    "                  ┏━━━┓\n",
    "            q0: ──┨ H ┠───■─────\n",
    "                  ┗━━━┛   ┃\n",
    "                  ┏━━━┓ ┏━┻━┓\n",
    "            q1: ──┨ H ┠─┨╺╋╸┠───\n",
    "                  ┗━━━┛ ┗━━━┛\n",
    "        dag_circ = DAGCircuit(circ)\n",
    "        dag_circ.to_circuit()\n",
    "                  ┏━━━┓\n",
    "            q0: ──┨ H ┠───■─────\n",
    "                  ┗━━━┛   ┃\n",
    "                  ┏━━━┓ ┏━┻━┓\n",
    "            q1: ──┨ H ┠─┨╺╋╸┠───\n",
    "                  ┗━━━┛ ┗━━━┛\n",
    "        \"\"\"\n",
    "        circuit = Circuit()\n",
    "        considered_node = set(self.head_node.values())\n",
    "\n",
    "        def adding_current_node(current_node, circuit, considered):\n",
    "            if all(i in considered for i in current_node.father.values()) and not isinstance(\n",
    "                current_node, DAGQubitNode\n",
    "            ):\n",
    "                circuit += current_node.gate\n",
    "                considered.add(current_node)\n",
    "            else:\n",
    "                for node in current_node.father.values():\n",
    "                    if node not in considered:\n",
    "                        adding_current_node(node, circuit, considered)\n",
    "                for node in current_node.child.values():\n",
    "                    if node not in considered:\n",
    "                        adding_current_node(node, circuit, considered)\n",
    "\n",
    "        for current_node in self.final_node.values():\n",
    "            adding_current_node(current_node, circuit, considered_node)\n",
    "        return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b13110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve information about the neighbors of each vertex in graph g\n",
    "def get_info_neighbors(g):\n",
    "    info = {}  # Dictionary to store neighbor information for each vertex\n",
    "    \n",
    "    n = len(g.nodes())  # Get the number of vertices in the graph g\n",
    "    \n",
    "    # Iterate through all vertices in the graph\n",
    "    for k in g.nodes():\n",
    "        neighbors = []  #List to store neighbors of the current vertex k\n",
    "        \n",
    "        # Iterate through all edges in the graph\n",
    "        for u, v in g.edges:\n",
    "            # Check if vertex v is adjacent to k\n",
    "            if v == k:\n",
    "                neighbors.append(u)  # Add the other endpoint u as a neighbor\n",
    "            \n",
    "            # Check if vertex u is adjacent to k\n",
    "            if u == k:\n",
    "                neighbors.append(v)  # Add the other endpoint v as a neighbor\n",
    "        \n",
    "        # Store the vertex k and its neighbors in the dictionary\n",
    "        info[k] = neighbors\n",
    "    \n",
    "    # Optional: Log the information about vertices and their neighbors (commented out)\n",
    "    # my_logger.info('Vertex and its neighbors: {}'.format(info))\n",
    "    \n",
    "    return info  # Return the dictionary containing neighbor information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aad3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the initial quantum state, here chosen as the all-zero state\n",
    "def create_encoder():\n",
    "    encoder = Circuit()  # Initialize an empty quantum circuit\n",
    "    return encoder  # Return the quantum circuit\n",
    "\n",
    "# Function to construct one layer of the target unitary operator based on the target Hamiltonian, parameterized by gamma\n",
    "def build_U_HD(layer, target_graph):\n",
    "    # Initialize a quantum circuit\n",
    "    cir_HD = Circuit()\n",
    "    \n",
    "    # Add RZ gates for each vertex in the target graph, parameterized by gamma\n",
    "    for v in target_graph.nodes:\n",
    "        cir_HD += RZ('gamma{}'.format(layer)).on(v)\n",
    "    \n",
    "    return cir_HD  # Return the constructed circuit\n",
    "\n",
    "# Function to construct one layer of the mixer unitary operator based on the initial Hamiltonian, parameterized by beta\n",
    "def build_U_HM(layer, info):\n",
    "    # Initialize a quantum circuit for n qubits\n",
    "    cir_HM = Circuit()\n",
    "    \n",
    "    # Iterate through the neighbor information dictionary\n",
    "    for key, value in info.items():\n",
    "        if len(value) != 0:\n",
    "            # MindQuantum only supports controlled gates where control qubits are all |1>,\n",
    "            # To achieve flipping with all control qubits in |0>, we process the control qubits\n",
    "            \n",
    "            # Flip the states of neighboring qubits\n",
    "            for i in range(len(value)):\n",
    "                cir_HM += X.on(value[i])  # Apply X gate to flip the qubit\n",
    "            \n",
    "            # Apply a multi-qubit controlled RX gate with the target as the first qubit\n",
    "            cir_HM += RX('beta{}'.format(layer)).on(key, value)\n",
    "            \n",
    "            # Flip the states of neighboring qubits back to the original\n",
    "            for i in range(len(value)):\n",
    "                cir_HM += X.on(value[i])\n",
    "            \n",
    "            # Add a barrier for clarity and separation\n",
    "            cir_HM.barrier()\n",
    "        else:\n",
    "            # If the vertex is isolated, directly add it to the vertex subset\n",
    "            cir_HM += RX('beta{}'.format(layer)).on(key)  # Apply RX gate to the isolated qubit\n",
    "            cir_HM.barrier()  # Add a barrier for clarity\n",
    "\n",
    "    return cir_HM  # Return the constructed mixer unitary operator circuit\n",
    "\n",
    "# Function to construct a p-layer QAOA+ ansatz\n",
    "def build_ansatz(p, target_graph):\n",
    "    # Prepare the initial state; any feasible solution can be used\n",
    "    encoder = create_encoder()\n",
    "    \n",
    "    # Get neighbor information for the target graph to assist in circuit construction\n",
    "    info = get_info_neighbors(target_graph)\n",
    "    \n",
    "    # Construct the QAOA+ ansatz with p layers; alternate between the target and initial Hamiltonian circuits\n",
    "    ansatz = Circuit()\n",
    "    for layer in range(1, p + 1):\n",
    "        ansatz += build_U_HD(layer, target_graph)  # Add the target Hamiltonian circuit\n",
    "        ansatz += build_U_HM(layer, info)         # Add the mixer Hamiltonian circuit\n",
    "        \n",
    "        # Add a barrier to separate layers\n",
    "        ansatz.barrier()\n",
    "    \n",
    "    return encoder, ansatz  # Return the initial state circuit and the ansatz circuit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39ddafeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to construct the initial parameterized quantum circuit (PQC)\n",
    "# Methods 2 and 3 apply mixers only on a subset of vertices\n",
    "def build_initial_PQC(target_graph):\n",
    "    # Method 1: Apply mixers on all vertices (i.e., using a complete QAOA+ ansatz for one layer)\n",
    "    # Uncomment the following lines to enable Method 1\n",
    "    # encoder, ansatz = build_ansatz(1, target_graph)\n",
    "    # circ = encoder + ansatz\n",
    "    # allowed_applied_nodes = []\n",
    "    # for node in V:\n",
    "    #     allowed_applied_nodes.append(node)\n",
    "\n",
    "    # Method 2: Assign mixers based on node degree\n",
    "    # If the degree of a node is less than or equal to the average degree, assign a mixer\n",
    "    # Uncomment the following lines to enable Method 2\n",
    "    # m = len(E)  # Number of edges in the graph\n",
    "    # avg_d = (2 * m) / len(V)  # Calculate the average degree\n",
    "    # layer = 1  # Specify the layer\n",
    "    # allowed_applied_nodes = []  # List of vertices allowed for mixer application\n",
    "    # for node, values in info.items():\n",
    "    #     d = len(info[node])  # Degree of the node\n",
    "    #     if d <= avg_d:\n",
    "    #         allowed_applied_nodes.append(node)\n",
    "    #\n",
    "    # # Construct the target Hamiltonian unitary operation\n",
    "    # circ = build_U_HD(1, target_graph)\n",
    "    #\n",
    "    # # Construct the mixer Hamiltonian unitary operation\n",
    "    # for node in allowed_applied_nodes:\n",
    "    #     value = info[node]  # Get neighbors of the node\n",
    "    #     \n",
    "    #     # Apply mixers on the node\n",
    "    #     if len(value) != 0:\n",
    "    #         # Flip the states of neighboring qubits\n",
    "    #         for i in range(len(value)):\n",
    "    #             circ += X.on(value[i])\n",
    "    #\n",
    "    #         # Apply a multi-qubit controlled RX gate\n",
    "    #         circ += RX('beta{}'.format(layer)).on(node, value)\n",
    "    #\n",
    "    #         # Flip the states of neighboring qubits back to original\n",
    "    #         for i in range(len(value)):\n",
    "    #             circ += X.on(value[i])\n",
    "    #\n",
    "    #         circ.barrier()  # Add a barrier\n",
    "    #     else:\n",
    "    #         # Apply RX gate directly for isolated vertices\n",
    "    #         circ += RX('beta{}'.format(layer)).on(node)\n",
    "    #         circ.barrier()\n",
    "\n",
    "    # Method 3: Random assignment of vertices (suitable for regular graphs)\n",
    "    layer = 1  # Specify the layer\n",
    "    allowed_applied_nodes = []  # List to store vertices for mixer application\n",
    "    # For regular graphs, randomly select t vertices where t <= min{t1, t2}\n",
    "    t1 = n - k  # Compute t1 based on the problem requirements\n",
    "    t2 = int(n / 2)  # Compute t2 as half the number of vertices\n",
    "    t = min(t1, t2)  # Take the smaller of t1 and t2\n",
    "\n",
    "    # Randomly select t vertices for mixer application\n",
    "    while len(allowed_applied_nodes) <= t:\n",
    "        node = random.randint(0, n - 1)  # Select a random vertex\n",
    "        if node not in allowed_applied_nodes:\n",
    "            allowed_applied_nodes.append(node)\n",
    "    my_logger.info('Vertices selected for mixer application in the first layer: {}'.format(allowed_applied_nodes))\n",
    "\n",
    "    # Construct the target Hamiltonian unitary operation\n",
    "    circ = build_U_HD(1, target_graph)\n",
    "\n",
    "    # Construct the mixer Hamiltonian unitary operation\n",
    "    for node in allowed_applied_nodes:\n",
    "        value = info[node]  # Get neighbors of the node\n",
    "\n",
    "        # Apply mixers on the node\n",
    "        if len(value) != 0:\n",
    "            # Flip the states of neighboring qubits\n",
    "            for i in range(len(value)):\n",
    "                circ += X.on(value[i])\n",
    "\n",
    "            # Apply a multi-qubit controlled RX gate\n",
    "            circ += RX('beta{}'.format(layer)).on(node, value)\n",
    "\n",
    "            # Flip the states of neighboring qubits back to original\n",
    "            for i in range(len(value)):\n",
    "                circ += X.on(value[i])\n",
    "\n",
    "            circ.barrier()  # Add a barrier\n",
    "        else:\n",
    "            # Apply RX gate directly for isolated vertices\n",
    "            circ += RX('beta{}'.format(layer)).on(node)\n",
    "            circ.barrier()\n",
    "\n",
    "    return circ, allowed_applied_nodes  # Return the constructed circuit and the selected nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf2dfc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the updated quantum circuit\n",
    "# The updated circuit is constructed by adding the latest operators to the already optimized circuit.\n",
    "# The list `applied_nodes` contains the vertices where mixers are allowed, and `info` provides adjacency information.\n",
    "def build_latest_PQC(updated_pqc, layer, applied_nodes, info):\n",
    "    \"\"\"\n",
    "    Build the latest parameterized quantum circuit (PQC).\n",
    "    \n",
    "    Args:\n",
    "        updated_pqc: The current quantum circuit that has been optimized so far.\n",
    "        layer: The current layer of the circuit.\n",
    "        applied_nodes: List of vertices where mixers are allowed to act.\n",
    "        info: Dictionary containing adjacency information for each vertex.\n",
    "    \n",
    "    Returns:\n",
    "        updated_pqc: The updated quantum circuit with the new operators applied.\n",
    "    \"\"\"\n",
    "    # Add a new layer of the target unitary operator\n",
    "    updated_pqc += build_U_HD(layer, target_graph)\n",
    "    \n",
    "    # Add adaptive \\( e^{-i \\beta H_{M}} \\) operations for the specified layer\n",
    "    for node in applied_nodes:\n",
    "        value = info[node]  # Retrieve neighboring nodes for the current vertex\n",
    "\n",
    "        # Apply the corresponding mixer on the vertex\n",
    "        if len(value) != 0:  # If the vertex has neighbors\n",
    "            # Apply X gates to flip the state of neighboring qubits\n",
    "            for i in range(len(value)):\n",
    "                updated_pqc += X.on(value[i])\n",
    "\n",
    "            # Apply a multi-qubit controlled RX gate\n",
    "            # The first argument is the target qubit (the node itself), and the second is the list of control qubits (neighbors)\n",
    "            updated_pqc += RX('beta{}'.format(layer)).on(node, value)\n",
    "\n",
    "            # Apply X gates again to revert the state of neighboring qubits\n",
    "            for i in range(len(value)):\n",
    "                updated_pqc += X.on(value[i])\n",
    "\n",
    "            updated_pqc.barrier()  # Add a barrier for clarity in visualization\n",
    "        else:\n",
    "            # Directly apply the RX gate if the vertex is isolated (no neighbors)\n",
    "            updated_pqc += RX('beta{}'.format(layer)).on(node)\n",
    "            updated_pqc.barrier()  # Add a barrier for clarity\n",
    "    \n",
    "    return updated_pqc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2246d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the initial expectation function value given the initial parameters\n",
    "# N_pm represents the number of mixers in the current layer\n",
    "# Lists beta and gamma store the current circuit parameters (including the new layer and the optimized layer)\n",
    "def calculate_initial_expectation_value(circ, beta, gamma):\n",
    "    # Store parameters: first store gamma parameters, then beta parameters\n",
    "    params = []\n",
    "    for i in range(len(gamma)):\n",
    "        params.append(gamma[i])  # Add gamma parameters to the parameter list\n",
    "    \n",
    "    # For the mixer unitary operation, reuse optimized parameters for the first (p-1) layers\n",
    "    # Randomly initialize parameters for the p-th layer\n",
    "    for i in range(len(beta)):\n",
    "        params.append(beta[i])  # Add beta parameters to the parameter list\n",
    "    \n",
    "    \n",
    "    # Create a simulator using 'mqvector' backend\n",
    "    # The simulator can handle circuits with up to the number of qubits specified in 'circ'\n",
    "    sim = Simulator('projectq', circ.n_qubits)\n",
    "    \n",
    "    # Create a parameter resolver to map circuit parameters to their values\n",
    "    pr = dict(zip(circ.params_name, params))\n",
    "    \n",
    "    # Apply the circuit to the simulator with the resolved parameters\n",
    "    sim.apply_circuit(circ, pr=pr)\n",
    "    \n",
    "    # Uncomment the following line to print the quantum state (debugging purposes)\n",
    "    # print(sim.get_qs(True))\n",
    "    \n",
    "    # Compute the expectation value of the Hamiltonian\n",
    "    expectation = sim.get_expectation(ham)\n",
    "    \n",
    "    # Return the negative real part of the expectation value\n",
    "    # (Assuming minimization is the goal in the optimization process)\n",
    "    return -1 * (expectation.real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2acd5ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MQAnsatzOnlyLayer(nn.Cell):\n",
    "    def __init__(self, expectation_with_grad, params, weight='normal'):\n",
    "        \"\"\"\n",
    "        Initialize an MQAnsatzOnlyLayer object.\n",
    "        \n",
    "        Args:\n",
    "            expectation_with_grad: An object that computes the expectation value and its gradient.\n",
    "            params: Initial parameters for the quantum ansatz (a numpy array of shape [gamma0, beta0, gamma1, beta1, ...]).\n",
    "            weight: Initialization method for the parameter weights. Defaults to 'normal'. Can also accept a Tensor.\n",
    "        \"\"\"\n",
    "        super().__init__()  # Initialize the parent class\n",
    "        \n",
    "        # Initialize the MQAnsatzOnlyOps object\n",
    "        self.evolution = MQAnsatzOnlyOps(expectation_with_grad)\n",
    "        \n",
    "        # Determine the size of the weight tensor from the ansatz parameters\n",
    "        weight_size = len(self.evolution.expectation_with_grad.ansatz_params_name)\n",
    "        \n",
    "        # Validate the shape of the provided weight tensor, if specified\n",
    "        if isinstance(weight, ms.Tensor):\n",
    "            if weight.ndim != 1 or weight.shape[0] != weight_size:\n",
    "                raise ValueError(\n",
    "                    f\"Weight init shape error, required ({weight_size}, ), but got {weight.shape}.\"\n",
    "                )\n",
    "        \n",
    "        # Initialize the parameter tensor\n",
    "        # Convert the input parameters to a float32 tensor\n",
    "        # Initial parameters (params) are in the form [gamma0, beta0, gamma1, beta1, ...]\n",
    "        self.weight = Parameter(params.astype(np.float32), name='ansatz_weight')\n",
    "        \n",
    "        # Log the initialized weight values for debugging\n",
    "        my_logger.info('weight = {}'.format(self.weight.asnumpy()))\n",
    "\n",
    "    def construct(self):\n",
    "        \"\"\"\n",
    "        Construct the MQAnsatzOnlyLayer node.\n",
    "        \n",
    "        This method defines the forward computation of the layer.\n",
    "        It applies the quantum evolution operator with the current weight parameters.\n",
    "        \"\"\"\n",
    "        return self.evolution(self.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efd4d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute the optimization process for a quantum circuit based on convergence error\n",
    "def execute_function(target_graph, circuit, beta, gamma):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        target_graph: The graph representing the problem to solve.\n",
    "        circuit: The quantum circuit to be optimized.\n",
    "        beta: Initial beta parameters for the ansatz.\n",
    "        gamma: Initial gamma parameters for the ansatz.\n",
    "    \n",
    "    Returns:\n",
    "        result: Measurement results after sampling.\n",
    "        gamma_opt: Optimized gamma parameters.\n",
    "        beta_opt: Optimized beta parameters.\n",
    "        loss: Final optimized expectation value (negated for maximization).\n",
    "        loss0: List of expectation values during the optimization process.\n",
    "    \"\"\"\n",
    "    lr = 0.05  # Learning rate\n",
    "    ITR = 600  # Maximum number of iterations\n",
    "    \n",
    "    # Store parameters in order: gamma first, then beta\n",
    "    # params = [gamma1, beta1, beta2, ...] for the AMA algorithm\n",
    "    params = []\n",
    "    for i in range(len(gamma)):\n",
    "        params.append(gamma[i])\n",
    "    for i in range(len(beta)):\n",
    "        params.append(beta[i])\n",
    "    \n",
    "    my_logger.info('This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = {}'.format(params))\n",
    "    ms.set_context(mode=ms.PYNATIVE_MODE, device_target=\"CPU\")  # Set the computation context\n",
    "\n",
    "    # Convert the parameter list to a numpy array\n",
    "    params = np.array(params)\n",
    "\n",
    "    # Create a quantum simulator using the 'projectq' backend\n",
    "    sim = Simulator('projectq', circuit.n_qubits)\n",
    "\n",
    "    # Get the operator for computing expectation value and its gradient\n",
    "    grad_ops = sim.get_expectation_with_grad(ham, circuit)\n",
    "    \n",
    "    # Initialize the quantum network layer with the gradient operator and parameters\n",
    "    QuantumNet = MQAnsatzOnlyLayer((grad_ops), params)\n",
    "\n",
    "    # Set up the optimizer (Adam) for trainable parameters with a specified learning rate\n",
    "    opti = Adam(QuantumNet.trainable_params(), learning_rate=lr)\n",
    "    \n",
    "    # Create a training step for the network\n",
    "    train_net = nn.TrainOneStepCell(QuantumNet, opti)\n",
    "    \n",
    "    my_logger.info('lr = {}, ITR = {}'.format(lr, ITR))\n",
    "    \n",
    "    # List to store the expectation values during training\n",
    "    loss0 = []\n",
    "    for i in range(ITR + 1):\n",
    "        # Train one step and get the optimized expectation value\n",
    "        loss = train_net().asnumpy()[0]\n",
    "        loss0.append(loss)\n",
    "        \n",
    "        # Check convergence based on consecutive expectation value differences\n",
    "        if i >= 2:\n",
    "            l = len(loss0)\n",
    "            delta1 = abs(loss0[l - 1] - loss0[l - 2])\n",
    "            delta2 = abs(loss0[l - 2] - loss0[l - 3])\n",
    "            if delta1 <= 0.001 and delta2 <= 0.001:\n",
    "                my_logger.info('Convergence reached after {} iterations. Expectation value evolution: loss0 = {}'.format(len(loss0), loss0))\n",
    "                break\n",
    "            else:\n",
    "                # Log every 50 steps\n",
    "                if i % 50 == 0:\n",
    "                    my_logger.info(\"train_step = {}, loss = {}\".format(i, round(loss, 5)))\n",
    "    \n",
    "    # Number of iterations consumed\n",
    "    consumed_iter = len(loss0)\n",
    "    my_logger.info('Number of iterations consumed: {}'.format(consumed_iter))\n",
    "    \n",
    "    # Retrieve the optimized parameters\n",
    "    beta_opt = []\n",
    "    gamma_opt = []\n",
    "    params = []\n",
    "    \n",
    "    # Extract circuit parameters\n",
    "    pr = dict(zip(circuit.params_name, QuantumNet.weight.asnumpy()))\n",
    "    for key, value in pr.items():\n",
    "        params.append(value)\n",
    "    my_logger.info('Optimized circuit parameters: params = {}'.format(params))\n",
    "    my_logger.info('\\n\\n')\n",
    "    \n",
    "    # Separate optimized gamma and beta parameters\n",
    "    if len(beta) == 1:\n",
    "        for i in range(len(params)):\n",
    "            if i % 2 == 0:\n",
    "                gamma_opt.append(params[i])\n",
    "            else:\n",
    "                beta_opt.append(params[i])\n",
    "    else:\n",
    "        for i in range(len(params)):\n",
    "            if i == 0:\n",
    "                gamma_opt.append(params[i])\n",
    "            else:\n",
    "                beta_opt.append(params[i])\n",
    "    \n",
    "    # Apply measurement operations on all vertices in the graph\n",
    "    for i in target_graph.nodes():\n",
    "        circuit += Measure('q_{}'.format(i)).on(i)\n",
    "\n",
    "    # Perform sampling with the optimized parameters\n",
    "    result = sim.sampling(circuit, pr=pr, shots=1000)\n",
    "    \n",
    "    # Return results: measurements, optimized parameters, and the final expectation value\n",
    "    return result, gamma_opt, beta_opt, -round(loss, 5), loss0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb3dd118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_training(ham, g, circ, SEED, initial_beta, initial_gamma):\n",
    "    \"\"\"\n",
    "    Function to perform global training for the quantum circuit.\n",
    "    \n",
    "    Args:\n",
    "        ham: The Hamiltonian representing the problem.\n",
    "        g: The graph representing the problem structure.\n",
    "        circ: The quantum circuit to be optimized.\n",
    "        SEED: Seed for random initialization to ensure reproducibility.\n",
    "        initial_beta: List to store beta parameters for the ansatz.\n",
    "        initial_gamma: List to store gamma parameters for the ansatz.\n",
    "    \n",
    "    Returns:\n",
    "        result: Measurement results after optimization.\n",
    "        gamma_opt: Optimized gamma parameters.\n",
    "        beta_opt: Optimized beta parameters.\n",
    "        loss: Final optimized expectation value (negated for maximization).\n",
    "        loss0: List of expectation values during the optimization process.\n",
    "    \"\"\"\n",
    "    # Randomly initialize 2p circuit parameters\n",
    "    # Use a uniform distribution in the range [minval, maxval)\n",
    "    # minval and maxval are Tensor types\n",
    "    minval = Tensor(0, ms.float32)  # Minimum value of the range\n",
    "    maxval = Tensor(np.pi, ms.float32)  # Maximum value of the range\n",
    "    shape = tuple([1])  # Shape of the tensor\n",
    "\n",
    "    # Randomly initialize the parameters for the latest ansatz layer\n",
    "    if len(initial_beta) == 0:\n",
    "        # For the first layer, initialize both gamma and beta\n",
    "        param = ops.uniform(shape, minval, maxval, seed=SEED, dtype=ms.float32)\n",
    "        initial_beta.append(param.asnumpy()[0])  # Append beta parameter\n",
    "        \n",
    "        param = ops.uniform(shape, minval, maxval, seed=SEED, dtype=ms.float32)\n",
    "        initial_gamma.append(param.asnumpy()[0])  # Append gamma parameter\n",
    "    else:\n",
    "        # For subsequent layers, only initialize beta\n",
    "        param = ops.uniform(shape, minval, maxval, seed=SEED, dtype=ms.float32)\n",
    "        initial_beta.append(param.asnumpy()[0])  # Append beta parameter\n",
    "        \n",
    "        param = ops.uniform(shape, minval, maxval, seed=SEED, dtype=ms.float32)\n",
    "        initial_gamma.append(param.asnumpy()[0])  # Append gamma parameter\n",
    "    \n",
    "    # Log the initialized parameters and SEED\n",
    "    my_logger.info('SEED = {}, initial_beta = {}, initial_gamma = {}'.format(SEED, initial_beta, initial_gamma))\n",
    "\n",
    "    # Parameter optimization\n",
    "    # Perform optimization and retrieve optimized beta and gamma parameters\n",
    "    result, gamma_opt, beta_opt, loss, loss0 = execute_function(g, circ, initial_beta, initial_gamma)\n",
    "\n",
    "    return result, gamma_opt, beta_opt, loss, loss0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57921237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search for optimized parameters for 1-layer QAOA+ ansatz\n",
    "# The function performs multiple global random initializations to find the max_loss and corresponding optimized parameters\n",
    "def search_optimized_parameters(circ, g):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        circ: The quantum circuit to optimize.\n",
    "        g: The graph representing the problem structure.\n",
    "\n",
    "    Returns:\n",
    "        params_opt: Optimized parameters corresponding to max_loss.\n",
    "        max_loss: The maximum expectation value obtained.\n",
    "        avg: The average expectation value across all random initializations.\n",
    "        value: List of expectation values from each optimization run.\n",
    "        avg_iterations: Average number of iterations consumed across all optimization runs.\n",
    "    \"\"\"\n",
    "    ham = build_ham(g)  # Generate the Hamiltonian\n",
    "    \n",
    "    # Initialize storage for results\n",
    "    value = []  # Stores the expectation value after optimization for each initialization\n",
    "    params = []  # Stores optimized parameters\n",
    "    measure_result = []  # Stores measurement results\n",
    "    ITR = []  # Stores the number of iterations consumed for each run\n",
    "    \n",
    "    my_logger.info('\\n\\n')  # Log separator\n",
    "\n",
    "    SEED = []  # List to store seeds for random initialization\n",
    "    for k in range(0, counts):\n",
    "        seed = random.randint(1, 2500)  # Generate random seed\n",
    "        SEED.append(seed)\n",
    "        \n",
    "    # Perform optimization for each random initialization\n",
    "    for i in range(1, counts + 1):\n",
    "        initial_beta = []  # Initialize beta parameters\n",
    "        initial_gamma = []  # Initialize gamma parameters\n",
    "        temp_circuit = copy.deepcopy(circ)  # Create a deep copy of the circuit for modification\n",
    "        my_logger.info('The {}-th global random initialization'.format(i))\n",
    "        \n",
    "        # Perform global training and retrieve optimization results\n",
    "        result, gamma_opt, beta_opt, loss, loss0 = global_training(\n",
    "            ham, g, temp_circuit, SEED[i - 1], initial_beta, initial_gamma\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        value.append(loss)\n",
    "        params.append([beta_opt, gamma_opt])\n",
    "        measure_result.append(result.data)\n",
    "        ITR.append(len(loss0))\n",
    "    \n",
    "    # Log the collected information\n",
    "    my_logger.info('Global random initialization complete. Logging results...')\n",
    "    my_logger.info('value = {}'.format(value))\n",
    "    my_logger.info('\\n\\n')\n",
    "    my_logger.info('params = [[beta_optimized, gamma_optimized], ...] = {}'.format(params))\n",
    "    my_logger.info('\\n\\n')\n",
    "    my_logger.info('measure_result = {}'.format(measure_result))\n",
    "    my_logger.info('\\n\\n')\n",
    "    my_logger.info('consumed_iterations = {}'.format(ITR))\n",
    "    my_logger.info('\\n\\n')\n",
    "    \n",
    "    # Calculate the average expectation value\n",
    "    avg = sum(value) / len(value)\n",
    "    avg = round(avg, 5)\n",
    "    my_logger.info('avg_loss = {}'.format(avg))\n",
    "    \n",
    "    # Calculate the average number of iterations consumed\n",
    "    avg_iterations = sum(ITR) / len(ITR)\n",
    "    avg_iterations = round(avg_iterations, 5)\n",
    "    my_logger.info('Average iterations consumed = {}'.format(avg_iterations))\n",
    "    \n",
    "    # Determine the maximum expectation value and corresponding parameters\n",
    "    max_loss = max(value)\n",
    "    my_logger.info('max_loss = {}'.format(max_loss))\n",
    "    params_opt = []  # Store optimized parameters corresponding to max_loss\n",
    "    SEED_opt = []  # Store seeds corresponding to max_loss\n",
    "\n",
    "    for j in range(len(value)):\n",
    "        if value[j] == max_loss:\n",
    "            params_opt.append(params[j])\n",
    "            SEED_opt.append(SEED[j])\n",
    "    \n",
    "    my_logger.info('params_opt = {}'.format(params_opt))\n",
    "    my_logger.info('\\n')\n",
    "    my_logger.info('SEED_opt = {}'.format(SEED_opt))\n",
    "    \n",
    "    # Return the results\n",
    "    return params_opt, max_loss, avg, value, avg_iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d80e533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to construct the target Hamiltonian H_D\n",
    "# The target function is min C = -sum(x_i), where i = 0, 1, ..., N-1\n",
    "# x_i can be 0 or 1, where 1 indicates the vertex is part of the subset V'\n",
    "def build_ham(g):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        g: The graph representing the problem structure.\n",
    "    \n",
    "    Returns:\n",
    "        ham: The Hamiltonian H_D as a QubitOperator object.\n",
    "    \"\"\"\n",
    "    ham = QubitOperator()  # Initialize an empty QubitOperator for the Hamiltonian\n",
    "\n",
    "    # Iterate over all nodes in the graph\n",
    "    for i in g.nodes:\n",
    "        # Add the Z_i term with a coefficient of 0.5\n",
    "        ham += QubitOperator(f'Z{i}', 0.5)\n",
    "        \n",
    "        # Add the Z_i Z_i term with a coefficient of -0.5, which corresponds to the identity operator\n",
    "        ham += QubitOperator(f'Z{i} Z{i}', -0.5)\n",
    "\n",
    "    # Convert the QubitOperator to a Hamiltonian object\n",
    "    ham = Hamiltonian(ham)\n",
    "    return ham  # Return the constructed Hamiltonian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19c32971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient(circuit, beta, gamma, target_param_index):\n",
    "    \"\"\"\n",
    "    Calculate the gradient of the objective function with respect to a specific parameter.\n",
    "    For the added layers, this is the gradient of the mixer term \\( e^{-i \\beta H_{B}} \\), so we adjust only beta.\n",
    "\n",
    "    Args:\n",
    "        circuit: The quantum circuit.\n",
    "        beta, gamma: Current parameters of the circuit.\n",
    "        target_param_index: The index of the target parameter (corresponds to a beta or gamma parameter).\n",
    "\n",
    "    Returns:\n",
    "        grad: The gradient of the objective function with respect to the specified parameter.\n",
    "    \"\"\"\n",
    "    shift = np.pi / 2  # Parameter shift value for gradient calculation\n",
    "\n",
    "    # Create shifted parameters for the parameter shift rule\n",
    "    shifted_beta_plus = beta.copy()  # Copy beta for the positive shift\n",
    "    shifted_beta_minus = beta.copy()  # Copy beta for the negative shift\n",
    "\n",
    "    # Apply the positive and negative shifts to the target parameter\n",
    "    shifted_beta_plus[target_param_index] += shift\n",
    "    shifted_beta_minus[target_param_index] -= shift\n",
    "\n",
    "    # Calculate the expectation values for the shifted parameters\n",
    "    expectation_plus = calculate_initial_expectation_value(circuit, shifted_beta_plus, gamma)\n",
    "    expectation_minus = calculate_initial_expectation_value(circuit, shifted_beta_minus, gamma)\n",
    "\n",
    "    # Compute the gradient using the parameter shift rule\n",
    "    grad = abs((expectation_plus - expectation_minus) / (2 * np.sin(shift)))\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9f18e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select  one mixer  based on a the gradient \n",
    "def select_mixer_vertices_combined(updated_pqc, layer, updated_beta, updated_gamma, applied_nodes, num_initial_params=10):\n",
    "    \"\"\"\n",
    "    Select a vertex for applying the mixer based on the combination of the gradient.\n",
    "\n",
    "    Args:\n",
    "        updated_pqc: The current quantum circuit.\n",
    "        layer: The current layer of the circuit.\n",
    "        updated_beta, updated_gamma: Current parameters of the circuit.\n",
    "        applied_nodes: List of vertices where mixers have already been applied.\n",
    "        num_initial_params: Number of initial parameter sets to use for averaging (default: 1).\n",
    "\n",
    "    Returns:\n",
    "        selected_node: The vertex selected for applying the mixer.\n",
    "        max_score: The maximum score for the selected vertex.\n",
    "        avg_grad_allowed_node: The average gradient of the selected node.\n",
    "    \"\"\"\n",
    "    # Define the candidate vertex pool (excluding already applied nodes)\n",
    "    pool = [i for i in range(len(V))]\n",
    "    avg_gradients = []  # Store average gradients for each vertex\n",
    "\n",
    "    scores = [] # stores the evaluation function values about each mixer\n",
    "    for node in pool:\n",
    "        temp_applied_nodes = [] + [node]  # Hypothetically apply the mixer to the vertex\n",
    "        gradients = []  # Store gradients for averaging\n",
    "        \n",
    "        # Calculate average gradient and expectation value using the same initial parameters\n",
    "        for k in range(num_initial_params):\n",
    "            # Prepare the parameters for the new layer\n",
    "            initial_beta = updated_beta.copy()\n",
    "            initial_gamma = updated_gamma.copy()\n",
    "\n",
    "            minval = Tensor(0, ms.float32)\n",
    "            maxval = Tensor(np.pi, ms.float32)\n",
    "            shape = tuple([1])\n",
    "\n",
    "            # Randomly initialize the parameter for the new mixer term \\( e^{-i \\beta H_{B}} \\)\n",
    "            SEED = random.randint(1, 2500)\n",
    "            param = ops.uniform(shape, minval, maxval, seed=SEED, dtype=ms.float32)\n",
    "            initial_beta.append(param.asnumpy()[0])\n",
    "            \n",
    "            # for the new layer of the target unitary operator\n",
    "            param = ops.uniform(shape, minval, maxval, seed=SEED, dtype=ms.float32)\n",
    "            initial_gamma.append(param.asnumpy()[0])\n",
    "\n",
    "            # Create a deep copy of the current circuit\n",
    "            circ = copy.deepcopy(updated_pqc)\n",
    "            \n",
    "            # Build the updated parameterized quantum circuit\n",
    "            temp_circuit = build_latest_PQC(circ, layer, temp_applied_nodes, info)\n",
    "\n",
    "            # Compute the initial expectation value and gradient\n",
    "           \n",
    "            gradient = calculate_gradient(temp_circuit, initial_beta, initial_gamma, len(initial_beta) - 1)\n",
    "\n",
    "            gradients.append(gradient)\n",
    "\n",
    "        # Calculate the gradient \n",
    "        avg_gradient = np.mean(gradients)\n",
    "        \n",
    "        avg_gradients.append(avg_gradient)\n",
    "        print('avg_gradients = {}'.format(avg_gradients))\n",
    "\n",
    "    # Combine average gradient and initial expectation value to compute the score\n",
    "    weight = 1.0  # Adjustable weight coefficient\n",
    "    for grad in avg_gradients:\n",
    "        scores.append(grad*weight)\n",
    "    max_score = max(scores)  # Find the maximum score\n",
    "    selected_node = pool[scores.index(max_score)]  # Find the vertex corresponding to the max score\n",
    "    \n",
    "    # Retrieve the average gradient for the selected node\n",
    "    for t0 in range(len(scores)):\n",
    "        if scores[t0] == max_score:\n",
    "            avg_grad_allowed_node = avg_gradients[t0]\n",
    "    \n",
    "    return selected_node, max_score, avg_grad_allowed_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd9e8447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build an adaptive ansatz circuit\n",
    "def adaptive_ansatz(SEED):\n",
    "    \"\"\"\n",
    "    Constructs an adaptive ansatz circuit based on layer-by-layer optimization,\n",
    "    selecting mixer vertices adaptively at each layer.\n",
    "\n",
    "    Args:\n",
    "        SEED: Seed for random initialization of parameters.\n",
    "\n",
    "    Returns:\n",
    "        function_value: List of expectation function values for each optimization round.\n",
    "        mixer_nodes: List of allowed mixer vertices for each layer.\n",
    "        ITR: List of iteration counts for each optimization round.\n",
    "        circuit_depth_layer: List of circuit depths for each layer.\n",
    "    \"\"\"\n",
    "    # Initialize variables\n",
    "    shock = 0  # Tracks oscillations during optimization\n",
    "    function_value = []  # Stores expectation values at each layer\n",
    "    circuit_depth_layer = []  # Records circuit depth at each layer\n",
    "    mixer_nodes = []  # Stores mixer vertices for each layer\n",
    "    ITR = []  # Stores iteration counts for each optimization round\n",
    "    layer = 1  # Start with the first layer\n",
    "\n",
    "    # Build the initial PQC (Parameterized Quantum Circuit)\n",
    "    circ, allowed_applied_nodes = build_initial_PQC(target_graph)\n",
    "    mixer_nodes.append(allowed_applied_nodes)  # Add initial layer mixer vertices\n",
    "    temp_circuit = copy.deepcopy(circ)\n",
    "    circuit_depth_layer.append(DAGCircuit(temp_circuit).depth())  # Record initial circuit depth\n",
    "\n",
    "    # Initialize parameters for the first layer\n",
    "    initial_beta = []\n",
    "    initial_gamma = []\n",
    "\n",
    "    # Perform optimization for the first layer using multiple random initializations\n",
    "    params_opt, max_loss, avg, value, avg_iterations = search_optimized_parameters(temp_circuit, target_graph)\n",
    "\n",
    "    # Extract optimized parameters for the first layer\n",
    "    optimized_beta = [param for param in params_opt[0][0]]\n",
    "    optimized_gamma = [param for param in params_opt[0][1]]\n",
    "    function_value.append(max_loss)  # Store the expectation value\n",
    "    ITR.append(avg_iterations * counts)  # Store the iteration count\n",
    "\n",
    "    # Move to the second layer\n",
    "    layer += 1\n",
    "    if layer == 2:\n",
    "        allowed_applied_nodes0 = []  # Initialize allowed mixer vertices for this layer\n",
    "        # Reuse parameters from the previous layer\n",
    "        initial_beta = optimized_beta.copy()\n",
    "        initial_gamma = optimized_gamma.copy()\n",
    "\n",
    "        # Select the first mixer vertex for this layer\n",
    "        allowed_node, max_value, avg_grad_allowed_node = select_mixer_vertices_combined(\n",
    "            circ, layer, optimized_beta, optimized_gamma, allowed_applied_nodes0, num_initial_params=1\n",
    "        )\n",
    "        allowed_applied_nodes0.append(allowed_node)\n",
    "        circ = build_latest_PQC(circ, layer, allowed_applied_nodes0, info)\n",
    "        my_logger.info('max_evaluation_value = {}'.format(max_value))\n",
    "        my_logger.info('First allowed mixer vertex = {}'.format(allowed_node))\n",
    "\n",
    "        # execute optimization after each addition\n",
    "        temp_circuit = copy.deepcopy(circ)\n",
    "        circuit_depth_layer.append(DAGCircuit(temp_circuit).depth())  # Record circuit depth\n",
    "        my_logger.info('The vertice acted on by the mixer is: {}'.format(allowed_applied_nodes0))\n",
    "\n",
    "        # Optimize parameters for the second layer\n",
    "        result, optimized_gamma, optimized_beta, loss, loss0 = global_training(\n",
    "            ham, target_graph, temp_circuit, SEED, initial_beta, initial_gamma\n",
    "        )\n",
    "        if loss < max(function_value) - (2 * delta):\n",
    "            shock += 1  # Increment shock counter for oscillations\n",
    "        function_value.append(loss)\n",
    "        ITR.append(len(loss0))\n",
    "        mixer_nodes.append(allowed_applied_nodes0)\n",
    "\n",
    "    # Add additional layers (layer >= 3)\n",
    "    while layer>=2:\n",
    "        # Termination conditions based on oscillations, maximum layers, or small improvement\n",
    "        layer_depth = len(function_value)\n",
    "        if layer_depth>=3:\n",
    "            delta1 = abs(function_value[layer_depth - 1] - function_value[layer_depth - 2])\n",
    "            delta2 = abs(function_value[layer_depth - 2] - function_value[layer_depth - 3])\n",
    "        else:\n",
    "            delta1  = delta+1\n",
    "            delta2 = delta+1\n",
    "            \n",
    "        if shock >=3:\n",
    "            my_logger.info('Too many shocks...')\n",
    "            break\n",
    "        else:\n",
    "            if delta1 <= delta and delta2 <= delta:\n",
    "                my_logger.info('Small improvement in expectation value, terminating.')\n",
    "                break\n",
    "            else:\n",
    "                layer += 1\n",
    "                applied_nodes = []  # Reset mixer vertices for this layer\n",
    "                initial_beta = optimized_beta.copy()\n",
    "                initial_gamma = optimized_gamma.copy()\n",
    "\n",
    "                # Select mixer vertices and update the circuit\n",
    "                applied_node, max_value, avg_grad_allowed_node = select_mixer_vertices_combined(\n",
    "                    circ, layer, optimized_beta, optimized_gamma, applied_nodes, num_initial_params=10\n",
    "                )\n",
    "                my_logger.info('max_evaluation_value = {}'.format(max_value))\n",
    "                my_logger.info('The vertex acted upon by the mixer = {}'.format(allowed_node))\n",
    "\n",
    "                applied_nodes.append(applied_node)\n",
    "                circ = build_latest_PQC(circ, layer, applied_nodes, info)\n",
    "\n",
    "                temp_circuit = copy.deepcopy(circ)\n",
    "                circuit_depth_layer.append(DAGCircuit(temp_circuit).depth())  # Record circuit depth\n",
    "\n",
    "                # Optimize parameters for the current layer\n",
    "                result, optimized_gamma, optimized_beta, loss, loss0 = global_training(\n",
    "                    ham, target_graph, temp_circuit, SEED, initial_beta, initial_gamma\n",
    "                )\n",
    "\n",
    "                if loss < max(function_value) - (2 * delta):\n",
    "                    shock += 1  # Increment shock counter for oscillations\n",
    "\n",
    "                function_value.append(loss)\n",
    "                ITR.append(len(loss0))\n",
    "                mixer_nodes.append(applied_nodes)\n",
    "\n",
    "    # Log final results\n",
    "    my_logger.info('Expectation value changes: {}'.format(function_value))\n",
    "    my_logger.info('Mixer vertices for each layer: {}'.format(mixer_nodes))\n",
    "\n",
    "    return function_value, mixer_nodes, ITR, circuit_depth_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e4a0417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ER graphs with 8 vertices\n",
    "E0 = [[(0, 3), (0, 5), (1, 2), (1, 3), (1, 4), (1, 6), (2, 3), (2, 5), (2, 7), (5, 7), (6, 7)], [(0, 1), (0, 2), (0, 3), (0, 4), (0, 7), (1, 3), (1, 4), (1, 5), (1, 7), (2, 3), (2, 6), (3, 4), (3, 5), (4, 7), (5, 6), (5, 7)], [(0, 1), (0, 5), (0, 6), (0, 7), (1, 2), (1, 3), (1, 5), (2, 6), (2, 7), (3, 4), (3, 5), (4, 5), (5, 6), (6, 7)], [(0, 1), (0, 2), (0, 4), (0, 6), (0, 7), (1, 4), (1, 5), (1, 7), (2, 3), (2, 5), (2, 6), (2, 7), (3, 5), (4, 6), (5, 6), (5, 7)], [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (1, 7), (2, 4), (3, 4), (4, 5), (4, 6), (5, 6), (5, 7), (6, 7)], [(0, 1), (0, 3), (0, 4), (0, 7), (1, 2), (1, 3), (1, 4), (1, 5), (2, 4), (3, 4), (4, 5), (5, 7), (6, 7)], [(0, 1), (0, 3), (0, 6), (1, 2), (1, 4), (1, 6), (1, 7), (2, 4), (2, 6), (2, 7), (3, 5), (3, 6), (4, 7)], [(0, 1), (0, 2), (0, 6), (0, 7), (1, 6), (1, 7), (2, 4), (2, 5), (2, 7), (3, 4), (3, 5), (3, 6), (4, 6), (4, 7), (6, 7)], [(0, 2), (0, 4), (0, 7), (1, 3), (1, 5), (2, 5), (2, 6), (3, 5), (3, 6), (3, 7), (4, 5), (5, 6), (5, 7)], [(0, 1), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (1, 5), (1, 6), (2, 4), (2, 5), (3, 4), (3, 5), (3, 6), (3, 7), (4, 7), (5, 7)], [(0, 2), (0, 3), (1, 3), (1, 4), (1, 6), (2, 3), (2, 4), (2, 6), (3, 5), (3, 7), (4, 5), (4, 6), (4, 7)], [(0, 3), (0, 4), (0, 5), (0, 6), (1, 2), (1, 3), (1, 4), (2, 3), (2, 5), (2, 6), (3, 5), (3, 6), (6, 7)], [(0, 1), (0, 2), (0, 3), (0, 5), (1, 2), (1, 6), (2, 4), (2, 5), (2, 7), (3, 6), (4, 5), (4, 7), (5, 7)], [(0, 1), (0, 2), (0, 6), (1, 2), (1, 4), (2, 7), (3, 6), (4, 6), (5, 6), (5, 7)], [(0, 1), (0, 3), (0, 6), (1, 2), (1, 3), (1, 6), (1, 7), (2, 3), (2, 5), (2, 7), (4, 7), (6, 7)], [(0, 2), (0, 4), (0, 6), (1, 2), (1, 4), (1, 5), (1, 7), (2, 4), (2, 5), (2, 6), (3, 4), (4, 5), (4, 6), (4, 7), (5, 6), (6, 7)], [(0, 1), (0, 6), (1, 2), (1, 3), (2, 6), (2, 7), (3, 4), (3, 6), (4, 5), (4, 6), (4, 7), (5, 7)], [(0, 2), (0, 4), (0, 5), (0, 6), (0, 7), (1, 3), (1, 4), (2, 4), (2, 6), (3, 5), (4, 5), (5, 6)], [(0, 2), (1, 2), (1, 4), (1, 6), (2, 6), (2, 7), (3, 4), (3, 5), (3, 7), (4, 5), (4, 6), (4, 7), (5, 6), (6, 7)], [(0, 2), (0, 3), (0, 4), (0, 7), (1, 2), (1, 3), (1, 5), (2, 4), (2, 6), (3, 4), (3, 6), (3, 7), (4, 6), (4, 7), (5, 6), (5, 7)]]\n",
    "\n",
    "# 3 regular graphs with 8 vertices\n",
    "# E0 = [[(1, 2), (1, 4), (1, 6), (2, 5), (2, 0), (4, 6), (4, 3), (6, 5), (5, 7), (7, 0), (7, 3), (0, 3)], [(2, 7), (2, 3), (2, 0), (7, 4), (7, 6), (0, 1), (0, 5), (1, 4), (1, 6), (4, 3), (6, 5), (5, 3)], [(2, 7), (2, 1), (2, 4), (7, 6), (7, 3), (1, 5), (1, 6), (6, 5), (5, 0), (0, 4), (0, 3), (4, 3)], [(2, 7), (2, 6), (2, 0), (7, 4), (7, 0), (0, 1), (1, 3), (1, 4), (4, 5), (6, 5), (6, 3), (3, 5)], [(0, 1), (0, 6), (0, 3), (1, 2), (1, 3), (2, 7), (2, 4), (7, 5), (7, 3), (4, 6), (4, 5), (6, 5)], [(1, 2), (1, 3), (1, 4), (2, 6), (2, 3), (4, 7), (4, 5), (7, 6), (7, 5), (3, 0), (6, 0), (5, 0)], [(1, 2), (1, 3), (1, 4), (2, 6), (2, 4), (6, 7), (6, 0), (7, 5), (7, 3), (3, 0), (4, 5), (5, 0)], [(2, 7), (2, 5), (2, 0), (7, 4), (7, 3), (0, 1), (0, 4), (1, 3), (1, 6), (4, 6), (3, 5), (6, 5)], [(1, 2), (1, 0), (1, 7), (2, 6), (2, 0), (0, 5), (6, 7), (6, 4), (7, 3), (4, 5), (4, 3), (5, 3)], [(1, 3), (1, 5), (1, 7), (3, 2), (3, 7), (6, 7), (6, 4), (6, 5), (4, 0), (4, 2), (5, 0), (0, 2)], [(1, 2), (1, 4), (1, 6), (2, 6), (2, 5), (4, 7), (4, 3), (7, 6), (7, 0), (0, 3), (0, 5), (3, 5)], [(1, 3), (1, 6), (1, 7), (3, 2), (3, 0), (4, 6), (4, 5), (4, 2), (6, 0), (5, 7), (5, 2), (7, 0)], [(2, 7), (2, 5), (2, 4), (7, 0), (7, 3), (0, 1), (0, 6), (1, 3), (1, 5), (3, 6), (4, 6), (4, 5)], [(0, 1), (0, 2), (0, 7), (1, 6), (1, 7), (4, 7), (4, 3), (4, 2), (5, 6), (5, 2), (5, 3), (6, 3)], [(1, 2), (1, 3), (1, 4), (2, 6), (2, 4), (4, 7), (7, 6), (7, 0), (3, 0), (3, 5), (6, 5), (5, 0)], [(1, 3), (1, 4), (1, 7), (3, 2), (3, 5), (6, 7), (6, 5), (6, 0), (7, 0), (5, 2), (4, 0), (4, 2)], [(1, 2), (1, 3), (1, 5), (2, 7), (2, 6), (7, 4), (7, 0), (4, 6), (4, 0), (3, 6), (3, 5), (0, 5)], [(0, 1), (0, 7), (0, 6), (1, 5), (1, 6), (4, 7), (4, 3), (4, 2), (7, 5), (2, 6), (2, 3), (5, 3)], [(4, 7), (4, 1), (4, 0), (7, 1), (7, 3), (5, 6), (5, 0), (5, 2), (6, 1), (6, 3), (2, 3), (2, 0)], [(2, 7), (2, 1), (2, 3), (7, 0), (7, 3), (1, 5), (1, 6), (4, 6), (4, 5), (4, 0), (6, 5), (0, 3)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce7a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ER graphs with 10 vertices\n",
    "# E0 = [[(0, 2), (0, 3), (0, 5), (1, 2), (1, 5), (1, 6), (1, 7), (1, 8), (2, 3), (2, 4), (2, 5), (2, 6), (4, 5), (4, 6), (5, 6), (6, 7), (6, 9), (7, 8)], [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 7), (0, 8), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (2, 3), (2, 6), (2, 7), (2, 8), (3, 5), (4, 6), (4, 7), (4, 8), (4, 9), (5, 6), (5, 9), (6, 9), (8, 9)], [(0, 1), (0, 3), (0, 4), (0, 5), (0, 6), (1, 2), (1, 5), (1, 9), (2, 6), (3, 7), (4, 6), (4, 8), (5, 8), (5, 9), (6, 8), (7, 9), (8, 9)], [(0, 3), (0, 4), (0, 5), (0, 7), (0, 8), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (2, 6), (2, 9), (3, 4), (3, 5), (3, 6), (3, 8), (4, 8), (4, 9), (5, 7), (6, 7), (6, 9), (7, 8), (8, 9)], [(0, 2), (0, 4), (0, 5), (0, 7), (1, 7), (1, 9), (2, 4), (2, 7), (2, 8), (3, 8), (4, 8), (4, 9), (6, 8), (8, 9)], [(0, 2), (0, 4), (0, 5), (0, 6), (0, 9), (1, 3), (1, 4), (1, 6), (2, 3), (2, 4), (2, 5), (2, 7), (2, 8), (2, 9), (3, 4), (3, 5), (3, 6), (3, 9), (4, 6), (4, 7), (4, 8), (5, 6), (6, 8), (7, 8), (7, 9)], [(0, 1), (0, 4), (0, 5), (0, 8), (0, 9), (1, 5), (1, 9), (2, 7), (2, 8), (3, 5), (3, 8), (3, 9), (4, 5), (4, 6), (4, 8), (5, 7), (5, 8), (6, 7), (6, 9)], [(0, 1), (0, 3), (0, 5), (0, 9), (1, 4), (1, 7), (1, 8), (2, 3), (2, 6), (2, 7), (2, 8), (2, 9), (3, 6), (3, 7), (3, 9), (4, 5), (4, 6), (4, 7), (4, 9), (5, 7), (6, 7), (6, 8), (7, 9), (8, 9)], [(0, 1), (0, 2), (0, 3), (0, 4), (1, 3), (1, 4), (1, 5), (1, 6), (2, 4), (2, 5), (2, 9), (3, 4), (3, 8), (4, 8), (6, 7), (6, 9), (7, 8)], [(0, 1), (0, 5), (0, 6), (0, 9), (1, 2), (1, 7), (1, 8), (1, 9), (2, 4), (2, 7), (2, 8), (2, 9), (3, 4), (3, 6), (3, 8), (3, 9), (4, 5), (4, 7), (5, 9), (6, 8), (6, 9), (7, 8), (7, 9), (8, 9)], [(0, 2), (0, 5), (0, 8), (1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5), (2, 6), (2, 8), (3, 5), (3, 7), (4, 5), (4, 6), (4, 7), (5, 6), (5, 8), (5, 9), (6, 7), (6, 8)], [(0, 2), (0, 4), (0, 6), (0, 7), (0, 8), (1, 2), (1, 3), (1, 8), (1, 9), (2, 6), (2, 7), (2, 8), (3, 6), (3, 8), (4, 6), (4, 8), (4, 9), (5, 8), (5, 9), (6, 7), (6, 8), (6, 9), (7, 8), (8, 9)], [(0, 1), (0, 5), (0, 7), (1, 2), (1, 5), (1, 6), (1, 7), (1, 9), (2, 3), (2, 4), (2, 5), (2, 9), (3, 4), (3, 6), (3, 7), (3, 8), (4, 6), (4, 7), (5, 8), (5, 9), (6, 8)], [(0, 1), (0, 5), (0, 7), (1, 2), (1, 5), (1, 6), (1, 7), (1, 9), (2, 3), (2, 4), (2, 5), (2, 9), (3, 4), (3, 6), (3, 7), (3, 8), (4, 6), (4, 7), (5, 8), (5, 9), (6, 8)], [(0, 1), (0, 4), (0, 6), (1, 2), (1, 3), (1, 4), (1, 7), (1, 9), (3, 7), (4, 5), (4, 6), (4, 7), (4, 8), (4, 9), (5, 6), (6, 7), (7, 8), (7, 9), (8, 9)], [(0, 3), (0, 4), (0, 6), (1, 2), (1, 6), (1, 7), (1, 9), (2, 5), (2, 7), (2, 8), (2, 9), (3, 4), (3, 8), (4, 6), (4, 7), (4, 9), (5, 6), (5, 8), (6, 7), (6, 8), (6, 9), (8, 9)], [(0, 3), (0, 4), (0, 5), (0, 7), (0, 9), (1, 2), (1, 3), (1, 7), (1, 9), (2, 3), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (3, 4), (3, 5), (3, 7), (4, 6), (5, 7), (5, 8), (5, 9), (6, 8), (7, 8), (7, 9), (8, 9)], [(0, 1), (0, 2), (0, 5), (0, 7), (0, 8), (0, 9), (1, 2), (1, 7), (1, 8), (2, 4), (2, 5), (2, 7), (3, 5), (3, 7), (3, 8), (3, 9), (4, 6), (4, 7), (5, 6), (5, 8), (5, 9), (6, 8), (6, 9)], [(0, 5), (0, 9), (1, 5), (1, 7), (1, 9), (2, 5), (3, 5), (3, 7), (3, 8), (4, 5), (4, 6), (4, 7), (4, 8), (6, 7)], [(0, 4), (0, 5), (1, 2), (1, 4), (1, 5), (1, 6), (1, 8), (2, 4), (2, 5), (2, 7), (3, 4), (3, 5), (3, 6), (3, 9), (4, 6), (4, 7), (5, 6), (5, 7), (5, 8), (6, 8), (7, 8), (7, 9), (8, 9)]]\n",
    "\n",
    "# 3-regular graphs with 10 vertices\n",
    "# E0 = [[(1, 2), (1, 5), (1, 8), (2, 6), (2, 5), (6, 4), (6, 3), (4, 3), (4, 0), (0, 7), (0, 9), (7, 8), (7, 9), (5, 8), (3, 9)], [(2, 7), (2, 8), (2, 0), (7, 1), (7, 3), (4, 9), (4, 6), (4, 5), (9, 8), (9, 1), (6, 5), (6, 0), (5, 1), (8, 3), (0, 3)], [(6, 7), (6, 5), (6, 3), (7, 0), (7, 8), (4, 9), (4, 1), (4, 0), (9, 2), (9, 0), (2, 3), (2, 5), (5, 1), (1, 8), (3, 8)], [(2, 7), (2, 4), (2, 0), (7, 4), (7, 9), (0, 1), (0, 5), (1, 5), (1, 6), (4, 8), (8, 9), (8, 3), (5, 6), (6, 3), (9, 3)], [(1, 2), (1, 0), (1, 8), (2, 9), (2, 4), (0, 7), (0, 8), (6, 9), (6, 5), (6, 3), (9, 7), (4, 8), (4, 5), (5, 3), (7, 3)], [(0, 1), (0, 5), (0, 4), (1, 3), (1, 9), (7, 8), (7, 6), (7, 4), (8, 2), (8, 3), (6, 9), (6, 5), (9, 2), (3, 4), (2, 5)], [(5, 9), (5, 0), (5, 2), (9, 3), (9, 0), (4, 7), (4, 8), (4, 1), (7, 6), (7, 1), (2, 6), (2, 0), (6, 3), (8, 3), (8, 1)], [(0, 1), (0, 9), (0, 3), (1, 2), (1, 4), (2, 8), (2, 4), (6, 9), (6, 4), (6, 5), (9, 7), (5, 7), (5, 8), (8, 3), (7, 3)], [(2, 7), (2, 6), (2, 0), (7, 4), (7, 8), (5, 9), (5, 0), (5, 8), (9, 4), (9, 0), (4, 3), (1, 3), (1, 8), (1, 6), (3, 6)], [(1, 2), (1, 3), (1, 4), (2, 6), (2, 5), (7, 8), (7, 6), (7, 3), (8, 9), (8, 0), (6, 9), (9, 0), (3, 4), (4, 5), (5, 0)], [(0, 1), (0, 3), (0, 8), (1, 5), (1, 6), (6, 9), (6, 5), (9, 8), (9, 7), (4, 7), (4, 5), (4, 2), (7, 3), (2, 8), (2, 3)], [(2, 7), (2, 6), (2, 3), (7, 3), (7, 8), (0, 1), (0, 5), (0, 9), (1, 4), (1, 9), (6, 9), (6, 4), (4, 8), (8, 5), (5, 3)], [(5, 9), (5, 6), (5, 7), (9, 8), (9, 3), (4, 6), (4, 1), (4, 0), (6, 1), (2, 8), (2, 3), (2, 0), (8, 7), (7, 1), (3, 0)], [(2, 7), (2, 1), (2, 8), (7, 5), (7, 0), (5, 9), (5, 6), (9, 6), (9, 3), (1, 3), (1, 8), (3, 0), (6, 4), (4, 8), (4, 0)], [(6, 9), (6, 2), (6, 1), (9, 8), (9, 3), (2, 5), (2, 3), (4, 7), (4, 8), (4, 0), (7, 5), (7, 1), (8, 1), (5, 0), (0, 3)], [(1, 2), (1, 3), (1, 4), (2, 6), (2, 9), (5, 9), (5, 4), (5, 0), (9, 8), (6, 8), (6, 3), (3, 7), (8, 7), (4, 0), (0, 7)], [(1, 2), (1, 6), (1, 7), (2, 6), (2, 0), (6, 9), (9, 4), (9, 8), (4, 0), (4, 3), (5, 7), (5, 8), (5, 3), (7, 0), (3, 8)], [(5, 9), (5, 0), (5, 3), (9, 6), (9, 2), (6, 7), (6, 0), (7, 0), (7, 1), (2, 8), (2, 4), (8, 3), (8, 1), (1, 4), (4, 3)], [(4, 7), (4, 9), (4, 0), (7, 6), (7, 1), (1, 3), (1, 6), (3, 8), (3, 5), (6, 0), (9, 2), (9, 0), (2, 8), (2, 5), (8, 5)], [(1, 2), (1, 9), (1, 7), (2, 3), (2, 4), (6, 9), (6, 7), (6, 3), (9, 4), (4, 5), (7, 8), (5, 0), (5, 8), (3, 0), (0, 8)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb02b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ER graphs with 12 vertices\n",
    "# E0 = [[(0, 1), (0, 3), (0, 6), (0, 7), (0, 10), (0, 11), (1, 6), (1, 8), (1, 10), (2, 3), (2, 4), (2, 10), (2, 11), (3, 7), (3, 8), (3, 9), (4, 6), (4, 9), (4, 10), (5, 6), (5, 8), (5, 11), (6, 11), (7, 8), (7, 11), (8, 9), (8, 10), (8, 11), (9, 10), (9, 11), (10, 11)], [(0, 1), (0, 2), (0, 3), (0, 5), (0, 6), (0, 7), (0, 8), (0, 10), (0, 11), (1, 2), (1, 5), (1, 6), (1, 7), (1, 8), (2, 6), (2, 7), (2, 9), (2, 11), (3, 4), (3, 5), (3, 6), (3, 9), (3, 10), (3, 11), (4, 6), (4, 9), (5, 6), (5, 7), (5, 8), (5, 10), (5, 11), (6, 9), (7, 8), (7, 9), (7, 10), (7, 11), (8, 9), (8, 11)], [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 9), (0, 10), (0, 11), (1, 2), (1, 3), (1, 5), (1, 6), (1, 9), (1, 10), (1, 11), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (3, 5), (3, 6), (3, 11), (4, 5), (5, 6), (5, 8), (5, 9), (5, 11), (6, 7), (6, 8), (6, 10), (6, 11), (7, 10), (7, 11), (8, 10), (8, 11), (9, 10), (9, 11), (10, 11)], [(0, 5), (0, 6), (0, 7), (0, 8), (0, 10), (0, 11), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 9), (1, 11), (2, 4), (2, 5), (2, 7), (2, 9), (2, 10), (2, 11), (3, 5), (3, 8), (3, 11), (4, 6), (4, 7), (4, 8), (4, 10), (4, 11), (5, 7), (5, 8), (5, 9), (6, 8), (6, 9), (6, 10), (7, 8), (7, 9), (7, 10), (7, 11), (8, 11)], [(0, 1), (0, 2), (0, 4), (0, 7), (0, 8), (0, 11), (1, 6), (1, 7), (1, 8), (1, 9), (1, 11), (2, 5), (2, 6), (2, 7), (3, 4), (3, 8), (3, 9), (4, 5), (4, 6), (4, 7), (4, 8), (4, 9), (4, 11), (5, 7), (5, 8), (5, 10), (6, 10), (6, 11), (7, 8), (8, 9), (9, 10)], [(0, 2), (0, 3), (0, 4), (0, 6), (0, 7), (0, 8), (0, 11), (1, 4), (1, 6), (2, 7), (3, 7), (3, 8), (3, 9), (4, 5), (4, 9), (4, 11), (5, 6), (5, 10), (6, 7), (6, 9), (6, 10), (6, 11), (7, 8), (10, 11)], [(0, 1), (0, 2), (0, 3), (0, 6), (0, 11), (1, 2), (1, 5), (1, 6), (1, 8), (1, 9), (1, 10), (2, 4), (2, 6), (2, 9), (3, 5), (3, 7), (3, 8), (3, 10), (4, 5), (4, 10), (4, 11), (5, 7), (6, 7), (6, 8), (6, 9), (7, 8), (7, 10), (8, 10), (8, 11), (10, 11)], [(0, 2), (0, 7), (0, 10), (0, 11), (1, 2), (1, 5), (1, 7), (1, 10), (1, 11), (2, 5), (3, 6), (3, 9), (3, 10), (3, 11), (4, 5), (4, 7), (4, 8), (4, 9), (4, 10), (5, 8), (5, 9), (6, 11), (7, 8), (7, 10), (8, 9), (8, 10), (9, 11)], [(0, 1), (0, 2), (0, 3), (0, 5), (0, 6), (0, 7), (1, 2), (1, 4), (1, 7), (1, 8), (2, 3), (2, 8), (2, 10), (2, 11), (3, 8), (3, 11), (4, 5), (4, 7), (4, 9), (5, 7), (5, 10), (5, 11), (6, 10), (9, 11), (10, 11)], [(0, 1), (0, 3), (0, 4), (0, 5), (0, 6), (0, 9), (0, 11), (1, 5), (1, 6), (1, 8), (1, 9), (1, 10), (1, 11), (2, 5), (2, 7), (2, 10), (3, 4), (3, 5), (3, 6), (3, 7), (3, 10), (4, 8), (4, 9), (4, 10), (4, 11), (5, 6), (6, 7), (6, 8), (6, 9), (6, 11), (7, 8), (7, 9), (7, 10), (7, 11), (8, 10), (9, 10)], [(0, 1), (0, 3), (0, 5), (0, 6), (0, 7), (0, 9), (0, 11), (1, 7), (1, 9), (1, 11), (2, 5), (2, 7), (2, 8), (2, 9), (2, 10), (3, 10), (3, 11), (4, 6), (4, 7), (4, 8), (4, 11), (5, 6), (5, 10), (7, 9), (9, 10), (10, 11)], [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 9), (0, 10), (0, 11), (1, 4), (1, 7), (1, 9), (1, 11), (2, 6), (2, 7), (2, 9), (2, 11), (4, 5), (4, 7), (4, 8), (4, 11), (5, 7), (5, 10), (5, 11), (6, 11), (7, 9), (7, 10), (7, 11), (8, 11), (9, 10), (9, 11)], [(0, 1), (0, 2), (0, 6), (0, 8), (0, 9), (0, 10), (0, 11), (1, 2), (1, 3), (1, 4), (1, 6), (1, 8), (1, 9), (1, 10), (1, 11), (2, 4), (2, 10), (2, 11), (3, 5), (3, 6), (3, 7), (3, 9), (3, 10), (3, 11), (4, 5), (5, 9), (5, 11), (6, 10), (7, 9), (7, 10), (9, 10), (9, 11), (10, 11)], [(0, 1), (0, 2), (0, 3), (0, 4), (0, 6), (0, 10), (0, 11), (1, 5), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (2, 4), (2, 8), (2, 11), (3, 4), (3, 10), (3, 11), (4, 5), (4, 6), (4, 9), (4, 10), (4, 11), (5, 7), (5, 9), (5, 11), (6, 7), (6, 9), (6, 10), (6, 11), (7, 10), (8, 10), (9, 10), (9, 11), (10, 11)], [(0, 3), (0, 6), (0, 8), (0, 10), (0, 11), (1, 4), (1, 5), (1, 6), (1, 9), (1, 11), (2, 6), (2, 7), (2, 9), (2, 11), (3, 5), (3, 6), (3, 7), (3, 8), (3, 11), (4, 6), (4, 7), (4, 8), (4, 11), (5, 6), (5, 7), (5, 10), (6, 8), (6, 10), (7, 9), (8, 9), (8, 10), (8, 11), (9, 11)], [(0, 1), (0, 2), (0, 5), (0, 8), (0, 9), (0, 10), (0, 11), (1, 3), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (2, 3), (2, 9), (2, 10), (3, 5), (3, 7), (3, 9), (3, 10), (5, 7), (5, 10), (5, 11), (6, 7), (6, 10), (7, 10), (8, 11), (9, 10), (9, 11)], [(0, 1), (0, 3), (0, 4), (0, 5), (0, 7), (0, 8), (0, 9), (1, 3), (1, 4), (1, 7), (1, 8), (1, 9), (1, 10), (2, 4), (2, 5), (2, 6), (2, 9), (2, 10), (3, 8), (3, 9), (3, 10), (3, 11), (4, 5), (4, 7), (4, 9), (4, 10), (5, 9), (5, 11), (7, 9), (7, 10), (7, 11), (10, 11)], [(0, 1), (0, 4), (0, 6), (0, 7), (0, 8), (0, 10), (0, 11), (1, 2), (1, 3), (1, 4), (1, 8), (1, 9), (2, 4), (2, 5), (2, 7), (2, 11), (3, 7), (3, 8), (3, 9), (3, 10), (4, 6), (4, 7), (4, 8), (4, 9), (4, 10), (5, 6), (5, 8), (5, 10), (6, 7), (6, 8), (6, 10), (6, 11), (7, 8), (7, 9), (7, 10), (8, 10), (9, 11)], [(0, 1), (0, 3), (0, 4), (0, 5), (0, 8), (0, 9), (0, 11), (1, 3), (1, 8), (2, 3), (2, 4), (2, 6), (2, 9), (2, 10), (2, 11), (3, 8), (3, 11), (4, 6), (4, 10), (4, 11), (5, 7), (5, 8), (5, 9), (5, 10), (5, 11), (6, 8), (6, 11), (7, 8), (7, 9), (9, 10), (10, 11)], [(0, 1), (0, 2), (0, 3), (0, 9), (1, 5), (1, 6), (1, 7), (1, 8), (1, 10), (1, 11), (2, 3), (2, 4), (2, 5), (2, 7), (2, 8), (2, 9), (2, 10), (3, 4), (3, 6), (3, 9), (3, 10), (4, 5), (4, 8), (4, 9), (4, 10), (5, 7), (5, 10), (5, 11), (6, 7), (6, 9), (6, 11), (7, 10), (8, 9), (8, 10), (8, 11)]]\n",
    "\n",
    "# ER graphs with 12 vertices\n",
    "# E0 = [[(0, 1), (0, 11), (0, 9), (1, 3), (1, 9), (5, 9), (5, 10), (5, 2), (4, 7), (4, 8), (4, 3), (7, 10), (7, 11), (2, 6), (2, 10), (6, 8), (6, 11), (3, 8)], [(2, 7), (2, 9), (2, 11), (7, 10), (7, 8), (4, 10), (4, 5), (4, 1), (10, 5), (6, 9), (6, 5), (6, 0), (9, 0), (11, 3), (11, 1), (3, 8), (3, 0), (1, 8)], [(0, 1), (0, 10), (0, 3), (1, 4), (1, 5), (2, 6), (2, 9), (2, 3), (6, 7), (6, 5), (7, 10), (7, 8), (4, 9), (4, 11), (9, 10), (5, 8), (8, 11), (11, 3)], [(0, 1), (0, 10), (0, 8), (1, 4), (1, 5), (6, 9), (6, 2), (6, 7), (9, 10), (9, 3), (2, 8), (2, 10), (7, 3), (7, 11), (5, 11), (5, 3), (11, 4), (4, 8)], [(1, 2), (1, 5), (1, 11), (2, 10), (2, 3), (5, 9), (5, 7), (9, 8), (9, 3), (4, 6), (4, 3), (4, 11), (6, 11), (6, 0), (7, 10), (7, 8), (10, 0), (8, 0)], [(4, 10), (4, 5), (4, 1), (10, 11), (10, 7), (5, 9), (5, 1), (9, 2), (9, 3), (6, 7), (6, 11), (6, 0), (7, 3), (11, 2), (2, 8), (8, 1), (8, 0), (0, 3)], [(1, 2), (1, 3), (1, 9), (2, 9), (2, 3), (4, 10), (4, 5), (4, 0), (10, 11), (10, 0), (3, 8), (11, 9), (11, 7), (6, 7), (6, 8), (6, 0), (7, 5), (8, 5)], [(0, 1), (0, 5), (0, 2), (1, 5), (1, 10), (4, 7), (4, 6), (4, 8), (7, 8), (7, 9), (6, 5), (6, 11), (8, 11), (11, 9), (3, 10), (3, 2), (3, 9), (10, 2)], [(1, 2), (1, 8), (1, 7), (2, 9), (2, 4), (5, 9), (5, 7), (5, 3), (9, 11), (10, 11), (10, 8), (10, 0), (11, 6), (6, 0), (6, 3), (7, 8), (0, 4), (4, 3)], [(0, 1), (0, 10), (0, 3), (1, 4), (1, 6), (5, 9), (5, 4), (5, 7), (9, 3), (9, 7), (4, 10), (10, 11), (6, 7), (6, 8), (11, 8), (11, 2), (8, 2), (2, 3)], [(2, 7), (2, 6), (2, 0), (7, 0), (7, 10), (4, 10), (4, 1), (4, 3), (10, 1), (6, 8), (6, 5), (8, 3), (8, 5), (5, 11), (11, 0), (11, 9), (1, 9), (3, 9)], [(1, 2), (1, 0), (1, 9), (2, 11), (2, 3), (4, 10), (4, 8), (4, 0), (10, 5), (10, 9), (0, 8), (5, 7), (5, 3), (6, 7), (6, 8), (6, 3), (7, 11), (11, 9)], [(5, 9), (5, 8), (5, 3), (9, 4), (9, 7), (2, 6), (2, 10), (2, 4), (6, 8), (6, 10), (4, 1), (10, 11), (11, 3), (11, 0), (8, 1), (7, 0), (7, 1), (3, 0)], [(4, 10), (4, 9), (4, 5), (10, 5), (10, 8), (5, 0), (6, 7), (6, 3), (6, 1), (7, 1), (7, 11), (9, 2), (9, 1), (2, 11), (2, 0), (8, 11), (8, 3), (3, 0)], [(1, 2), (1, 3), (1, 8), (2, 8), (2, 10), (5, 9), (5, 7), (5, 3), (9, 10), (9, 3), (4, 7), (4, 6), (4, 11), (7, 6), (6, 0), (8, 11), (11, 0), (10, 0)], [(2, 7), (2, 6), (2, 9), (7, 4), (7, 0), (4, 8), (4, 11), (6, 5), (6, 10), (1, 3), (1, 10), (1, 9), (3, 10), (3, 8), (9, 0), (8, 11), (5, 11), (5, 0)], [(2, 7), (2, 6), (2, 0), (7, 10), (7, 9), (3, 5), (3, 11), (3, 9), (5, 4), (5, 1), (6, 10), (6, 0), (4, 8), (4, 1), (8, 11), (8, 9), (11, 1), (10, 0)], [(4, 10), (4, 6), (4, 1), (10, 5), (10, 3), (1, 3), (1, 9), (3, 8), (5, 0), (5, 2), (6, 8), (6, 11), (8, 7), (11, 2), (11, 9), (2, 0), (0, 7), (7, 9)], [(2, 7), (2, 6), (2, 3), (7, 6), (7, 9), (3, 5), (3, 8), (5, 10), (5, 11), (6, 0), (10, 11), (10, 1), (11, 0), (4, 8), (4, 9), (4, 1), (8, 1), (9, 0)], [(4, 10), (4, 1), (4, 3), (10, 8), (10, 2), (5, 9), (5, 6), (5, 7), (9, 0), (9, 3), (1, 3), (1, 11), (2, 6), (2, 0), (6, 7), (7, 11), (0, 8), (8, 11)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53641f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "V = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "k = 3\n",
    "n = len(V)\n",
    "V.sort()\n",
    "print(V)\n",
    "\n",
    "E = E0[17]\n",
    "\n",
    "target_graph = nx.Graph()\n",
    "target_graph.add_nodes_from(V)\n",
    "target_graph.add_edges_from(E)\n",
    "\n",
    "target_graph = nx.Graph()\n",
    "target_graph.add_nodes_from(V)\n",
    "target_graph.add_edges_from(E)\n",
    "\n",
    "# print the graph\n",
    "pos = nx.circular_layout(target_graph)\n",
    "options = {\n",
    "    \"with_labels\": True,\n",
    "    \"font_size\": 16,\n",
    "    \"font_weight\": \"bold\",\n",
    "    \"font_color\": \"white\",\n",
    "    \"node_size\": 1000,\n",
    "    \"width\": 2\n",
    "}\n",
    "nx.draw_networkx(target_graph, pos, **options)\n",
    "ax = plt.gca()\n",
    "ax.margins(0.20)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "info = get_info_neighbors(target_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bce4a62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated random seeds: total_SEED = [4298, 23462, 8116, 10457, 15714]\n",
      "Vertices selected for mixer application in the first layer: [7, 2, 3, 5, 0]\n",
      "\n",
      "\n",
      "\n",
      "The 1-th global random initialization\n",
      "SEED = 1705, initial_beta = [0.37379628], initial_gamma = [0.94739044]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [0.94739044, 0.37379628]\n",
      "weight = [0.94739044 0.37379628]\n",
      "lr = 0.05, ITR = 600\n",
      "train_step = 50, loss = -2.917609930038452\n",
      "Convergence reached after 68 iterations. Expectation value evolution: loss0 = [-0.16802262, -0.2136727, -0.2639711, -0.31863174, -0.37735957, -0.43984872, -0.5057832, -0.57483816, -0.6466805, -0.7209717, -0.7973702, -0.875533, -0.95511866, -1.0357893, -1.1172118, -1.1990606, -1.2810171, -1.3627727, -1.444028, -1.5244955, -1.6038994, -1.6819776, -1.7584838, -1.833189, -1.905883, -1.9763774, -2.044507, -2.1101313, -2.173136, -2.2334325, -2.2909596, -2.34568, -2.397582, -2.4466746, -2.4929864, -2.5365636, -2.5774658, -2.6157637, -2.6515372, -2.6848729, -2.715861, -2.7445962, -2.7711732, -2.795689, -2.8182397, -2.8389213, -2.85783, -2.8750598, -2.8907046, -2.9048572, -2.9176087, -2.9290493, -2.9392672, -2.9483492, -2.9563801, -2.9634428, -2.9696171, -2.9749804, -2.9796069, -2.9835675, -2.9869301, -2.9897587, -2.992113, -2.9940495, -2.9956203, -2.9968734, -2.9978533, -2.9986005]\n",
      "Number of iterations consumed: 68\n",
      "Optimized circuit parameters: params = [0.94739044, 3.1003895]\n",
      "\n",
      "\n",
      "\n",
      "Global random initialization complete. Logging results...\n",
      "value = [2.9986]\n",
      "\n",
      "\n",
      "\n",
      "params = [[beta_optimized, gamma_optimized], ...] = [[[3.1003895], [0.94739044]]]\n",
      "\n",
      "\n",
      "\n",
      "measure_result = [{'10001100': 1000}]\n",
      "\n",
      "\n",
      "\n",
      "consumed_iterations = [68]\n",
      "\n",
      "\n",
      "\n",
      "avg_loss = 2.9986\n",
      "Average iterations consumed = 68.0\n",
      "max_loss = 2.9986000061035156\n",
      "params_opt = [[[3.1003895], [0.94739044]]]\n",
      "\n",
      "\n",
      "SEED_opt = [1705]\n",
      "avg_gradients = [0.02898127831515407]\n",
      "avg_gradients = [0.02898127831515407, 0.42791488133019323]\n",
      "avg_gradients = [0.02898127831515407, 0.42791488133019323, 0.42748132376782877]\n",
      "avg_gradients = [0.02898127831515407, 0.42791488133019323, 0.42748132376782877, 0.032389565165100165]\n",
      "avg_gradients = [0.02898127831515407, 0.42791488133019323, 0.42748132376782877, 0.032389565165100165, 0.00034344063055580243]\n",
      "avg_gradients = [0.02898127831515407, 0.42791488133019323, 0.42748132376782877, 0.032389565165100165, 0.00034344063055580243, 0.14037413113518404]\n",
      "avg_gradients = [0.02898127831515407, 0.42791488133019323, 0.42748132376782877, 0.032389565165100165, 0.00034344063055580243, 0.14037413113518404, 3.0926839889922064e-05]\n",
      "avg_gradients = [0.02898127831515407, 0.42791488133019323, 0.42748132376782877, 0.032389565165100165, 0.00034344063055580243, 0.14037413113518404, 3.0926839889922064e-05, 0.47466929028268723]\n",
      "max_evaluation_value = 0.47466929028268723\n",
      "First allowed mixer vertex = 7\n",
      "The vertice acted on by the mixer is: [7]\n",
      "SEED = 4298, initial_beta = [3.1003895, 1.7902505], initial_gamma = [0.94739044, 1.4601787]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [0.94739044, 1.4601787, 3.1003895, 1.7902505]\n",
      "weight = [0.94739044 1.4601787  3.1003895  1.7902505 ]\n",
      "lr = 0.05, ITR = 600\n",
      "train_step = 50, loss = -2.6557300090789795\n",
      "Convergence reached after 84 iterations. Expectation value evolution: loss0 = [-1.2559918, -1.3057319, -1.3548905, -1.4033005, -1.4507877, -1.497167, -1.5422446, -1.5858214, -1.6276977, -1.6676781, -1.7055779, -1.7412292, -1.7744875, -1.8052381, -1.8334012, -1.8589376, -1.881852, -1.9021962, -1.9200691, -1.9356163, -1.9490279, -1.9605348, -1.9704047, -1.9789392, -1.9864706, -1.9933609, -2.0000002, -2.0068026, -2.0141964, -2.0226102, -2.0324488, -2.044072, -2.057776, -2.073785, -2.0922492, -2.1132507, -2.136813, -2.1629076, -2.191465, -2.222377, -2.2555058, -2.2906826, -2.3277109, -2.366365, -2.4063861, -2.4474792, -2.4893079, -2.531492, -2.5736063, -2.6151845, -2.6557298, -2.6947298, -2.7316792, -2.7661068, -2.7976055, -2.8258598, -2.8506718, -2.8719761, -2.8898463, -2.9044876, -2.9162185, -2.9254425, -2.9326134, -2.9382, -2.9426513, -2.9463692, -2.9496894, -2.9528692, -2.9560862, -2.9594417, -2.9629703, -2.9666526, -2.9704301, -2.9742184, -2.9779215, -2.9814436, -2.984699, -2.9876187, -2.990155, -2.9922845, -2.9940066, -2.995342, -2.9963286, -2.9970167]\n",
      "Number of iterations consumed: 84\n",
      "Optimized circuit parameters: params = [0.94739044, 3.06654, -0.14920324, 0.14027345]\n",
      "\n",
      "\n",
      "\n",
      "avg_gradients = [0.1093267094022979]\n",
      "avg_gradients = [0.1093267094022979, 0.1952566473517498]\n",
      "avg_gradients = [0.1093267094022979, 0.1952566473517498, 0.2573508166501889]\n",
      "avg_gradients = [0.1093267094022979, 0.1952566473517498, 0.2573508166501889, 0.28661453402394443]\n",
      "avg_gradients = [0.1093267094022979, 0.1952566473517498, 0.2573508166501889, 0.28661453402394443, 0.10345825792057906]\n",
      "avg_gradients = [0.1093267094022979, 0.1952566473517498, 0.2573508166501889, 0.28661453402394443, 0.10345825792057906, 0.1409414645018942]\n",
      "avg_gradients = [0.1093267094022979, 0.1952566473517498, 0.2573508166501889, 0.28661453402394443, 0.10345825792057906, 0.1409414645018942, 0.06955237252298409]\n",
      "avg_gradients = [0.1093267094022979, 0.1952566473517498, 0.2573508166501889, 0.28661453402394443, 0.10345825792057906, 0.1409414645018942, 0.06955237252298409, 0.3277329839557054]\n",
      "max_evaluation_value = 0.3277329839557054\n",
      "The vertex acted upon by the mixer = 7\n",
      "SEED = 4298, initial_beta = [3.06654, -0.14920324, 0.14027345, 2.3597114], initial_gamma = [0.94739044, 2.6519406]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [0.94739044, 2.6519406, 3.06654, -0.14920324, 0.14027345, 2.3597114]\n",
      "weight = [ 0.94739044  2.6519406   3.06654    -0.14920324  0.14027345  2.3597114 ]\n",
      "lr = 0.05, ITR = 600\n",
      "Convergence reached after 41 iterations. Expectation value evolution: loss0 = [-1.9942044, -2.04292, -2.0998576, -2.1637602, -2.2329407, -2.3054016, -2.3795793, -2.4548736, -2.5300517, -2.6033597, -2.6729949, -2.7373283, -2.7950346, -2.8451087, -2.886802, -2.9196007, -2.9433098, -2.958183, -2.9650123, -2.9651315, -2.9603195, -2.9526181, -2.9440792, -2.9364874, -2.9311402, -2.9287527, -2.929494, -2.9331071, -2.939051, -2.9466293, -2.955101, -2.9637632, -2.9720135, -2.9793897, -2.985589, -2.9904647, -2.9940102, -2.9963293, -2.9976027, -2.9980545, -2.9979222]\n",
      "Number of iterations consumed: 41\n",
      "Optimized circuit parameters: params = [0.94739044, 3.1759675, 4.0244417, -1.1951721, -0.032941483, 1.3123833]\n",
      "\n",
      "\n",
      "\n",
      "Small improvement in expectation value, terminating.\n",
      "Expectation value changes: [2.9986, 2.99702, 2.99792]\n",
      "Mixer vertices for each layer: [[7, 2, 3, 5, 0], [7], [7]]\n",
      "Execution 1 completed.\n",
      "Expectation values: [2.9986, 2.99702, 2.99792]\n",
      "Mixer vertices per layer: [[7, 2, 3, 5, 0], [7], [7]]\n",
      "Iteration counts: [68.0, 84, 41]\n",
      "Circuit depth per layer: [16, 20, 24]\n",
      "Runtime: 55.28s\n",
      "Vertices selected for mixer application in the first layer: [3, 7, 4, 5, 1]\n",
      "\n",
      "\n",
      "\n",
      "The 1-th global random initialization\n",
      "SEED = 704, initial_beta = [3.0493703], initial_gamma = [1.4737408]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [1.4737408, 3.0493703]\n",
      "weight = [1.4737408 3.0493703]\n",
      "lr = 0.05, ITR = 600\n",
      "Convergence reached after 7 iterations. Expectation value evolution: loss0 = [-2.9936347, -2.9986637, -2.9999895, -2.9989126, -2.9978023, -2.997809, -2.998592]\n",
      "Number of iterations consumed: 7\n",
      "Optimized circuit parameters: params = [1.4737408, 3.168137]\n",
      "\n",
      "\n",
      "\n",
      "Global random initialization complete. Logging results...\n",
      "value = [2.99859]\n",
      "\n",
      "\n",
      "\n",
      "params = [[beta_optimized, gamma_optimized], ...] = [[[3.168137], [1.4737408]]]\n",
      "\n",
      "\n",
      "\n",
      "measure_result = [{'10010000': 2, '10011000': 998}]\n",
      "\n",
      "\n",
      "\n",
      "consumed_iterations = [7]\n",
      "\n",
      "\n",
      "\n",
      "avg_loss = 2.99859\n",
      "Average iterations consumed = 7.0\n",
      "max_loss = 2.9985899925231934\n",
      "params_opt = [[[3.168137], [1.4737408]]]\n",
      "\n",
      "\n",
      "SEED_opt = [704]\n",
      "avg_gradients = [0.10645540740483961]\n",
      "avg_gradients = [0.10645540740483961, 8.829069813476309e-06]\n",
      "avg_gradients = [0.10645540740483961, 8.829069813476309e-06, 0.15268676812920934]\n",
      "avg_gradients = [0.10645540740483961, 8.829069813476309e-06, 0.15268676812920934, 0.07822144143071796]\n",
      "avg_gradients = [0.10645540740483961, 8.829069813476309e-06, 0.15268676812920934, 0.07822144143071796, 0.3314295180113517]\n",
      "avg_gradients = [0.10645540740483961, 8.829069813476309e-06, 0.15268676812920934, 0.07822144143071796, 0.3314295180113517, 3.165032381979849e-05]\n",
      "avg_gradients = [0.10645540740483961, 8.829069813476309e-06, 0.15268676812920934, 0.07822144143071796, 0.3314295180113517, 3.165032381979849e-05, 0.34834524280268947]\n",
      "avg_gradients = [0.10645540740483961, 8.829069813476309e-06, 0.15268676812920934, 0.07822144143071796, 0.3314295180113517, 3.165032381979849e-05, 0.34834524280268947, 0.23768398939153157]\n",
      "max_evaluation_value = 0.34834524280268947\n",
      "First allowed mixer vertex = 6\n",
      "The vertice acted on by the mixer is: [6]\n",
      "SEED = 23462, initial_beta = [3.168137, 1.7179396], initial_gamma = [1.4737408, 1.0752627]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [1.4737408, 1.0752627, 3.168137, 1.7179396]\n",
      "weight = [1.4737408 1.0752627 3.168137  1.7179396]\n",
      "lr = 0.05, ITR = 600\n",
      "Convergence reached after 51 iterations. Expectation value evolution: loss0 = [-1.5636953, -1.6557361, -1.747508, -1.8388463, -1.9296057, -2.019656, -2.1088803, -2.1971726, -2.2844343, -2.370571, -2.4554908, -2.5391011, -2.6213071, -2.7020097, -2.7811046, -2.8584828, -2.9340286, -3.0076225, -3.0791402, -3.1484554, -3.215442, -3.2799754, -3.341935, -3.4012072, -3.4576874, -3.5112824, -3.561913, -3.6095164, -3.654046, -3.6954749, -3.733796, -3.7690227, -3.80119, -3.8303535, -3.8565905, -3.8799975, -3.9006903, -3.9188025, -3.9344833, -3.9478943, -3.9592087, -3.9686067, -3.9762738, -3.9823964, -3.9871595, -3.9907439, -3.993323, -3.995061, -3.9961102, -3.996611, -3.9966898]\n",
      "Number of iterations consumed: 51\n",
      "Optimized circuit parameters: params = [1.4737408, 3.1730354, 3.168137, 3.2474883]\n",
      "\n",
      "\n",
      "\n",
      "avg_gradients = [1.0387530612077089e-05]\n",
      "avg_gradients = [1.0387530612077089e-05, 0.06934071212866044]\n",
      "avg_gradients = [1.0387530612077089e-05, 0.06934071212866044, 0.020291201506468383]\n",
      "avg_gradients = [1.0387530612077089e-05, 0.06934071212866044, 0.020291201506468383, 0.26433617290278366]\n",
      "avg_gradients = [1.0387530612077089e-05, 0.06934071212866044, 0.020291201506468383, 0.26433617290278366, 0.27238817275357197]\n",
      "avg_gradients = [1.0387530612077089e-05, 0.06934071212866044, 0.020291201506468383, 0.26433617290278366, 0.27238817275357197, 0.0190480666943711]\n",
      "avg_gradients = [1.0387530612077089e-05, 0.06934071212866044, 0.020291201506468383, 0.26433617290278366, 0.27238817275357197, 0.0190480666943711, 0.3320939031493356]\n",
      "avg_gradients = [1.0387530612077089e-05, 0.06934071212866044, 0.020291201506468383, 0.26433617290278366, 0.27238817275357197, 0.0190480666943711, 0.3320939031493356, 0.2751412316327314]\n",
      "max_evaluation_value = 0.3320939031493356\n",
      "The vertex acted upon by the mixer = 6\n",
      "SEED = 23462, initial_beta = [3.1730354, 3.168137, 3.2474883, 1.6035519], initial_gamma = [1.4737408, 2.7102692]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [1.4737408, 2.7102692, 3.1730354, 3.168137, 3.2474883, 1.6035519]\n",
      "weight = [1.4737408 2.7102692 3.1730354 3.168137  3.2474883 1.6035519]\n",
      "lr = 0.05, ITR = 600\n",
      "Convergence reached after 20 iterations. Expectation value evolution: loss0 = [-3.362448, -3.4408324, -3.515615, -3.5859122, -3.6512127, -3.7109601, -3.7645879, -3.811767, -3.8524816, -3.886789, -3.914889, -3.937244, -3.95451, -3.9673316, -3.9763439, -3.9822237, -3.9856327, -3.98712, -3.9871614, -3.9862182]\n",
      "Number of iterations consumed: 20\n",
      "Optimized circuit parameters: params = [1.4737408, 3.2529373, 3.1730354, 4.034317, 3.1312923, 0.7376616]\n",
      "\n",
      "\n",
      "\n",
      "avg_gradients = [0.12966905395729636]\n",
      "avg_gradients = [0.12966905395729636, 0.10988300803976774]\n",
      "avg_gradients = [0.12966905395729636, 0.10988300803976774, 0.10582032039215787]\n",
      "avg_gradients = [0.12966905395729636, 0.10988300803976774, 0.10582032039215787, 0.17144309912502845]\n",
      "avg_gradients = [0.12966905395729636, 0.10988300803976774, 0.10582032039215787, 0.17144309912502845, 0.2514209096663088]\n",
      "avg_gradients = [0.12966905395729636, 0.10988300803976774, 0.10582032039215787, 0.17144309912502845, 0.2514209096663088, 0.06597923086697718]\n",
      "avg_gradients = [0.12966905395729636, 0.10988300803976774, 0.10582032039215787, 0.17144309912502845, 0.2514209096663088, 0.06597923086697718, 0.31894421682893137]\n",
      "avg_gradients = [0.12966905395729636, 0.10988300803976774, 0.10582032039215787, 0.17144309912502845, 0.2514209096663088, 0.06597923086697718, 0.31894421682893137, 0.21131178948147541]\n",
      "max_evaluation_value = 0.31894421682893137\n",
      "The vertex acted upon by the mixer = 6\n",
      "SEED = 23462, initial_beta = [3.2529373, 3.1730354, 4.034317, 3.1312923, 0.7376616, 1.4698997], initial_gamma = [1.4737408, 1.2316467]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [1.4737408, 1.2316467, 3.2529373, 3.1730354, 4.034317, 3.1312923, 0.7376616, 1.4698997]\n",
      "weight = [1.4737408 1.2316467 3.2529373 3.1730354 4.034317  3.1312923 0.7376616\n",
      " 1.4698997]\n",
      "lr = 0.05, ITR = 600\n",
      "Convergence reached after 47 iterations. Expectation value evolution: loss0 = [-1.6639344, -1.7917312, -1.919652, -2.0472476, -2.1733975, -2.2967713, -2.4159248, -2.5293665, -2.635657, -2.7335489, -2.8221617, -2.9011748, -2.970987, -3.0327709, -3.0883458, -3.1398697, -3.189444, -3.2387795, -3.289008, -3.340644, -3.3936515, -3.447563, -3.5016098, -3.5548544, -3.606308, -3.6550384, -3.700264, -3.741424, -3.7782242, -3.8106446, -3.8389108, -3.8634307, -3.8847115, -3.903276, -3.919596, -3.9340498, -3.9469054, -3.9583209, -3.9683638, -3.9770358, -3.9843066, -3.9901454, -3.994551, -3.9975727, -3.999323, -3.999974, -3.9997468]\n",
      "Number of iterations consumed: 47\n",
      "Optimized circuit parameters: params = [1.4737408, 3.1706505, 3.2529373, 2.556007, 3.7180295, 3.6979616, 0.3337005, 2.0944312]\n",
      "\n",
      "\n",
      "\n",
      "Small improvement in expectation value, terminating.\n",
      "Expectation value changes: [2.99859, 3.99669, 3.98622, 3.99975]\n",
      "Mixer vertices for each layer: [[3, 7, 4, 5, 1], [6], [6], [6]]\n",
      "Execution 2 completed.\n",
      "Expectation values: [2.99859, 3.99669, 3.98622, 3.99975]\n",
      "Mixer vertices per layer: [[3, 7, 4, 5, 1], [6], [6], [6]]\n",
      "Iteration counts: [7.0, 51, 20, 47]\n",
      "Circuit depth per layer: [16, 20, 24, 28]\n",
      "Runtime: 77.15s\n",
      "Vertices selected for mixer application in the first layer: [5, 4, 2, 1, 6]\n",
      "\n",
      "\n",
      "\n",
      "The 1-th global random initialization\n",
      "SEED = 1342, initial_beta = [2.4567802], initial_gamma = [1.2135738]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [1.2135738, 2.4567802]\n",
      "weight = [1.2135738 2.4567802]\n",
      "lr = 0.05, ITR = 600\n",
      "Convergence reached after 26 iterations. Expectation value evolution: loss0 = [-2.6743534, -2.7171729, -2.7575102, -2.7951443, -2.8298683, -2.8614976, -2.8898787, -2.9148986, -2.9364934, -2.9546576, -2.969451, -2.9810052, -2.9895248, -2.9952857, -2.9986272, -2.9999392, -2.9996445, -2.9981773, -2.9959598, -2.9933808, -2.9907768, -2.9884195, -2.9865086, -2.9851713, -2.9844663, -2.9843931]\n",
      "Number of iterations consumed: 26\n",
      "Optimized circuit parameters: params = [1.2135738, 3.2837114]\n",
      "\n",
      "\n",
      "\n",
      "Global random initialization complete. Logging results...\n",
      "value = [2.98439]\n",
      "\n",
      "\n",
      "\n",
      "params = [[beta_optimized, gamma_optimized], ...] = [[[3.2837114], [1.2135738]]]\n",
      "\n",
      "\n",
      "\n",
      "measure_result = [{'00100010': 7, '00100100': 6, '00100110': 980, '01010000': 7}]\n",
      "\n",
      "\n",
      "\n",
      "consumed_iterations = [26]\n",
      "\n",
      "\n",
      "\n",
      "avg_loss = 2.98439\n",
      "Average iterations consumed = 26.0\n",
      "max_loss = 2.9843900203704834\n",
      "params_opt = [[[3.2837114], [1.2135738]]]\n",
      "\n",
      "\n",
      "SEED_opt = [1342]\n",
      "avg_gradients = [3.034560696280053e-06]\n",
      "avg_gradients = [3.034560696280053e-06, 0.36626842636467755]\n",
      "avg_gradients = [3.034560696280053e-06, 0.36626842636467755, 0.22741140174219887]\n",
      "avg_gradients = [3.034560696280053e-06, 0.36626842636467755, 0.22741140174219887, 0.28694751054221695]\n",
      "avg_gradients = [3.034560696280053e-06, 0.36626842636467755, 0.22741140174219887, 0.28694751054221695, 0.013668291107519437]\n",
      "avg_gradients = [3.034560696280053e-06, 0.36626842636467755, 0.22741140174219887, 0.28694751054221695, 0.013668291107519437, 0.14547182747071907]\n",
      "avg_gradients = [3.034560696280053e-06, 0.36626842636467755, 0.22741140174219887, 0.28694751054221695, 0.013668291107519437, 0.14547182747071907, 0.006886357615700778]\n",
      "avg_gradients = [3.034560696280053e-06, 0.36626842636467755, 0.22741140174219887, 0.28694751054221695, 0.013668291107519437, 0.14547182747071907, 0.006886357615700778, 0.48655056330905505]\n",
      "max_evaluation_value = 0.48655056330905505\n",
      "First allowed mixer vertex = 7\n",
      "The vertice acted on by the mixer is: [7]\n",
      "SEED = 8116, initial_beta = [3.2837114, 0.27536613], initial_gamma = [1.2135738, 0.0990969]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [1.2135738, 0.0990969, 3.2837114, 0.27536613]\n",
      "weight = [1.2135738  0.0990969  3.2837114  0.27536613]\n",
      "lr = 0.05, ITR = 600\n",
      "train_step = 50, loss = -3.83558988571167\n",
      "Convergence reached after 65 iterations. Expectation value evolution: loss0 = [-0.031072319, -0.053815827, -0.08350965, -0.11997064, -0.16305059, -0.21259342, -0.26841304, -0.33028123, -0.39792094, -0.47100437, -0.5491546, -0.6319491, -0.7189268, -0.8095967, -0.9034484, -0.9999638, -1.0986288, -1.1989452, -1.3004416, -1.4026821, -1.5052735, -1.607869, -1.7101698, -1.8119241, -1.9129229, -2.012995, -2.111999, -2.209818, -2.3063478, -2.4014938, -2.495161, -2.5872498, -2.6776516, -2.7662442, -2.8528917, -2.937442, -3.0197296, -3.0995753, -3.1767888, -3.251175, -3.3225355, -3.390676, -3.4554102, -3.516567, -3.5739949, -3.6275685, -3.6771932, -3.722809, -3.7643952, -3.80197, -3.8355935, -3.8653657, -3.8914258, -3.9139485, -3.9331396, -3.9492314, -3.962477, -3.9731443, -3.9815094, -3.987851, -3.9924438, -3.995555, -3.9974372, -3.998328, -3.9984438]\n",
      "Number of iterations consumed: 65\n",
      "Optimized circuit parameters: params = [1.2135738, 3.1531427, 3.2837114, 3.2292485]\n",
      "\n",
      "\n",
      "\n",
      "avg_gradients = [0.0002651112319862148]\n",
      "avg_gradients = [0.0002651112319862148, 0.32214098753040643]\n",
      "avg_gradients = [0.0002651112319862148, 0.32214098753040643, 0.30446866196232525]\n",
      "avg_gradients = [0.0002651112319862148, 0.32214098753040643, 0.30446866196232525, 0.04719006710710203]\n",
      "avg_gradients = [0.0002651112319862148, 0.32214098753040643, 0.30446866196232525, 0.04719006710710203, 0.13423571132889095]\n",
      "avg_gradients = [0.0002651112319862148, 0.32214098753040643, 0.30446866196232525, 0.04719006710710203, 0.13423571132889095, 0.2774792369471386]\n",
      "avg_gradients = [0.0002651112319862148, 0.32214098753040643, 0.30446866196232525, 0.04719006710710203, 0.13423571132889095, 0.2774792369471386, 0.10676569222121446]\n",
      "avg_gradients = [0.0002651112319862148, 0.32214098753040643, 0.30446866196232525, 0.04719006710710203, 0.13423571132889095, 0.2774792369471386, 0.10676569222121446, 0.24387312132860445]\n",
      "max_evaluation_value = 0.32214098753040643\n",
      "The vertex acted upon by the mixer = 7\n",
      "SEED = 8116, initial_beta = [3.1531427, 3.2837114, 3.2292485, 0.34047717], initial_gamma = [1.2135738, 0.295223]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [1.2135738, 0.295223, 3.1531427, 3.2837114, 3.2292485, 0.34047717]\n",
      "weight = [1.2135738  0.295223   3.1531427  3.2837114  3.2292485  0.34047717]\n",
      "lr = 0.05, ITR = 600\n",
      "train_step = 50, loss = -3.6906299591064453\n",
      "Convergence reached after 88 iterations. Expectation value evolution: loss0 = [-1.175014, -1.2380923, -1.3064095, -1.379984, -1.4582677, -1.5407076, -1.6271232, -1.7169567, -1.8089846, -1.902095, -1.99551, -2.0881953, -2.1791747, -2.2679586, -2.3540614, -2.4368873, -2.5161679, -2.5917256, -2.6632013, -2.7304614, -2.7935612, -2.8524463, -2.9072242, -2.958196, -3.005564, -3.0495834, -3.0906215, -3.1289291, -3.1647437, -3.1983783, -3.230067, -3.260024, -3.2885253, -3.315786, -3.3419795, -3.3673038, -3.3918946, -3.4158378, -3.439235, -3.4621518, -3.4846265, -3.5067163, -3.5284605, -3.5498736, -3.570977, -3.591776, -3.6122534, -3.632397, -3.6521914, -3.6716104, -3.690632, -3.7092369, -3.727394, -3.7450712, -3.7622364, -3.7788541, -3.7948883, -3.8103077, -3.8250864, -3.8392, -3.8526275, -3.865353, -3.8773646, -3.8886545, -3.8992205, -3.9090679, -3.918208, -3.9266574, -3.9344378, -3.9415736, -3.9480937, -3.9540286, -3.9594119, -3.9642785, -3.9686646, -3.9726062, -3.9761386, -3.9792955, -3.982109, -3.9846098, -3.9868264, -3.988785, -3.9905107, -3.9920256, -3.9933503, -3.994503, -3.9955006, -3.9963584]\n",
      "Number of iterations consumed: 88\n",
      "Optimized circuit parameters: params = [1.2135738, 3.0668018, 3.1038954, 3.140861, 3.1800013, 0.096136]\n",
      "\n",
      "\n",
      "\n",
      "avg_gradients = [2.828987411309658e-05]\n",
      "avg_gradients = [2.828987411309658e-05, 0.2788082696451066]\n",
      "avg_gradients = [2.828987411309658e-05, 0.2788082696451066, 0.21470327576309742]\n",
      "avg_gradients = [2.828987411309658e-05, 0.2788082696451066, 0.21470327576309742, 0.04255953228477318]\n",
      "avg_gradients = [2.828987411309658e-05, 0.2788082696451066, 0.21470327576309742, 0.04255953228477318, 0.08069738852766586]\n",
      "avg_gradients = [2.828987411309658e-05, 0.2788082696451066, 0.21470327576309742, 0.04255953228477318, 0.08069738852766586, 0.24197563004932943]\n",
      "avg_gradients = [2.828987411309658e-05, 0.2788082696451066, 0.21470327576309742, 0.04255953228477318, 0.08069738852766586, 0.24197563004932943, 0.09588154579749893]\n",
      "avg_gradients = [2.828987411309658e-05, 0.2788082696451066, 0.21470327576309742, 0.04255953228477318, 0.08069738852766586, 0.24197563004932943, 0.09588154579749893, 0.29200893688795626]\n",
      "max_evaluation_value = 0.29200893688795626\n",
      "The vertex acted upon by the mixer = 7\n",
      "SEED = 8116, initial_beta = [3.0668018, 3.1038954, 3.140861, 3.1800013, 0.096136, 1.372392], initial_gamma = [1.2135738, 0.48342666]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [1.2135738, 0.48342666, 3.0668018, 3.1038954, 3.140861, 3.1800013, 0.096136, 1.372392]\n",
      "weight = [1.2135738  0.48342666 3.0668018  3.1038954  3.140861   3.1800013\n",
      " 0.096136   1.372392  ]\n",
      "lr = 0.05, ITR = 600\n",
      "train_step = 50, loss = -3.921989917755127\n",
      "Convergence reached after 67 iterations. Expectation value evolution: loss0 = [-1.6797574, -1.7614166, -1.843528, -1.9262402, -2.0086107, -2.0895016, -2.1683526, -2.2446678, -2.3176157, -2.3869367, -2.4528267, -2.5149689, -2.5730245, -2.6271183, -2.677811, -2.7255614, -2.7708647, -2.8144097, -2.8568127, -2.8985047, -2.939921, -2.9816012, -3.023914, -3.0669503, -3.1107063, -3.15511, -3.1999643, -3.245054, -3.2901812, -3.3350441, -3.3792758, -3.4225614, -3.4646156, -3.505178, -3.5440726, -3.5811594, -3.6162975, -3.6494095, -3.6804945, -3.7095852, -3.7367435, -3.762063, -3.7856386, -3.8075597, -3.827923, -3.8468285, -3.8643634, -3.8805978, -3.8955872, -3.909374, -3.9219913, -3.933469, -3.9438365, -3.9531236, -3.9613616, -3.9685884, -3.9748502, -3.9802022, -3.9847062, -3.9884317, -3.9914541, -3.9938529, -3.995708, -3.9970977, -3.9980981, -3.9987798, -3.9992068]\n",
      "Number of iterations consumed: 67\n",
      "Optimized circuit parameters: params = [1.2135738, 3.1206262, 3.1757128, 3.8268497, 3.1091034, 0.015479286, 0.032975726, 0.6485465]\n",
      "\n",
      "\n",
      "\n",
      "Small improvement in expectation value, terminating.\n",
      "Expectation value changes: [2.98439, 3.99844, 3.99636, 3.99921]\n",
      "Mixer vertices for each layer: [[5, 4, 2, 1, 6], [7], [1], [7]]\n",
      "Execution 3 completed.\n",
      "Expectation values: [2.98439, 3.99844, 3.99636, 3.99921]\n",
      "Mixer vertices per layer: [[5, 4, 2, 1, 6], [7], [1], [7]]\n",
      "Iteration counts: [26.0, 65, 88, 67]\n",
      "Circuit depth per layer: [16, 20, 24, 28]\n",
      "Runtime: 107.46s\n",
      "Vertices selected for mixer application in the first layer: [5, 1, 6, 0, 7]\n",
      "\n",
      "\n",
      "\n",
      "The 1-th global random initialization\n",
      "SEED = 2371, initial_beta = [1.1619825], initial_gamma = [1.0417523]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [1.0417523, 1.1619825]\n",
      "weight = [1.0417523 1.1619825]\n",
      "lr = 0.05, ITR = 600\n",
      "train_step = 50, loss = -2.999160051345825\n",
      "Convergence reached after 52 iterations. Expectation value evolution: loss0 = [-1.2169898, -1.2924572, -1.3674519, -1.4418082, -1.5153769, -1.588021, -1.6596156, -1.7300454, -1.7992029, -1.866986, -1.9332975, -1.9980428, -2.0611298, -2.122468, -2.1819682, -2.239544, -2.2951112, -2.3485904, -2.3999069, -2.4489932, -2.4957912, -2.5402524, -2.5823407, -2.6220317, -2.659316, -2.6941981, -2.7266974, -2.756847, -2.784694, -2.8102982, -2.8337314, -2.8550751, -2.8744197, -2.8918626, -2.9075074, -2.9214606, -2.9338324, -2.9447331, -2.9542737, -2.962564, -2.969711, -2.9758198, -2.9809911, -2.9853215, -2.9889033, -2.9918234, -2.9941635, -2.996, -2.9974031, -2.9984381, -2.999164, -2.9996347]\n",
      "Number of iterations consumed: 52\n",
      "Optimized circuit parameters: params = [1.0417523, 3.1272979]\n",
      "\n",
      "\n",
      "\n",
      "Global random initialization complete. Logging results...\n",
      "value = [2.99963]\n",
      "\n",
      "\n",
      "\n",
      "params = [[beta_optimized, gamma_optimized], ...] = [[[3.1272979], [1.0417523]]]\n",
      "\n",
      "\n",
      "\n",
      "measure_result = [{'10100010': 1000}]\n",
      "\n",
      "\n",
      "\n",
      "consumed_iterations = [52]\n",
      "\n",
      "\n",
      "\n",
      "avg_loss = 2.99963\n",
      "Average iterations consumed = 52.0\n",
      "max_loss = 2.9996299743652344\n",
      "params_opt = [[[3.1272979], [1.0417523]]]\n",
      "\n",
      "\n",
      "SEED_opt = [2371]\n",
      "avg_gradients = [4.844897265599002e-07]\n",
      "avg_gradients = [4.844897265599002e-07, 0.48752787799148034]\n",
      "avg_gradients = [4.844897265599002e-07, 0.48752787799148034, 0.15129726413682457]\n",
      "avg_gradients = [4.844897265599002e-07, 0.48752787799148034, 0.15129726413682457, 3.866614775471788e-06]\n",
      "avg_gradients = [4.844897265599002e-07, 0.48752787799148034, 0.15129726413682457, 3.866614775471788e-06, 0.041535757742802826]\n",
      "avg_gradients = [4.844897265599002e-07, 0.48752787799148034, 0.15129726413682457, 3.866614775471788e-06, 0.041535757742802826, 0.026145789325773716]\n",
      "avg_gradients = [4.844897265599002e-07, 0.48752787799148034, 0.15129726413682457, 3.866614775471788e-06, 0.041535757742802826, 0.026145789325773716, 0.044273320962079143]\n",
      "avg_gradients = [4.844897265599002e-07, 0.48752787799148034, 0.15129726413682457, 3.866614775471788e-06, 0.041535757742802826, 0.026145789325773716, 0.044273320962079143, 0.16405047236979398]\n",
      "max_evaluation_value = 0.48752787799148034\n",
      "First allowed mixer vertex = 1\n",
      "The vertice acted on by the mixer is: [1]\n",
      "SEED = 10457, initial_beta = [3.1272979, 2.2710848], initial_gamma = [1.0417523, 2.517662]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [1.0417523, 2.517662, 3.1272979, 2.2710848]\n",
      "weight = [1.0417523 2.517662  3.1272979 2.2710848]\n",
      "lr = 0.05, ITR = 600\n",
      "train_step = 50, loss = -2.983609914779663\n",
      "Convergence reached after 56 iterations. Expectation value evolution: loss0 = [-1.9128227, -1.9441174, -1.9789183, -2.0170617, -2.0582948, -2.102299, -2.1486824, -2.1969767, -2.2466347, -2.2970364, -2.347503, -2.397319, -2.4457786, -2.4922543, -2.5363016, -2.5777621, -2.61676, -2.653527, -2.6881847, -2.7206686, -2.7507784, -2.778263, -2.802887, -2.824481, -2.8429754, -2.8584175, -2.8709795, -2.8809493, -2.8887093, -2.8947074, -2.8994195, -2.903312, -2.906807, -2.910256, -2.9139218, -2.9179728, -2.922484, -2.927449, -2.9327962, -2.9384072, -2.9441366, -2.9498308, -2.9553428, -2.9605439, -2.9653323, -2.969638, -2.9734237, -2.9766824, -2.9794357, -2.9817266, -2.9836142, -2.9851668, -2.9864566, -2.987553, -2.9885178, -2.9894035]\n",
      "Number of iterations consumed: 56\n",
      "Optimized circuit parameters: params = [1.0417523, 3.2450838, 3.3412056, 0.2685469]\n",
      "\n",
      "\n",
      "\n",
      "avg_gradients = [0.12231089666227923]\n",
      "avg_gradients = [0.12231089666227923, 0.32671416255480257]\n",
      "avg_gradients = [0.12231089666227923, 0.32671416255480257, 0.1933985144493914]\n",
      "avg_gradients = [0.12231089666227923, 0.32671416255480257, 0.1933985144493914, 0.03442220517094667]\n",
      "avg_gradients = [0.12231089666227923, 0.32671416255480257, 0.1933985144493914, 0.03442220517094667, 0.01951646590788155]\n",
      "avg_gradients = [0.12231089666227923, 0.32671416255480257, 0.1933985144493914, 0.03442220517094667, 0.01951646590788155, 0.18268039727987057]\n",
      "avg_gradients = [0.12231089666227923, 0.32671416255480257, 0.1933985144493914, 0.03442220517094667, 0.01951646590788155, 0.18268039727987057, 0.130692579046528]\n",
      "avg_gradients = [0.12231089666227923, 0.32671416255480257, 0.1933985144493914, 0.03442220517094667, 0.01951646590788155, 0.18268039727987057, 0.130692579046528, 0.2695484906753715]\n",
      "max_evaluation_value = 0.32671416255480257\n",
      "The vertex acted upon by the mixer = 1\n",
      "SEED = 10457, initial_beta = [3.2450838, 3.3412056, 0.2685469, 1.8364518], initial_gamma = [1.0417523, 0.13290489]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [1.0417523, 0.13290489, 3.2450838, 3.3412056, 0.2685469, 1.8364518]\n",
      "weight = [1.0417523  0.13290489 3.2450838  3.3412056  0.2685469  1.8364518 ]\n",
      "lr = 0.05, ITR = 600\n",
      "train_step = 50, loss = -2.775059938430786\n",
      "Convergence reached after 91 iterations. Expectation value evolution: loss0 = [-0.35702148, -0.44489643, -0.53893167, -0.63737077, -0.7389187, -0.84193844, -0.9441994, -1.0436231, -1.1389176, -1.2291573, -1.3131292, -1.3895708, -1.4576893, -1.5175233, -1.5699319, -1.6161952, -1.6576885, -1.6958464, -1.7322193, -1.768261, -1.8050085, -1.8430732, -1.8827459, -1.9240692, -1.9668871, -2.0108933, -2.0556824, -2.1007967, -2.1457694, -2.1901598, -2.233583, -2.2757277, -2.3163643, -2.355339, -2.392558, -2.4279704, -2.461553, -2.4933112, -2.5232828, -2.5515423, -2.578195, -2.603357, -2.627133, -2.6496031, -2.6708245, -2.690844, -2.7097135, -2.7274961, -2.744266, -2.7600987, -2.775062, -2.7892146, -2.8026047, -2.8152764, -2.8272712, -2.8386292, -2.849388, -2.85958, -2.8692322, -2.8783658, -2.8869982, -2.895144, -2.9028168, -2.9100306, -2.9168, -2.9231405, -2.9290686, -2.9346006, -2.9397545, -2.944548, -2.9489987, -2.9531255, -2.9569468, -2.9604812, -2.9637473, -2.9667625, -2.969545, -2.9721112, -2.974477, -2.9766576, -2.9786673, -2.9805186, -2.982224, -2.9837942, -2.9852395, -2.9865694, -2.987792, -2.9889154, -2.9899466, -2.9908922, -2.9917583]\n",
      "Number of iterations consumed: 91\n",
      "Optimized circuit parameters: params = [1.0417523, 2.9748187, 4.801866, 3.1837242, 1.4735526, 2.9318619]\n",
      "\n",
      "\n",
      "\n",
      "Small improvement in expectation value, terminating.\n",
      "Expectation value changes: [2.99963, 2.9894, 2.99176]\n",
      "Mixer vertices for each layer: [[5, 1, 6, 0, 7], [1], [1]]\n",
      "Execution 4 completed.\n",
      "Expectation values: [2.99963, 2.9894, 2.99176]\n",
      "Mixer vertices per layer: [[5, 1, 6, 0, 7], [1], [1]]\n",
      "Iteration counts: [52.0, 56, 91]\n",
      "Circuit depth per layer: [16, 20, 24]\n",
      "Runtime: 71.06s\n",
      "Vertices selected for mixer application in the first layer: [5, 2, 7, 4, 6]\n",
      "\n",
      "\n",
      "\n",
      "The 1-th global random initialization\n",
      "SEED = 2111, initial_beta = [2.5274801], initial_gamma = [0.18048392]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [0.18048392, 2.5274801]\n",
      "weight = [0.18048392 2.5274801 ]\n",
      "lr = 0.05, ITR = 600\n",
      "Convergence reached after 24 iterations. Expectation value evolution: loss0 = [-2.741095, -2.778668, -2.8138416, -2.8463824, -2.8760676, -2.9026983, -2.9261103, -2.9461894, -2.9628859, -2.976227, -2.986328, -2.9933982, -2.99774, -2.9997387, -2.9998434, -2.99854, -2.9963193, -2.9936433, -2.990917, -2.988466, -2.9865258, -2.98524, -2.984667, -2.9847915]\n",
      "Number of iterations consumed: 24\n",
      "Optimized circuit parameters: params = [0.18048392, 3.2807775]\n",
      "\n",
      "\n",
      "\n",
      "Global random initialization complete. Logging results...\n",
      "value = [2.98479]\n",
      "\n",
      "\n",
      "\n",
      "params = [[beta_optimized, gamma_optimized], ...] = [[[3.2807775], [0.18048392]]]\n",
      "\n",
      "\n",
      "\n",
      "measure_result = [{'00100000': 1, '00100100': 9, '10000100': 4, '10100000': 3, '10100100': 983}]\n",
      "\n",
      "\n",
      "\n",
      "consumed_iterations = [24]\n",
      "\n",
      "\n",
      "\n",
      "avg_loss = 2.98479\n",
      "Average iterations consumed = 24.0\n",
      "max_loss = 2.984790086746216\n",
      "params_opt = [[[3.2807775], [0.18048392]]]\n",
      "\n",
      "\n",
      "SEED_opt = [2111]\n",
      "avg_gradients = [0.00860909357360029]\n",
      "avg_gradients = [0.00860909357360029, 0.3359268604016873]\n",
      "avg_gradients = [0.00860909357360029, 0.3359268604016873, 0.28675498803092225]\n",
      "avg_gradients = [0.00860909357360029, 0.3359268604016873, 0.28675498803092225, 0.010667815812346104]\n",
      "avg_gradients = [0.00860909357360029, 0.3359268604016873, 0.28675498803092225, 0.010667815812346104, 0.005704092010660355]\n",
      "avg_gradients = [0.00860909357360029, 0.3359268604016873, 0.28675498803092225, 0.010667815812346104, 0.005704092010660355, 0.08964434135483068]\n",
      "avg_gradients = [0.00860909357360029, 0.3359268604016873, 0.28675498803092225, 0.010667815812346104, 0.005704092010660355, 0.08964434135483068, 0.023113829879181647]\n",
      "avg_gradients = [0.00860909357360029, 0.3359268604016873, 0.28675498803092225, 0.010667815812346104, 0.005704092010660355, 0.08964434135483068, 0.023113829879181647, 0.21118273042576519]\n",
      "max_evaluation_value = 0.3359268604016873\n",
      "First allowed mixer vertex = 1\n",
      "The vertice acted on by the mixer is: [1]\n",
      "SEED = 15714, initial_beta = [3.2807775, 1.8101279], initial_gamma = [0.18048392, 1.8320317]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [0.18048392, 1.8320317, 3.2807775, 1.8101279]\n",
      "weight = [0.18048392 1.8320317  3.2807775  1.8101279 ]\n",
      "lr = 0.05, ITR = 600\n",
      "Convergence reached after 33 iterations. Expectation value evolution: loss0 = [-2.6254783, -2.708679, -2.7908657, -2.8719003, -2.9516253, -3.0298615, -3.1064095, -3.1810546, -3.2535672, -3.3237073, -3.3912299, -3.45589, -3.5174472, -3.5756745, -3.6303625, -3.681327, -3.7284157, -3.7715125, -3.8105443, -3.845485, -3.876357, -3.9032347, -3.9262428, -3.9455552, -3.9613912, -3.9740095, -3.983703, -3.9907885, -3.9956, -3.9984782, -3.9997616, -3.9997785, -3.9988382]\n",
      "Number of iterations consumed: 33\n",
      "Optimized circuit parameters: params = [0.18048392, 3.198592, 3.2807775, 3.1784399]\n",
      "\n",
      "\n",
      "\n",
      "avg_gradients = [0.01468434903078365]\n",
      "avg_gradients = [0.01468434903078365, 0.24832620093548297]\n",
      "avg_gradients = [0.01468434903078365, 0.24832620093548297, 0.2511927726318874]\n",
      "avg_gradients = [0.01468434903078365, 0.24832620093548297, 0.2511927726318874, 0.036825742952803685]\n",
      "avg_gradients = [0.01468434903078365, 0.24832620093548297, 0.2511927726318874, 0.036825742952803685, 0.016820655659465434]\n",
      "avg_gradients = [0.01468434903078365, 0.24832620093548297, 0.2511927726318874, 0.036825742952803685, 0.016820655659465434, 0.280340375779838]\n",
      "avg_gradients = [0.01468434903078365, 0.24832620093548297, 0.2511927726318874, 0.036825742952803685, 0.016820655659465434, 0.280340375779838, 0.0972079244233703]\n",
      "avg_gradients = [0.01468434903078365, 0.24832620093548297, 0.2511927726318874, 0.036825742952803685, 0.016820655659465434, 0.280340375779838, 0.0972079244233703, 0.31554730185611]\n",
      "max_evaluation_value = 0.31554730185611\n",
      "The vertex acted upon by the mixer = 1\n",
      "SEED = 15714, initial_beta = [3.198592, 3.2807775, 3.1784399, 0.79175425], initial_gamma = [0.18048392, 1.2269107]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [0.18048392, 1.2269107, 3.198592, 3.2807775, 3.1784399, 0.79175425]\n",
      "weight = [0.18048392 1.2269107  3.198592   3.2807775  3.1784399  0.79175425]\n",
      "lr = 0.05, ITR = 600\n",
      "train_step = 50, loss = -3.969860076904297\n",
      "Convergence reached after 63 iterations. Expectation value evolution: loss0 = [-2.5219264, -2.6167426, -2.7051058, -2.7897987, -2.8703017, -2.9456327, -3.0157285, -3.0811274, -3.141794, -3.1971333, -3.2467546, -3.2908826, -3.3301554, -3.3651388, -3.3962739, -3.4240954, -3.449326, -3.4727173, -3.4948168, -3.515938, -3.5363007, -3.5561483, -3.5757418, -3.5952728, -3.6148114, -3.6343377, -3.6538012, -3.6731524, -3.6923394, -3.7112913, -3.7299254, -3.7481651, -3.765954, -3.7832496, -3.8000104, -3.8161852, -3.8317149, -3.8465426, -3.8606248, -3.8739362, -3.886467, -3.8982153, -3.909182, -3.919367, -3.9287722, -3.937405, -3.9452825, -3.9524307, -3.9588842, -3.9646819, -3.9698617, -3.974462, -3.9785206, -3.982076, -3.985169, -3.9878423, -3.9901383, -3.992097, -3.993754, -3.9951422, -3.9962919, -3.9972305, -3.9979856]\n",
      "Number of iterations consumed: 63\n",
      "Optimized circuit parameters: params = [0.18048392, 3.0889764, 3.147057, 3.1449935, 3.126905, 0.06373906]\n",
      "\n",
      "\n",
      "\n",
      "avg_gradients = [0.011991824938730012]\n",
      "avg_gradients = [0.011991824938730012, 0.3310282562912467]\n",
      "avg_gradients = [0.011991824938730012, 0.3310282562912467, 0.2775600659387636]\n",
      "avg_gradients = [0.011991824938730012, 0.3310282562912467, 0.2775600659387636, 0.01730437397858564]\n",
      "avg_gradients = [0.011991824938730012, 0.3310282562912467, 0.2775600659387636, 0.01730437397858564, 0.010243325667491643]\n",
      "avg_gradients = [0.011991824938730012, 0.3310282562912467, 0.2775600659387636, 0.01730437397858564, 0.010243325667491643, 0.26138476038994457]\n",
      "avg_gradients = [0.011991824938730012, 0.3310282562912467, 0.2775600659387636, 0.01730437397858564, 0.010243325667491643, 0.26138476038994457, 0.1451247710212949]\n",
      "avg_gradients = [0.011991824938730012, 0.3310282562912467, 0.2775600659387636, 0.01730437397858564, 0.010243325667491643, 0.26138476038994457, 0.1451247710212949, 0.3542641897481971]\n",
      "max_evaluation_value = 0.3542641897481971\n",
      "The vertex acted upon by the mixer = 1\n",
      "SEED = 15714, initial_beta = [3.0889764, 3.147057, 3.1449935, 3.126905, 0.06373906, 1.7119063], initial_gamma = [0.18048392, 1.036058]\n",
      "This is the function named execute_function, params = [gamma1, beta1, beta2, ...] = [0.18048392, 1.036058, 3.0889764, 3.147057, 3.1449935, 3.126905, 0.06373906, 1.7119063]\n",
      "weight = [0.18048392 1.036058   3.0889764  3.147057   3.1449935  3.126905\n",
      " 0.06373906 1.7119063 ]\n",
      "lr = 0.05, ITR = 600\n",
      "train_step = 50, loss = -3.937659978866577\n",
      "Convergence reached after 69 iterations. Expectation value evolution: loss0 = [-1.6738844, -1.7437166, -1.8244079, -1.9145062, -2.013648, -2.1207643, -2.2336555, -2.3495114, -2.4651573, -2.5771768, -2.682012, -2.7763078, -2.8574703, -2.9242127, -2.9768867, -3.0174067, -3.0487587, -3.0743167, -3.0972366, -3.1200848, -3.1446826, -3.172103, -3.2027795, -3.236675, -3.2734375, -3.3125079, -3.3531885, -3.39471, -3.4363124, -3.4773126, -3.517136, -3.5553203, -3.591514, -3.6254907, -3.6571505, -3.6865036, -3.7136314, -3.7386618, -3.7617548, -3.7830925, -3.802858, -3.8212154, -3.838299, -3.8542192, -3.869064, -3.8828957, -3.8957493, -3.9076424, -3.918585, -3.9285867, -3.9376576, -3.945812, -3.9530745, -3.9594853, -3.9650962, -3.969968, -3.974169, -3.9777744, -3.9808621, -3.983507, -3.985777, -3.9877343, -3.989433, -3.9909165, -3.9922178, -3.993362, -3.9943678, -3.9952493, -3.9960153]\n",
      "Number of iterations consumed: 69\n",
      "Optimized circuit parameters: params = [0.18048392, 3.0966117, 2.347252, 3.1423407, 2.403269, 2.441755, 2.9302368, 2.413766]\n",
      "\n",
      "\n",
      "\n",
      "Small improvement in expectation value, terminating.\n",
      "Expectation value changes: [2.98479, 3.99884, 3.99799, 3.99602]\n",
      "Mixer vertices for each layer: [[5, 2, 7, 4, 6], [1], [7], [7]]\n",
      "Execution 5 completed.\n",
      "Expectation values: [2.98479, 3.99884, 3.99799, 3.99602]\n",
      "Mixer vertices per layer: [[5, 2, 7, 4, 6], [1], [7], [7]]\n",
      "Iteration counts: [24.0, 33, 63, 69]\n",
      "Circuit depth per layer: [16, 20, 24, 28]\n",
      "Runtime: 93.56s\n",
      "All expectation values from executions: [[2.9986, 2.99702, 2.99792], [2.99859, 3.99669, 3.98622, 3.99975], [2.98439, 3.99844, 3.99636, 3.99921], [2.99963, 2.9894, 2.99176], [2.98479, 3.99884, 3.99799, 3.99602]]\n",
      "All mixer vertices per layer: [[[7, 2, 3, 5, 0], [7], [7]], [[3, 7, 4, 5, 1], [6], [6], [6]], [[5, 4, 2, 1, 6], [7], [1], [7]], [[5, 1, 6, 0, 7], [1], [1]], [[5, 2, 7, 4, 6], [1], [7], [7]]]\n",
      "All iteration counts: [[68.0, 84, 41], [7.0, 51, 20, 47], [26.0, 65, 88, 67], [52.0, 56, 91], [24.0, 33, 63, 69]]\n",
      "All circuit depths: [[16, 20, 24], [16, 20, 24, 28], [16, 20, 24, 28], [16, 20, 24], [16, 20, 24, 28]]\n",
      "All runtimes: [55.2762815952301, 77.15391731262207, 107.45925068855286, 71.06150555610657, 93.56131410598755]\n"
     ]
    }
   ],
   "source": [
    "# Construct the target Hamiltonian\n",
    "ham = build_ham(target_graph)\n",
    "\n",
    "# Parameter initialization\n",
    "counts = 1  # Number of repeated random initializations (RI) for 1-layer ansatz\n",
    "delta = 0.1  # Convergence threshold for expectation value changes\n",
    "iterations = []  # Store the number of iterations per optimization round\n",
    "mixers = []  # Store allowed mixer vertices per layer\n",
    "values = []  # Store the evolution of expectation values\n",
    "running_time = []  # Store the runtime of each execution\n",
    "depth = []  # Store the circuit depth of each execution\n",
    "\n",
    "times = 5\n",
    "# times = int(input('Please input the number of the Adaptive QAOA runs:'))  # Number of repeated adaptive ansatz runs\n",
    "\n",
    "# Generate random seeds for repeated runs\n",
    "total_SEED = []\n",
    "for i in range(times):\n",
    "    total_SEED.append(random.randint(1, 25000))\n",
    "my_logger.info('Generated random seeds: total_SEED = {}'.format(total_SEED))\n",
    "\n",
    "# Start adaptive ansatz execution\n",
    "for i in range(len(total_SEED)):\n",
    "    start_time = time.time()  # Record start time\n",
    "    \n",
    "    # Current seed for this run\n",
    "    SEED = total_SEED[i]\n",
    "    \n",
    "    # Execute adaptive ansatz and retrieve optimization results\n",
    "    function_values, mixer_nodes, ITR, circuit_depth_layer = adaptive_ansatz(SEED)\n",
    "    \n",
    "    # Store results\n",
    "    iterations.append(ITR)  # Append iteration counts per round\n",
    "    mixers.append(mixer_nodes)  # Append allowed mixer vertices per layer\n",
    "    values.append(function_values)  # Append expectation values per layer\n",
    "    depth.append(circuit_depth_layer)  # Append circuit depth per layer\n",
    "\n",
    "    # Record runtime\n",
    "    end_time = time.time()\n",
    "    delta0 = end_time - start_time\n",
    "    running_time.append(delta0)\n",
    "\n",
    "    # Log results\n",
    "    my_logger.info('Execution {} completed.'.format(i + 1))\n",
    "    my_logger.info('Expectation values: {}'.format(function_values))\n",
    "    my_logger.info('Mixer vertices per layer: {}'.format(mixer_nodes))\n",
    "    my_logger.info('Iteration counts: {}'.format(ITR))\n",
    "    my_logger.info('Circuit depth per layer: {}'.format(circuit_depth_layer))\n",
    "    my_logger.info('Runtime: {:.2f}s'.format(delta0))\n",
    "\n",
    "# Final summary of results\n",
    "my_logger.info('All expectation values from executions: {}'.format(values))\n",
    "my_logger.info('All mixer vertices per layer: {}'.format(mixers))\n",
    "my_logger.info('All iteration counts: {}'.format(iterations))\n",
    "my_logger.info('All circuit depths: {}'.format(depth))\n",
    "my_logger.info('All runtimes: {}'.format(running_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "974db1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth = [[16, 20, 24], [16, 20, 24, 28], [16, 20, 24, 28], [16, 20, 24], [16, 20, 24, 28]]\n",
      "max_depth = [24, 28, 28, 24, 28]\n"
     ]
    }
   ],
   "source": [
    "my_logger.info('depth = {}'.format(depth))\n",
    "\n",
    "# Record the circuit depth in each run of the AMA algorithm\n",
    "max_depth = []\n",
    "for i in range(0,len(depth)):\n",
    "    max_depth.append(max(depth[i]))\n",
    "my_logger.info('max_depth = {}'.format(max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a62556bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values = [[2.9986, 2.99702, 2.99792], [2.99859, 3.99669, 3.98622, 3.99975], [2.98439, 3.99844, 3.99636, 3.99921], [2.99963, 2.9894, 2.99176], [2.98479, 3.99884, 3.99799, 3.99602]]\n",
      "\n",
      "\n",
      "mixers = [[[7, 2, 3, 5, 0], [7], [7]], [[3, 7, 4, 5, 1], [6], [6], [6]], [[5, 4, 2, 1, 6], [7], [1], [7]], [[5, 1, 6, 0, 7], [1], [1]], [[5, 2, 7, 4, 6], [1], [7], [7]]]\n",
      "\n",
      "\n",
      "iterations = [[68.0, 84, 41], [7.0, 51, 20, 47], [26.0, 65, 88, 67], [52.0, 56, 91], [24.0, 33, 63, 69]]\n",
      "\n",
      "\n",
      "running_time = [55.2762815952301, 77.15391731262207, 107.45925068855286, 71.06150555610657, 93.56131410598755]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_logger.info('values = {}'.format(values))\n",
    "my_logger.info('\\n')\n",
    "my_logger.info('mixers = {}'.format(mixers))\n",
    "my_logger.info('\\n')\n",
    "my_logger.info('iterations = {}'.format(iterations))\n",
    "my_logger.info('\\n')\n",
    "\n",
    "my_logger.info('running_time = {}'.format(running_time))\n",
    "my_logger.info('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3778c0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum expectation values for each run: max_loss_run = [2.9986, 3.99975, 3.99921, 2.99963, 3.99884]\n",
      "\n",
      "\n",
      "Total iteration counts for each run: total_iter_run = [193.0, 125.0, 246.0, 199.0, 189.0]\n"
     ]
    }
   ],
   "source": [
    "# Calculate and store the maximum expectation value from each run\n",
    "max_loss_run = []  # List to store the maximum expectation value for each run\n",
    "for i in range(len(values)):\n",
    "    max_loss_run.append(max(values[i]))  # Append the maximum value from each run's expectation values\n",
    "my_logger.info('Maximum expectation values for each run: max_loss_run = {}'.format(max_loss_run))\n",
    "\n",
    "# Calculate and store the total iteration count for each run\n",
    "total_iter_run = []  # List to store the total iteration count for each run\n",
    "for i in range(len(iterations)):\n",
    "    total_iterations = sum(iterations[i])  # Sum all iteration counts for this run\n",
    "    total_iter_run.append(total_iterations)  # Append the total iterations for this run\n",
    "my_logger.info('\\n')\n",
    "my_logger.info('Total iteration counts for each run: total_iter_run = {}'.format(total_iter_run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "434278ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degrees of allowed mixer vertices: degrees = [[[1, 3, 2, 4, 5], [1], [1]], [[2, 1, 4, 4, 2], [3], [3], [3]], [[4, 4, 3, 2, 3], [1], [2], [1]], [[4, 2, 3, 5, 1], [2], [2]], [[4, 3, 1, 4, 3], [2], [1], [1]]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the degree of allowed mixer vertices for each run\n",
    "# Used to compute the number of CNOT gates for multi-qubit controlled gates\n",
    "degrees = []  # Stores degrees of allowed mixer vertices for all runs\n",
    "\n",
    "# Loop over each run\n",
    "for i in range(len(mixers)):\n",
    "    degrees_run = []  # Stores degrees of allowed mixer vertices for each layer in the current run\n",
    "\n",
    "    # Loop over each layer in the current run\n",
    "    for j in range(len(mixers[i])):\n",
    "        degrees_round = []  # Stores degrees of allowed mixer vertices in the current layer\n",
    "\n",
    "        # Access each allowed mixer vertex in the current layer and store its degree\n",
    "        for t in range(len(mixers[i][j])):\n",
    "            node = mixers[i][j][t]  # Allowed mixer vertex\n",
    "            d = len(info[node])  # Degree of the vertex\n",
    "            degrees_round.append(d)\n",
    "        \n",
    "        degrees_run.append(degrees_round)  # Store degrees for the current layer\n",
    "    degrees.append(degrees_run)  # Store degrees for the current run\n",
    "    \n",
    "# Log the degrees information\n",
    "my_logger.info('Degrees of allowed mixer vertices: degrees = {}'.format(degrees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5728cb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mind_case",
   "language": "python",
   "name": "mind_case"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
